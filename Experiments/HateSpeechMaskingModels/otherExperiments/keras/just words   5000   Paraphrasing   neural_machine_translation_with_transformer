{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"just words | 5000 | Paraphrasing | neural_machine_translation_with_transformer","provenance":[{"file_id":"1WQn_jy0reyPrgoybw0zaFDa3_iS5DzAu","timestamp":1630098377011},{"file_id":"1AKMMMWo52uqXoLjFRwsPUPaLcYxYuuWR","timestamp":1630059224425},{"file_id":"16_nfzINfxjl0wXe7OmHg3R1YLoR-mcnp","timestamp":1629471209050},{"file_id":"1AKVcu4C08_OWa07Ghl84q6WmpijlrClk","timestamp":1629307981327},{"file_id":"1u2x4I-WagUER4QJNd4tt0bkz8ilfnDly","timestamp":1628998157816},{"file_id":"https://github.com/keras-team/keras-io/blob/master/examples/nlp/ipynb/neural_machine_translation_with_transformer.ipynb","timestamp":1628672106359}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"cells":[{"cell_type":"markdown","metadata":{"id":"OoI1jDpua-wl"},"source":["# English-to-Spanish translation with a sequence-to-sequence Transformer\n","\n","**Author:** [fchollet](https://twitter.com/fchollet)<br>\n","**Date created:** 2021/05/26<br>\n","**Last modified:** 2021/05/26<br>\n","**Description:** Implementing a sequence-to-sequene Transformer and training it on a machine translation task."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bTHMBYKRbi1T","executionInfo":{"status":"ok","timestamp":1630098688919,"user_tz":-180,"elapsed":47665,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"7d106ce4-c99a-4426-8666-eabf5a031586"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QC6rAuTna-wp"},"source":["## Introduction\n","\n","In this example, we'll build a sequence-to-sequence Transformer model, which\n","we'll train on an English-to-Spanish machine translation task.\n","\n","You'll learn how to:\n","\n","- Vectorize text using the Keras `TextVectorization` layer.\n","- Implement a `TransformerEncoder` layer, a `TransformerDecoder` layer,\n","and a `PositionalEmbedding` layer.\n","- Prepare data for training a sequence-to-sequence model.\n","- Use the trained model to generate translations of never-seen-before\n","input sentences (sequence-to-sequence inference).\n","\n","The code featured here is adapted from the book\n","[Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition)\n","(chapter 11: Deep learning for text).\n","The present example is fairly barebones, so for detailed explanations of\n","how each building block works, as well as the theory behind Transformers,\n","I recommend reading the book."]},{"cell_type":"markdown","metadata":{"id":"7il3-WZPa-wr"},"source":["## Setup"]},{"cell_type":"code","metadata":{"id":"ctfudCVLVpA6"},"source":["# !pip install --upgrade tensorflow\n","# !pip install --upgrade tensorflow-gpu"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mxIpmPJfa-ws","executionInfo":{"status":"ok","timestamp":1630098692712,"user_tz":-180,"elapsed":3798,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["import pathlib\n","import random\n","import string\n","import re\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6WkEVy-Za-wt"},"source":["## Downloading the data\n","\n","We'll be working with an English-to-Spanish translation dataset\n","provided by [Anki](https://www.manythings.org/anki/). Let's download it:"]},{"cell_type":"code","metadata":{"id":"W8FYDJLEa-wu","executionInfo":{"status":"ok","timestamp":1630098722970,"user_tz":-180,"elapsed":380,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# text_file = keras.utils.get_file(\n","#     fname=\"spa-eng.zip\",\n","#     origin=\"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n","#     extract=True,\n","# )\n","# text_file = pathlib.Path('/content/drive/MyDrive/MasterThesis/paraphrasing/ParapgrasingMask/Parapgrasing - Masking - maskWithWords.tsv')\n","# text_file = pathlib.Path('/content/drive/MyDrive/MasterThesis/paraphrasing/NOTHS_Parapgrasing - Masking - MaskWithoutWords.tsv')\n","text_file = pathlib.Path('/content/drive/MyDrive/MasterThesis/paraphrasing/maskbadWords.tsv')\n","# text_file = pathlib.Path('/content/drive/MyDrive/MasterThesis/paraphrasing/ParapgrasingMask/ParapgrasingMasking.tsv')"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3GIGj5-Qa-wv"},"source":["## Parsing the data\n","\n","Each line contains an English sentence and its corresponding Spanish sentence.\n","The English sentence is the *source sequence* and Spanish one is the *target sequence*.\n","We prepend the token `\"[start]\"` and we append the token `\"[end]\"` to the Spanish sentence."]},{"cell_type":"code","metadata":{"id":"TemcqrMsa-ww","executionInfo":{"status":"ok","timestamp":1630098730838,"user_tz":-180,"elapsed":2456,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["with open(text_file) as f:\n","    lines = f.read().split(\"\\n\")[:-1]\n","text_pairs = []\n","for line in lines:\n","    inp, targ = line.split(\"\\t\")\n","    targ = \"[start] \" + targ + \" [end]\"\n","    text_pairs.append((inp, targ))"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uVT6PBMga-wx"},"source":["Here's what our sentence pairs look like:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RVHW_4Gva-wy","executionInfo":{"status":"ok","timestamp":1630098730840,"user_tz":-180,"elapsed":7,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"7d54e330-0dcf-44f6-e120-41c0b947bb3e"},"source":["for _ in range(5):\n","    print(random.choice(text_pairs))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["('ÿÆÿßŸäŸÜÿ©', '[start] ***** [end]')\n","('ÿ≥ÿßŸÖÿ¨ÿ©', '[start] ***** [end]')\n","('ŸÅÿßÿ∫ÿ±', '[start] **** [end]')\n","('ŸäŸáŸàÿØŸä', '[start] ***** [end]')\n","('ÿßŸÖŸàÿ™ŸÉŸÖ', '[start] ****** [end]')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Z5tRhKiMa-wz"},"source":["Now, let's split the sentence pairs into a training set, a validation set,\n","and a test set."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8mUPXPWYa-wz","executionInfo":{"status":"ok","timestamp":1630098737006,"user_tz":-180,"elapsed":801,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"485abc9c-798a-4e52-ff9b-dfb9a056205c"},"source":["random.shuffle(text_pairs)\n","num_val_samples = int(0.25 * len(text_pairs))\n","num_train_samples = len(text_pairs) -  num_val_samples\n","train_pairs = text_pairs[:num_train_samples]\n","val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n","# test_pairs = text_pairs[num_train_samples + num_val_samples :]\n","\n","print(f\"{len(text_pairs)} total pairs\")\n","print(f\"{len(train_pairs)} training pairs\")\n","print(f\"{len(val_pairs)} validation pairs\")\n","# print(f\"{len(test_pairs)} test pairs\")"],"execution_count":6,"outputs":[{"output_type":"stream","text":["1448 total pairs\n","1086 training pairs\n","362 validation pairs\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IfI1L6L2l-bh","executionInfo":{"status":"ok","timestamp":1630098737620,"user_tz":-180,"elapsed":4,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"8bba5bc4-e4ce-40e9-f77d-df9e43985b5a"},"source":["test_file = pathlib.Path('/content/drive/MyDrive/MasterThesis/paraphrasing/paraphrasingTest.tsv')\n","with open(test_file) as f:\n","    lines = f.read().split(\"\\n\")[:-1]\n","test_pairs = []\n","for line in lines:\n","    inp, targ = line.split(\"\\t\")\n","    targ = \"[start] \" + targ + \" [end]\"\n","    test_pairs.append((inp, targ))\n","\n","for _ in range(5):\n","    print(random.choice(test_pairs))\n","\n","random.shuffle(test_pairs)\n","num_test_samples = len(test_pairs)\n","test_pairs = test_pairs[: num_test_samples]\n","print(f\"{len(test_pairs)} test pairs\")"],"execution_count":7,"outputs":[{"output_type":"stream","text":["('ÿ¨ÿßŸäŸÉŸÖ ÿ¨ÿßŸäŸÉŸÖ Ÿäÿß ÿßŸÑÿ≥ÿπŸàÿØŸäŸäŸÜ Ÿäÿß ÿßŸÑŸÉÿ®ÿ≥Ÿá ŸÉŸÑŸáÿß ŸäŸàŸÖ ŸàŸÜÿµ ÿ®ÿ≥', '[start] ÿ¨ÿßŸäŸÉŸÖ ÿ¨ÿßŸäŸÉŸÖ Ÿäÿß ÿßŸÑÿ≥ÿπŸàÿØŸäŸäŸÜ Ÿäÿß ÿßŸÑŸÉÿ®ÿ≥Ÿá ŸÉŸÑŸáÿß ŸäŸàŸÖ ŸàŸÜÿµ ÿ®ÿ≥ [end]')\n","('Ÿäÿß ÿßÿ®ŸÜ ÿßŸÑŸÉÿßŸÅÿ±ÿ© Ÿäÿß ÿ±ŸàŸÜÿßŸÑÿØŸà ... ÿ™ÿ≠ÿ±ŸÉ ÿ≥ŸÖ', '[start] Ÿäÿß ÿßÿ®ŸÜ ******* Ÿäÿß ÿ±ŸàŸÜÿßŸÑÿØŸà ... ÿ™ÿ≠ÿ±ŸÉ ** [end]')\n","('Ÿäÿß ÿ¨ŸÖÿßÿπÿ© Ÿäÿß ÿ¨ÿØÿπÿßŸÜ Ÿäÿß ÿ¥ÿ®ÿßÿ® Ÿäÿß ŸÖÿ≠ÿ™ÿ±ŸÖŸäŸÜ Ÿäÿß ÿßÿ≥ÿßÿ™ÿ∞ÿ© Ÿäÿß ŸàŸÑÿßÿØ ÿßŸÑŸÜÿßÿ≥ Ÿäÿß ŸàŸÑÿßÿØ ÿßŸÑŸàÿ≥ÿÆÿ© ŸÖŸãŸÄŸäŸèŸÄÿ≥Ÿä ŸÑÿß ŸäŸÇÿßÿ±ŸÜ üñ§üëë ‚Ä¶', '[start] Ÿäÿß ÿ¨ŸÖÿßÿπÿ© Ÿäÿß ÿ¨ÿØÿπÿßŸÜ Ÿäÿß ÿ¥ÿ®ÿßÿ® Ÿäÿß ŸÖÿ≠ÿ™ÿ±ŸÖŸäŸÜ Ÿäÿß ÿßÿ≥ÿßÿ™ÿ∞ÿ© Ÿäÿß ŸàŸÑÿßÿØ ÿßŸÑŸÜÿßÿ≥ Ÿäÿß ŸàŸÑÿßÿØ ****** ŸÖŸãŸÄŸäŸèŸÄÿ≥Ÿä ŸÑÿß ŸäŸÇÿßÿ±ŸÜ üñ§üëë ‚Ä¶ [end]')\n","('Ÿäÿß ÿ™ŸäŸÖŸà Ÿäÿß ÿØŸàŸÑŸä ÿπŸÇÿ®ÿßŸÑ ŸÖÿß ÿßŸÅÿ±ÿ≠ ÿ®ÿ™ÿÆÿ±ÿ¨ŸÉ ŸÉÿØÿ©üî•üî•üî•üî• ÿ®ÿ≠ÿ®ŸÉ ŸÅÿ¥ÿÆ Ÿäÿ≥ÿ∑ÿßÿß Ÿäÿß ŸÅÿÆÿ± ÿßŸÑŸÖŸÜÿµŸàÿ±ÿ© ŸàŸÖÿµÿ± ŸÉŸÑŸáÿß‚ô•Ô∏è‚ô•Ô∏è‚ô•Ô∏è‚ô•Ô∏è', '[start] Ÿäÿß ÿ™ŸäŸÖŸà Ÿäÿß ÿØŸàŸÑŸä ÿπŸÇÿ®ÿßŸÑ ŸÖÿß ÿßŸÅÿ±ÿ≠ ÿ®ÿ™ÿÆÿ±ÿ¨ŸÉ ŸÉÿØÿ©üî•üî•üî•üî• ÿ®ÿ≠ÿ®ŸÉ *** Ÿäÿ≥ÿ∑ÿßÿß Ÿäÿß ŸÅÿÆÿ± ÿßŸÑŸÖŸÜÿµŸàÿ±ÿ© ŸàŸÖÿµÿ± ŸÉŸÑŸáÿß‚ô•Ô∏è‚ô•Ô∏è‚ô•Ô∏è‚ô•Ô∏è [end]')\n","('Ÿäÿß ŸÉÿßŸÅÿ± Ÿäÿß ÿ≤ŸÜÿØŸäŸÇ Ÿäÿß ŸÖÿ±ÿ™ÿØ Ÿäÿß ÿßŸÜÿ™ ÿπÿßŸàÿ≤ Ÿäÿ®ŸÇŸâ ÿπŸÜÿØŸÜÿß ÿØŸäŸÖŸÇÿ±ÿßÿ∑Ÿäÿ© ÿ≤Ÿâ ÿßŸÑŸÉŸÅÿ±ÿ© ÿßŸÑŸÑŸâ ŸÖÿß Ÿäÿπÿ±ŸÅŸàÿ¥ ÿ±ÿ®ŸÜÿß', '[start] Ÿäÿß **** Ÿäÿß ***** Ÿäÿß **** Ÿäÿß ÿßŸÜÿ™ ÿπÿßŸàÿ≤ Ÿäÿ®ŸÇŸâ ÿπŸÜÿØŸÜÿß ÿØŸäŸÖŸÇÿ±ÿßÿ∑Ÿäÿ© ÿ≤Ÿâ ****** ÿßŸÑŸÑŸâ ŸÖÿß Ÿäÿπÿ±ŸÅŸàÿ¥ ÿ±ÿ®ŸÜÿß [end]')\n","401 test pairs\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1CpqzqNaa-w0"},"source":["## Vectorizing the text data\n","\n","We'll use two instances of the `TextVectorization` layer to vectorize the text\n","data (one for English and one for Spanish),\n","that is to say, to turn the original strings into integer sequences\n","where each integer represents the index of a word in a vocabulary.\n","\n","The English layer will use the default string standardization (strip punctuation characters)\n","and splitting scheme (split on whitespace), while\n","the Spanish layer will use a custom standardization, where we add the character\n","`\"¬ø\"` to the set of punctuation characters to be stripped.\n","\n","Note: in a production-grade machine translation model, I would not recommend\n","stripping the punctuation characters in either language. Instead, I would recommend turning\n","each punctuation character into its own token,\n","which you could achieve by providing a custom `split` function to the `TextVectorization` layer."]},{"cell_type":"code","metadata":{"id":"CPoQesZea-w0","executionInfo":{"status":"ok","timestamp":1630098756975,"user_tz":-180,"elapsed":1602,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# strip_chars = string.punctuation + \"¬ø\"\n","strip_chars = \"[a-zA-Z]|\\d+|[Ÿ†Ÿ°Ÿ¢Ÿ£Ÿ§Ÿ•Ÿ¶ŸßŸ®Ÿ©]|[.#ÿå<>@,\\\\-_‚Äù‚ÄúŸ™ŸéŸã]\"\n","\n","strip_chars = strip_chars.replace(\"[\", \"\")\n","strip_chars = strip_chars.replace(\"]\", \"\")\n","\n","vocab_size = 1450\n","sequence_length = 20\n","batch_size = 64\n","\n","\n","def custom_standardization(input_string):\n","    lowercase = tf.strings.lower(input_string)\n","    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n","\n","\n","inp_vectorization = TextVectorization(\n","    max_tokens=vocab_size, output_mode=\"int\", output_sequence_length=sequence_length,\n",")\n","targ_vectorization = TextVectorization(\n","    max_tokens=vocab_size,\n","    output_mode=\"int\",\n","    output_sequence_length=sequence_length + 1,\n","    standardize=custom_standardization,\n",")\n","train_eng_texts = [pair[0] for pair in train_pairs]\n","train_spa_texts = [pair[1] for pair in train_pairs]\n","inp_vectorization.adapt(train_eng_texts)\n","targ_vectorization.adapt(train_spa_texts)"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8enIADXMa-w1"},"source":["Next, we'll format our datasets.\n","\n","At each training step, the model will seek to predict target words N+1 (and beyond)\n","using the source sentence and the target words 0 to N.\n","\n","As such, the training dataset will yield a tuple `(inputs, targets)`, where:\n","\n","- `inputs` is a dictionary with the keys `encoder_inputs` and `decoder_inputs`.\n","`encoder_inputs` is the vectorized source sentence and `encoder_inputs` is the target sentence \"so far\",\n","that is to say, the words 0 to N used to predict word N+1 (and beyond) in the target sentence.\n","- `target` is the target sentence offset by one step:\n","it provides the next words in the target sentence -- what the model will try to predict."]},{"cell_type":"code","metadata":{"id":"dKmCVA5Ka-w2","executionInfo":{"status":"ok","timestamp":1630098760991,"user_tz":-180,"elapsed":507,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["\n","def format_dataset(inp, targ):\n","    inp = inp_vectorization(inp)\n","    targ = targ_vectorization(targ)\n","    return ({\"encoder_inputs\": inp, \"decoder_inputs\": targ[:, :-1],}, targ[:, 1:])\n","\n","\n","def make_dataset(pairs):\n","    inp_texts, targ_texts = zip(*pairs)\n","    inp_texts = list(inp_texts)\n","    targ_texts = list(targ_texts)\n","    dataset = tf.data.Dataset.from_tensor_slices((inp_texts, targ_texts))\n","    dataset = dataset.batch(batch_size)\n","    dataset = dataset.map(format_dataset)\n","    return dataset.shuffle(248).prefetch(16).cache()\n","\n","\n","train_ds = make_dataset(train_pairs)\n","val_ds = make_dataset(val_pairs)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U6ZQPBz4a-w3"},"source":["Let's take a quick look at the sequence shapes\n","(we have batches of 64 pairs, and all sequences are 20 steps long):"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PkVSFSxBa-w3","executionInfo":{"status":"ok","timestamp":1630098766084,"user_tz":-180,"elapsed":891,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"5f253204-aabe-45e7-be27-1ecb96064ca8"},"source":["for inputs, targets in train_ds.take(1):\n","    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n","    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n","    print(f\"targets.shape: {targets.shape}\")"],"execution_count":10,"outputs":[{"output_type":"stream","text":["inputs[\"encoder_inputs\"].shape: (64, 20)\n","inputs[\"decoder_inputs\"].shape: (64, 20)\n","targets.shape: (64, 20)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GQ6z9fVea-w3"},"source":["## Building the model\n","\n","Our sequence-to-sequence Transformer consists of a `TransformerEncoder`\n","and a `TransformerDecoder` chained together. To make the model aware of word order,\n","we also use a `PositionalEmbedding` layer.\n","\n","The source sequence will be pass to the `TransformerEncoder`,\n","which will produce a new representation of it.\n","This new representation will then be passed\n","to the `TransformerDecoder`, together with the target sequence so far (target words 0 to N).\n","The `TransformerDecoder` will then seek to predict the next words in the target sequence (N+1 and beyond).\n","\n","A key detail that makes this possible is causal masking\n","(see method `get_causal_attention_mask()` on the `TransformerDecoder`).\n","The `TransformerDecoder` sees the entire sequences at once, and thus we must make\n","sure that it only uses information from target tokens 0 to N when predicting token N+1\n","(otherwise, it could use information from the future, which would\n","result in a model that cannot be used at inference time)."]},{"cell_type":"code","metadata":{"id":"3jHRvQaHa-w3","executionInfo":{"status":"ok","timestamp":1630098766402,"user_tz":-180,"elapsed":6,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["\n","class TransformerEncoder(layers.Layer):\n","    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n","        super(TransformerEncoder, self).__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.dense_dim = dense_dim\n","        self.num_heads = num_heads\n","        self.attention = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim\n","        )\n","        self.dense_proj = keras.Sequential(\n","            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n","        )\n","        self.layernorm_1 = layers.LayerNormalization()\n","        self.layernorm_2 = layers.LayerNormalization()\n","        self.dropout = tf.keras.layers.Dropout(0.5)\n","        self.supports_masking = True\n","\n","    def call(self, inputs, mask=None):\n","        if mask is not None:\n","            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n","        attention_output = self.attention(\n","            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n","        )\n","        proj_input = self.layernorm_1(inputs + attention_output)\n","        proj_output = self.dense_proj(proj_input)\n","        return self.layernorm_2(proj_input + proj_output)\n","\n","\n","class PositionalEmbedding(layers.Layer):\n","    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n","        super(PositionalEmbedding, self).__init__(**kwargs)\n","        self.token_embeddings = layers.Embedding(\n","            input_dim=vocab_size, output_dim=embed_dim\n","        )\n","        self.position_embeddings = layers.Embedding(\n","            input_dim=sequence_length, output_dim=embed_dim\n","        )\n","        self.sequence_length = sequence_length\n","        self.vocab_size = vocab_size\n","        self.embed_dim = embed_dim\n","\n","    def call(self, inputs):\n","        length = tf.shape(inputs)[-1]\n","        positions = tf.range(start=0, limit=length, delta=1)\n","        embedded_tokens = self.token_embeddings(inputs)\n","        embedded_positions = self.position_embeddings(positions)\n","        return embedded_tokens + embedded_positions\n","\n","    def compute_mask(self, inputs, mask=None):\n","        return tf.math.not_equal(inputs, 0)\n","\n","\n","class TransformerDecoder(layers.Layer):\n","    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n","        super(TransformerDecoder, self).__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.latent_dim = latent_dim\n","        self.num_heads = num_heads\n","        self.attention_1 = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim\n","        )\n","        self.attention_2 = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=embed_dim\n","        )\n","        self.dense_proj = keras.Sequential(\n","            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n","        )\n","        self.layernorm_1 = layers.LayerNormalization()\n","        self.layernorm_2 = layers.LayerNormalization()\n","        self.dropout = tf.keras.layers.Dropout(0.5)\n","\n","        self.layernorm_3 = layers.LayerNormalization()\n","        self.supports_masking = True\n","\n","    def call(self, inputs, encoder_outputs, mask=None):\n","        causal_mask = self.get_causal_attention_mask(inputs)\n","        if mask is not None:\n","            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n","            padding_mask = tf.minimum(padding_mask, causal_mask)\n","\n","        attention_output_1 = self.attention_1(\n","            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n","        )\n","        out_1 = self.layernorm_1(inputs + attention_output_1)\n","\n","        attention_output_2 = self.attention_2(\n","            query=out_1,\n","            value=encoder_outputs,\n","            key=encoder_outputs,\n","            attention_mask=padding_mask,\n","        )\n","        out_2 = self.layernorm_2(out_1 + attention_output_2)\n","\n","        proj_output = self.dense_proj(out_2)\n","        return self.layernorm_3(out_2 + proj_output)\n","\n","    def get_causal_attention_mask(self, inputs):\n","        input_shape = tf.shape(inputs)\n","        batch_size, sequence_length = input_shape[0], input_shape[1]\n","        i = tf.range(sequence_length)[:, tf.newaxis]\n","        j = tf.range(sequence_length)\n","        mask = tf.cast(i >= j, dtype=\"int32\")\n","        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n","        mult = tf.concat(\n","            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n","            axis=0,\n","        )\n","        return tf.tile(mask, mult)\n"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WCD0jPjqa-w4"},"source":["Next, we assemble the end-to-end model."]},{"cell_type":"code","metadata":{"id":"PaxOj5PWa-w5","executionInfo":{"status":"ok","timestamp":1630098767744,"user_tz":-180,"elapsed":1347,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["embed_dim = 256\n","latent_dim = 2048\n","num_heads = 8\n","\n","encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n","x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n","encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n","encoder = keras.Model(encoder_inputs, encoder_outputs)\n","\n","decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n","encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n","x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n","# x = layers.Dropout(0.5)(x)\n","\n","x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n","\n","x = layers.Dropout(0.5)(x)\n","decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n","# x = layers.Dropout(0.2)(x)\n","\n","decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n","\n","decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n","transformer = keras.Model(\n","    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",")"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9dFxoe3ma-w5"},"source":["## Training our model\n","\n","We'll use accuracy as a quick way to monitor training progress on the validation data.\n","Note that machine translation typically uses BLEU scores as well as other metrics, rather than accuracy.\n","\n","Here we only train for 1 epoch, but to get the model to actually converge\n","you should train for at least 30 epochs."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8tGD8iZLa-w6","executionInfo":{"status":"ok","timestamp":1630098909694,"user_tz":-180,"elapsed":141953,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"d316ce20-7012-4301-d55d-5201377ae5c6"},"source":["epochs = 30  # This should be at least 30 for convergence\n","my_callbacks = [\n","    tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=2),\n","    # tf.keras.callbacks.ReduceLROnPlateau(\n","    #   monitor='val_loss', factor=0.1, patience=2,\n","    #   min_lr=0,\n","    # )\n","]\n","\n","transformer.summary()\n","transformer.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",")\n","\n","history  = transformer.fit(train_ds, epochs=epochs, validation_data=val_ds,callbacks=my_callbacks)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Model: \"transformer\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","encoder_inputs (InputLayer)     [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","positional_embedding (Positiona (None, None, 256)    376320      encoder_inputs[0][0]             \n","__________________________________________________________________________________________________\n","decoder_inputs (InputLayer)     [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","transformer_encoder (Transforme (None, None, 256)    3155456     positional_embedding[0][0]       \n","__________________________________________________________________________________________________\n","model_1 (Functional)            (None, None, 1450)   6008490     decoder_inputs[0][0]             \n","                                                                 transformer_encoder[0][0]        \n","==================================================================================================\n","Total params: 9,540,266\n","Trainable params: 9,540,266\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/30\n","17/17 [==============================] - 32s 2s/step - loss: 0.2363 - accuracy: 0.7179 - val_loss: 0.0884 - val_accuracy: 0.7781\n","Epoch 2/30\n","17/17 [==============================] - 28s 2s/step - loss: 0.0921 - accuracy: 0.7624 - val_loss: 0.0821 - val_accuracy: 0.7689\n","Epoch 3/30\n","17/17 [==============================] - 28s 2s/step - loss: 0.0963 - accuracy: 0.7572 - val_loss: 0.0867 - val_accuracy: 0.7689\n","Epoch 4/30\n","17/17 [==============================] - 28s 2s/step - loss: 0.0561 - accuracy: 0.8874 - val_loss: 0.1367 - val_accuracy: 0.7735\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":312},"id":"AoxqTnCF_2tK","executionInfo":{"status":"ok","timestamp":1630098924856,"user_tz":-180,"elapsed":15182,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"f3d190c4-4e0a-4892-f73c-20d93539af85"},"source":["import matplotlib.pyplot as plt\n","\n","s, (at, al) = plt.subplots(2,1)\n","at.plot(history.history['accuracy'], c= 'b')\n","at.plot(history.history['val_accuracy'], c='r')\n","at.set_title('model accuracy')\n","at.set_ylabel('accuracy')\n","at.set_xlabel('epoch')\n","at.legend(['train', 'val'], loc='upper left')\n","\n","al.plot(history.history['loss'], c='m')\n","al.plot(history.history['val_loss'], c='c')\n","al.set_title('model loss')\n","al.set_ylabel('loss')\n","al.set_xlabel('epoch')\n","al.legend(['train', 'val'], loc = 'upper left')"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7f28f6498410>"]},"metadata":{},"execution_count":14},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"SL-vwLH1a-w6"},"source":["## Decoding test sentences\n","\n","Finally, let's demonstrate how to translate brand new English sentences.\n","We simply feed into the model the vectorized English sentence\n","as well as the target token `\"[start]\"`, then we repeatedly generated the next token, until\n","we hit the token `\"[end]\"`."]},{"cell_type":"code","metadata":{"id":"okeujBqTa-w6","executionInfo":{"status":"ok","timestamp":1630098924857,"user_tz":-180,"elapsed":16,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["spa_vocab = targ_vectorization.get_vocabulary()\n","spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n","max_decoded_sentence_length = 20\n","\n","\n","def decode_sequence(input_sentence):\n","    tokenized_input_sentence = inp_vectorization([input_sentence])\n","    decoded_sentence = \"[start]\"\n","    for i in range(max_decoded_sentence_length):\n","        tokenized_target_sentence = targ_vectorization([decoded_sentence])[:, :-1]\n","        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n","\n","        sampled_token_index = np.argmax(predictions[0, i, :])\n","        sampled_token = spa_index_lookup[sampled_token_index]\n","        decoded_sentence += \" \" + sampled_token\n","\n","        if sampled_token == \"[end]\":\n","            break\n","    return decoded_sentence\n","\n","\n"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"qZlMgW0dnxno","executionInfo":{"status":"ok","timestamp":1630098924857,"user_tz":-180,"elapsed":15,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# from nltk.translate.bleu_score import corpus_bleu\n","# from nltk.translate.bleu_score import sentence_bleu\n","# predicted_list = []\n","# test_inp_texts = [pair[0] for pair in test_pairs]\n","# test_targ_texts = [pair[1] for pair in test_pairs]\n","\n","# score_list = []\n","# from nltk.translate.bleu_score import SmoothingFunction\n","# # print(len(test_inp_texts))\n","# # print(len(test_targ_texts))\n","# # def bleu_score():\n","\n","# for i,j in zip(test_inp_texts,test_targ_texts):\n","\n","#   input_sentence = test_inp_texts\n","#     # print(input_sentence[i])\n","#   translated = decode_sequence(i)\n","#   predicted = list(translated.split(\",\"))\n","#   score = sentence_bleu(i, translated, weights=(1, 0, 0, 0))\n","#   score_list.append(score)\n","#   predicted_list.append(predicted)\n","#   print(\"Input:\",i,\"\\n Actual\",j,\"\\n Predicted\",translated)\n","#   score = sentence_bleu(i, translated, weights=(1, 0, 0, 0))\n","#   print(\"blue score : \",score,\"\\n\\n\")\n","# avg = sum(score_list) / len(score_list)\n","# print(\"Average of the list =\", round(avg, 2))\n","\n","#   # return bleu_dic\n","\n","\n","# # bleu_score()\n","# # bleu_test"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"hiKXV65HxspA","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1630098957597,"user_tz":-180,"elapsed":32755,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"c6a16767-3776-4ced-97b6-48f320a100ce"},"source":["from nltk.translate.bleu_score import corpus_bleu\n","from nltk.translate.bleu_score import sentence_bleu\n","predicted_list = []\n","test_inp_texts = [pair[0] for pair in test_pairs]\n","test_targ_texts = [pair[1] for pair in test_pairs]\n","\n","score_list = []\n","score_list_2 = []\n","score_list_3 = []\n","score_list_4 = []\n","from nltk.translate.bleu_score import SmoothingFunction\n","# print(len(test_inp_texts))\n","# print(len(test_targ_texts))\n","# def bleu_score():\n","\n","for i,j in zip(test_inp_texts,test_targ_texts):\n","\n","  input_sentence = test_inp_texts\n","    # print(input_sentence[i])\n","  translated = decode_sequence(i)\n","  predicted = list(translated.split(\",\"))\n","  # score = sentence_bleu(i, translated, weights=(1, 0, 0, 0))\n","  score_1 = sentence_bleu(i, translated, weights=(1, 0, 0, 0))\n","  score_2 = sentence_bleu(i, translated,weights=(0.5, 0.5, 0, 0))\n","  score_3 = sentence_bleu(i, translated, weights=(0.33, 0.33, 0.33, 0))\n","  score_4 = sentence_bleu(i, translated, weights=(0.25, 0.25, 0.25, 0.25))\n","  score_list.append(score_1)\n","  score_list_2.append(score_2)\n","  score_list_3.append(score_3)\n","  score_list_4.append(score_4)\n","  predicted_list.append(predicted)\n","  print(\"Input:\",i,\"\\n Actual\",j,\"\\n Predicted\",translated)\n","  # score_1 = sentence_bleu(i, translated, weights=(1, 0, 0, 0))\n","  # score_2 = sentence_bleu(i, translated,weights=(0.5, 0.5, 0, 0))\n","  # score_3 = sentence_bleu(i, translated, weights=(0.33, 0.33, 0.33, 0))\n","  # score_4 = sentence_bleu(i, translated, weights=(0.25, 0.25, 0.25, 0.25))\n","  print(\"blue 1-gram : \",score_1,\"\\n\",\"blue 2-gram : \",score_2,\"\\n\",\"blue 3-gram : \",score_3,\"\\n\",\"blue 4-gram : \",score_4,\"\\n\")\n","avg = sum(score_list) / len(score_list)\n","avg_2 = sum(score_list_2) / len(score_list_2)\n","avg_3 = sum(score_list_3) / len(score_list_3)\n","avg_4 = sum(score_list_4) / len(score_list_4)\n","print(\"Average of the list 1-gram=\", round(avg, 2),\"Average of the list 2-gram=\", round(avg_2, 2),\"Average of the list 3-gram=\", \n","      round(avg_3, 2),\"Average of the list 4-gram=\", round(avg_4, 2))\n","\n","  # return bleu_dic\n","\n","\n","# bleu_score()\n","# bleu_test"],"execution_count":17,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 2-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n"],"name":"stderr"},{"output_type":"stream","text":["Input: Ÿäÿß ŸáŸÑÿßŸÑŸäŸá Ÿäÿß ŸÖŸÜÿßŸÅŸÇŸäŸÜ ŸÅÿ¨ÿ£Ÿá ÿ™ÿ≠ÿ®ŸàŸÜ ÿßŸÑÿßÿ™ÿ≠ÿßÿØÿü \n"," Actual [start] Ÿäÿß ŸáŸÑÿßŸÑŸäŸá Ÿäÿß ******* ŸÅÿ¨ÿ£Ÿá ÿ™ÿ≠ÿ®ŸàŸÜ ÿßŸÑÿßÿ™ÿ≠ÿßÿØÿü [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.02941176470588235 \n"," blue 2-gram :  0.17149858514250882 \n"," blue 3-gram :  0.3123287459051282 \n"," blue 4-gram :  0.41412387656655203 \n","\n","Input: Ÿäÿß ŸÖÿ∫ŸÅŸÑ Ÿäÿß ÿ™ŸÜŸÉŸá ÿßŸÇÿ∑ÿπ ŸàÿßÿÆÿ≥ ŸàÿßŸÅŸáŸÖ ÿ≥ŸäÿßŸÇ ÿßŸÑŸÉŸÑÿßŸÖ ŸÉŸÜÿ™ ÿ£ÿ™ŸÉŸÑŸÖ ÿπŸÜ ŸÉŸÑ ŸÖŸÑÿ™ÿ≠Ÿä ŸÖÿ™ÿ¥ÿØÿØ ÿßÿÆŸàŸÜÿ¨Ÿä ÿ∫ÿ±ÿ∂Ÿá ÿ≥ŸÑÿ∑ŸàŸä ÿÆÿ®Ÿäÿ´ ÿßŸÇŸÑÿ® Ÿàÿ¨ŸáŸÉ ÿ®ÿ≥ Ÿàÿ™ŸÇŸÑÿπ \n"," Actual [start] Ÿäÿß **** Ÿäÿß **** ÿßŸÇÿ∑ÿπ ŸàÿßÿÆÿ≥ ŸàÿßŸÅŸáŸÖ ÿ≥ŸäÿßŸÇ ÿßŸÑŸÉŸÑÿßŸÖ ŸÉŸÜÿ™ ÿ£ÿ™ŸÉŸÑŸÖ ÿπŸÜ ŸÉŸÑ ŸÖŸÑÿ™ÿ≠Ÿä ŸÖÿ™ÿ¥ÿØÿØ ****** ÿ∫ÿ±ÿ∂Ÿá ÿ≥ŸÑÿ∑ŸàŸä **** ÿßŸÇŸÑÿ® Ÿàÿ¨ŸáŸÉ ÿ®ÿ≥ Ÿà**** [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.02941176470588235 \n"," blue 2-gram :  0.17149858514250882 \n"," blue 3-gram :  0.3123287459051282 \n"," blue 4-gram :  0.41412387656655203 \n","\n","Input: ŸàŸÑÿØ ÿπŸÖŸä Ÿäÿß ÿµÿ±ÿµÿ±Ÿä ŸÅÿßŸÑÿßÿÆŸäÿ± ÿßŸÜŸä ÿ®ÿ£ÿ≥ŸÖŸä Ÿà ÿµŸàÿ±ÿ™Ÿä Ÿäÿß ŸàŸáŸÖŸä Ÿäÿß ŸÖÿ±Ÿäÿ∂ ÿ®ÿ±ÿß ŸÜŸäŸÉ \n"," Actual [start] ŸàŸÑÿØ ÿπŸÖŸä Ÿäÿß ***** ŸÅÿßŸÑÿßÿÆŸäÿ± ÿßŸÜŸä ÿ®ÿ£ÿ≥ŸÖŸä Ÿà ÿµŸàÿ±ÿ™Ÿä Ÿäÿß **** Ÿäÿß **** ÿ®ÿ±ÿß *** [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.02941176470588235 \n"," blue 2-gram :  0.17149858514250882 \n"," blue 3-gram :  0.3123287459051282 \n"," blue 4-gram :  0.41412387656655203 \n","\n","Input: üòÇüòÇüòÇüòÇ ÿØÿπŸÖ ÿßŸäŸá Ÿäÿß ŸÖŸÜÿ≠Ÿàÿ≥ Ÿäÿß ÿ¥ÿ≠ÿßÿ™ . ŸàŸÑÿß ŸäŸÖŸÉŸÜ ÿßŸÑÿØÿπŸÖ ÿ®ŸÖÿπŸÑŸàŸÖÿßÿ™ ŸÉŸäŸÅŸäÿ© ÿπŸÖŸÑ ÿßŸÑÿßŸÜŸÇŸÑÿßÿ® \n"," Actual [start] üòÇüòÇüòÇüòÇ ÿØÿπŸÖ ÿßŸäŸá Ÿäÿß ***** Ÿäÿß **** . ŸàŸÑÿß ŸäŸÖŸÉŸÜ ÿßŸÑÿØÿπŸÖ ÿ®ŸÖÿπŸÑŸàŸÖÿßÿ™ ŸÉŸäŸÅŸäÿ© ÿπŸÖŸÑ ÿßŸÑÿßŸÜŸÇŸÑÿßÿ® [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.02941176470588235 \n"," blue 2-gram :  0.17149858514250882 \n"," blue 3-gram :  0.3123287459051282 \n"," blue 4-gram :  0.41412387656655203 \n","\n","Input: ÿ≠ŸÖÿØŸÑŸÑŸá ÿπ ÿ≥ŸÑÿßŸÖÿ™ŸÉ Ÿäÿß ÿ≥ÿßŸÅŸÑŸá Ÿäÿß ÿ≥ŸáŸÑÿ© Ÿäÿß ÿ±ÿÆŸäÿµÿ©üòÇ‚ô•Ô∏è \n"," Actual [start] ÿ≠ŸÖÿØŸÑŸÑŸá ÿπ ÿ≥ŸÑÿßŸÖÿ™ŸÉ Ÿäÿß ***** Ÿäÿß **** Ÿäÿß *****üòÇ‚ô•Ô∏è [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.02941176470588235 \n"," blue 2-gram :  0.17149858514250882 \n"," blue 3-gram :  0.3123287459051282 \n"," blue 4-gram :  0.41412387656655203 \n","\n","Input: ŸäŸÜÿπŸÑ ÿßŸÑÿ∞Ÿä ÿ±ÿ®ÿßÿ¥ Ÿäÿß ŸàÿµÿÆŸá Ÿäÿß ÿ¨ŸäŸÅŸá ÿ™ŸÅ ÿπ Ÿàÿ¨ŸáŸÉ ŸàÿπÿßÿØŸá ÿ∫ÿßŸÑŸäŸá ÿπŸÑŸäŸÉ Ÿäÿß ÿµŸÜÿØŸÑ \n"," Actual [start] **** ÿßŸÑÿ∞Ÿä ÿ±ÿ®ÿßÿ¥ Ÿäÿß **** Ÿäÿß **** ** ÿπ Ÿàÿ¨ŸáŸÉ ŸàÿπÿßÿØŸá ÿ∫ÿßŸÑŸäŸá ÿπŸÑŸäŸÉ Ÿäÿß **** [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.02941176470588235 \n"," blue 2-gram :  0.17149858514250882 \n"," blue 3-gram :  0.3123287459051282 \n"," blue 4-gram :  0.41412387656655203 \n","\n","Input: ÿßŸÑÿµŸáÿßŸäŸÜÿ© ÿßŸÜÿ™ŸÖ Ÿäÿß ÿÆŸàŸÜÿ© Ÿäÿß ŸÇÿ™ŸÑÿ© ÿßŸÑÿ£ÿ∑ŸÅÿßŸÑ ŸàŸÖÿÆÿ±ÿ®ŸäŸÜ ŸÑŸÖ ÿ™ÿ™ÿ±ŸÉŸàÿß ÿ®ŸÑÿØ ÿßŸÑÿß ŸàÿÆÿ±ÿ®ÿ™ŸÖŸàŸá ÿ®ŸÖÿπŸäÿ© ÿßŸÑŸÖÿ±ÿ™ÿ≤ŸÇÿ© ŸÑÿπŸÜÿ© ÿßŸÑŸÑŸá ÿπŸÑŸäŸÉŸÖ Ÿäÿß ÿ≤ŸÜÿßÿØŸÇÿ© ÿßŸÜÿß ÿßÿπŸäÿ¥ ŸÅŸä ÿßŸÑÿ¨ÿ≤ÿßÿ¶ÿ± üá©üáø ŸàŸÑÿß ÿ≠ÿßÿ¨ÿ© ŸÑŸä ŸÅŸä ŸÖÿßŸÑŸÉŸÖ ÿßŸÑŸÇÿ∞ÿ± \n"," Actual [start] ÿßŸÑÿµŸáÿßŸäŸÜÿ© ÿßŸÜÿ™ŸÖ Ÿäÿß **** Ÿäÿß **** ÿßŸÑÿ£ÿ∑ŸÅÿßŸÑ Ÿà****** ŸÑŸÖ ÿ™ÿ™ÿ±ŸÉŸàÿß ÿ®ŸÑÿØ ÿßŸÑÿß ŸàÿÆÿ±ÿ®ÿ™ŸÖŸàŸá ÿ®ŸÖÿπŸäÿ© ******** **** ÿßŸÑŸÑŸá ÿπŸÑŸäŸÉŸÖ Ÿäÿß ****** ÿßŸÜÿß ÿßÿπŸäÿ¥ ŸÅŸä ÿßŸÑÿ¨ÿ≤ÿßÿ¶ÿ± üá©üáø ŸàŸÑÿß ÿ≠ÿßÿ¨ÿ© ŸÑŸä ŸÅŸä ŸÖÿßŸÑŸÉŸÖ ***** [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.02941176470588235 \n"," blue 2-gram :  0.17149858514250882 \n"," blue 3-gram :  0.3123287459051282 \n"," blue 4-gram :  0.41412387656655203 \n","\n","Input: Ÿäÿß ÿ¨ÿ±Ÿàÿ≥ Ÿäÿß ÿ≠ŸÖÿßÿ±ÿ´ÿßŸÑÿ™ ,,ÿ¥ŸÅÿ™ ÿßÿ®ÿ±ÿßŸáŸäŸÖ ÿ≠ÿ≥ŸÜ ÿ®ŸäÿßŸÉŸÑ ÿßŸÑŸÜÿ¨ŸäŸÑŸá ÿßÿ≤ÿßŸä ŸÑŸÖÿß ÿ≠ÿ≥ ÿßŸÜ ŸÖŸÉÿßŸÜŸá ÿßÿ™ŸáÿØÿØ ÿ®Ÿàÿ¨ŸàÿØ ÿ≤Ÿäÿ≤Ÿà ,,ÿßŸàÿ®ÿßŸÖÿß ŸàŸÉŸáÿ±ÿ®ÿß ÿπÿßŸäÿ≤ŸäŸÜ ŸäŸÇÿπÿØŸàÿß ÿ¥ŸàŸäŸá \n"," Actual [start] Ÿäÿß **** Ÿäÿß ****ÿ´ÿßŸÑÿ™ ,,ÿ¥ŸÅÿ™ ÿßÿ®ÿ±ÿßŸáŸäŸÖ ÿ≠ÿ≥ŸÜ ÿ®ŸäÿßŸÉŸÑ ÿßŸÑŸÜÿ¨ŸäŸÑŸá ÿßÿ≤ÿßŸä ŸÑŸÖÿß ÿ≠ÿ≥ ÿßŸÜ ŸÖŸÉÿßŸÜŸá ÿßÿ™ŸáÿØÿØ ÿ®Ÿàÿ¨ŸàÿØ ÿ≤Ÿäÿ≤Ÿà ,,ÿßŸàÿ®ÿßŸÖÿß ŸàŸÉŸáÿ±ÿ®ÿß ÿπÿßŸäÿ≤ŸäŸÜ ŸäŸÇÿπÿØŸàÿß ÿ¥ŸàŸäŸá [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.02941176470588235 \n"," blue 2-gram :  0.17149858514250882 \n"," blue 3-gram :  0.3123287459051282 \n"," blue 4-gram :  0.41412387656655203 \n","\n","Input: ÿ≠ÿ±ŸäŸÖ ÿßŸÑÿ≥ŸÑÿ∑ÿßŸÜ ÿßŸÖÿ´ÿßŸÑŸÉ ŸÖÿ¨ÿ±ÿØ ÿ∞ŸÉÿ± ÿ≥ŸäÿØŸáŸÖ ÿßŸÑÿ≥Ÿäÿ≥Ÿâ Ÿäÿ¨ŸäŸÑŸáŸÖ ÿ™ÿ®ŸàŸÑ ŸÑÿß ÿßÿ±ÿßÿØŸâ ÿßŸÜÿµÿ≠ŸÉ ÿ™ÿ±Ÿàÿ≠ ÿπŸÜ ŸàŸÑŸâ ŸÜÿπŸÖÿ™ŸÉ ÿßŸÑŸÇÿ±ÿØŸàÿ∫ÿßŸÜ ÿ™ŸÖÿßÿ±ÿ≥ ÿßŸÑÿ¥ÿ∞Ÿàÿ∞ ÿπŸÜÿØŸá ÿØÿß ÿÆŸÑŸäŸÅÿ™ŸÉŸÖ ÿßŸÑŸÖŸÜÿ¥ŸàÿØ Ÿäÿß ÿ£ŸÅÿßŸÇ Ÿäÿß ŸÖÿØŸÑÿ≥ Ÿäÿß ÿ™ÿßÿ¨ÿ± ÿßŸÑÿØŸäŸÜ Ÿäÿß ÿ±ÿßÿπŸâ ÿßŸÑÿÆÿ±ÿßÿ® \n"," Actual [start] ÿ≠ÿ±ŸäŸÖ ÿßŸÑÿ≥ŸÑÿ∑ÿßŸÜ ÿßŸÖÿ´ÿßŸÑŸÉ ŸÖÿ¨ÿ±ÿØ ÿ∞ŸÉÿ± ÿ≥ŸäÿØŸáŸÖ ÿßŸÑÿ≥Ÿäÿ≥Ÿâ Ÿäÿ¨ŸäŸÑŸáŸÖ **** ŸÑÿß ÿßÿ±ÿßÿØŸâ ÿßŸÜÿµÿ≠ŸÉ ÿ™ÿ±Ÿàÿ≠ ÿπŸÜ ŸàŸÑŸâ ŸÜÿπŸÖÿ™ŸÉ ********* ÿ™ŸÖÿßÿ±ÿ≥ ****** ÿπŸÜÿØŸá ÿØÿß ÿÆŸÑŸäŸÅÿ™ŸÉŸÖ ÿßŸÑŸÖŸÜÿ¥ŸàÿØ Ÿäÿß ÿ£ŸÅÿßŸÇ Ÿäÿß **** Ÿäÿß ÿ™ÿßÿ¨ÿ± ÿßŸÑÿØŸäŸÜ Ÿäÿß ÿ±ÿßÿπŸâ ****** [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.02941176470588235 \n"," blue 2-gram :  0.17149858514250882 \n"," blue 3-gram :  0.3123287459051282 \n"," blue 4-gram :  0.41412387656655203 \n","\n","Input: Popular opinion: ÿßŸÑÿ®ŸÜÿ∑ŸÑŸàŸÜ ÿ≥ÿßÿ™ÿ± ÿßŸÉÿ™ÿ± ŸÖŸÜ ÿßŸÑÿßÿ≥ŸÉŸäÿ±ÿ™ Ÿäÿß ÿ®ÿ¨ŸÖ Ÿäÿß ÿ≥ÿ¨ŸÖ Ÿäÿß ÿπÿ¨ŸÖ Ÿäÿß ŸÜÿ¨ŸÖ \n"," Actual [start] Popular opinion: ÿßŸÑÿ®ŸÜÿ∑ŸÑŸàŸÜ ÿ≥ÿßÿ™ÿ± ÿßŸÉÿ™ÿ± ŸÖŸÜ ÿßŸÑÿßÿ≥ŸÉŸäÿ±ÿ™ Ÿäÿß *** Ÿäÿß *** Ÿäÿß *** Ÿäÿß *** [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.11764705882352941 \n"," blue 2-gram :  0.3429971702850177 \n"," blue 3-gram :  0.49350522429506183 \n"," blue 4-gram :  0.5856596027429395 \n","\n","Input: ÿßŸÑÿÆŸÑŸäÿ¨ ÿπÿ±ÿ®Ÿä Ÿäÿß ÿ®ŸáŸäŸÖÿ© ŸàŸÑŸäÿ≥ ŸÅÿßÿ±ÿ≥Ÿä Ÿäÿß ŸÖÿ¨Ÿàÿ≥Ÿä Ÿäÿß ÿÆŸÜÿ≤Ÿäÿ± \n"," Actual [start] ÿßŸÑÿÆŸÑŸäÿ¨ ÿπÿ±ÿ®Ÿä Ÿäÿß ***** ŸàŸÑŸäÿ≥ ŸÅÿßÿ±ÿ≥Ÿä Ÿäÿß ***** Ÿäÿß ***** [end] \n"," Predicted [start] ***** [en]                  \n","blue 1-gram :  0.02777777777777778 \n"," blue 2-gram :  0.16666666666666669 \n"," blue 3-gram :  0.3064927280413241 \n"," blue 4-gram :  0.408248290463863 \n","\n","Input: ÿßŸÑŸÖŸáŸÖ ŸäÿπŸÜŸâ ÿßÿπŸÖŸÑŸà ÿßŸä ÿ≠ÿßÿ¨Ÿá Ÿà ŸÇŸàŸÑŸà ÿßŸâ ŸÉŸÑÿßŸÖ Ÿà ŸÖÿ™ÿ¨Ÿäÿ®Ÿàÿ¥ ÿ≥Ÿäÿ±ÿ© ÿßŸÑÿ≤ŸÖÿßŸÑŸÉ Ÿà ŸÑÿß ÿ¨ŸÖŸáŸàÿ±Ÿá ÿπŸÑÿ¥ÿßŸÜ ÿØŸàŸÑ ÿßŸÜÿ∂ŸÅ ŸÖŸÜŸÉŸÖ ÿ®ÿ≥ŸÜŸäŸÜ ÿ∂Ÿàÿ¶Ÿäÿ© Ÿà ÿßŸÑÿ≤ŸÖÿßŸÑŸÉ ÿßŸÜÿ∂ŸÅ Ÿà ÿßÿ±ŸÅÿπ ŸÖŸÜ ÿßŸÑÿ™Ÿáÿ≤ŸäŸÇ ÿ®ÿ™ÿßÿπ ŸÜÿßÿØŸäŸÉŸÖ ÿØÿß Ÿäÿß ŸÖŸáÿ≤ŸÇŸäŸÜ Ÿäÿß ÿ®ÿ™Ÿàÿπ ÿßŸÑÿÆŸÖÿ≥ÿ© üòÇ \n"," Actual [start] ÿßŸÑŸÖŸáŸÖ ŸäÿπŸÜŸâ ÿßÿπŸÖŸÑŸà ÿßŸä ÿ≠ÿßÿ¨Ÿá Ÿà ŸÇŸàŸÑŸà ÿßŸâ ŸÉŸÑÿßŸÖ Ÿà ŸÖÿ™ÿ¨Ÿäÿ®Ÿàÿ¥ ÿ≥Ÿäÿ±ÿ© ÿßŸÑÿ≤ŸÖÿßŸÑŸÉ Ÿà ŸÑÿß ÿ¨ŸÖŸáŸàÿ±Ÿá ÿπŸÑÿ¥ÿßŸÜ ÿØŸàŸÑ ÿßŸÜÿ∂ŸÅ ŸÖŸÜŸÉŸÖ ÿ®ÿ≥ŸÜŸäŸÜ ÿ∂Ÿàÿ¶Ÿäÿ© Ÿà ÿßŸÑÿ≤ŸÖÿßŸÑŸÉ ÿßŸÜÿ∂ŸÅ Ÿà ÿßÿ±ŸÅÿπ ŸÖŸÜ ******* ÿ®ÿ™ÿßÿπ ŸÜÿßÿØŸäŸÉŸÖ ÿØÿß Ÿäÿß ****** Ÿäÿß ÿ®ÿ™Ÿàÿπ ÿßŸÑÿÆŸÖÿ≥ÿ© üòÇ [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.02941176470588235 \n"," blue 2-gram :  0.17149858514250882 \n"," blue 3-gram :  0.3123287459051282 \n"," blue 4-gram :  0.41412387656655203 \n","\n","Input: Ÿäÿß ÿ®ŸÜ ÿπŸàŸÅ Ÿäÿß ŸÖÿ≥ŸÑŸàÿ® ŸÖÿß ÿ®Ÿäÿ≠ŸÉŸÖŸÜÿß ÿ±ÿ¶Ÿäÿ≥ ŸÖÿ∑ŸÑŸàÿ® .. #ÿßÿ≥ÿ™ŸÖÿ±ÿßÿ±_ÿßÿπÿ™ÿµÿßŸÖ_ÿßŸÑŸÇŸäÿßÿØÿ©_ÿßŸÑÿπÿßŸÖÿ© #ÿ™ÿ≥ŸÇÿ∑_ÿ™ÿßŸÜŸä_ÿ®ÿ≥ \n"," Actual [start] Ÿäÿß ÿ®ŸÜ ÿπŸàŸÅ Ÿäÿß ***** ŸÖÿß ÿ®Ÿäÿ≠ŸÉŸÖŸÜÿß ÿ±ÿ¶Ÿäÿ≥ ŸÖÿ∑ŸÑŸàÿ® .. #ÿßÿ≥ÿ™ŸÖÿ±ÿßÿ±_ÿßÿπÿ™ÿµÿßŸÖ_ÿßŸÑŸÇŸäÿßÿØÿ©_ÿßŸÑÿπÿßŸÖÿ© #ÿ™ÿ≥ŸÇÿ∑_ÿ™ÿßŸÜŸä_ÿ®ÿ≥ [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.02941176470588235 \n"," blue 2-gram :  0.17149858514250882 \n"," blue 3-gram :  0.3123287459051282 \n"," blue 4-gram :  0.41412387656655203 \n","\n","Input: ŸÑŸäÿ¥ ŸÖÿ™ÿßŸÉŸÑ ÿÆÿ±ÿ© ÿßŸÜÿ™ÿ© ŸàÿπŸÖÿ± ÿßÿ®ŸÜ ÿßŸÑÿµŸáÿßŸÑ ÿßÿ®ŸÜ ÿßŸÑÿ®ÿ∫ÿßŸäÿß ÿßÿ¥ÿØ ÿ∫Ÿäÿ±ÿ© ŸÖŸÜ ÿ±ÿ≥ŸàŸÑ ÿßŸÑŸÑŸá ÿµŸÑ ÿßŸÑŸÑŸá ÿπŸÑŸäŸá ŸàÿßŸÑŸá Ÿàÿ≥ŸÑŸÖ Ÿäÿß ŸÇÿ∞ÿßÿ±ÿ© ÿßŸÑÿ®ÿ¥ÿ± Ÿäÿß ŸäŸáŸàÿØ ÿßŸÑÿ£ŸÖÿ© ŸÑÿπŸÜŸÉ ÿßŸÑŸÑŸá ŸàŸÑÿπŸÜ ÿØŸäŸÜŸÉŸÖ ÿßŸÑŸÇÿ∞ÿ± ŸàŸÑÿπŸÜÿ™ ÿßŸÑŸÑŸá ÿπŸÖÿ± ÿßÿ®ŸÜ ÿßŸÑÿµŸáÿßŸÉ Ÿäÿß Ÿàÿßÿ®Ÿà ÿ®ŸÇÿ± \n"," Actual [start] ŸÑŸäÿ¥ ŸÖÿ™ÿßŸÉŸÑ *** ÿßŸÜÿ™ÿ© ŸàÿπŸÖÿ± ÿßÿ®ŸÜ ****** ÿßÿ®ŸÜ ******* ÿßÿ¥ÿØ **** ŸÖŸÜ ÿ±ÿ≥ŸàŸÑ ÿßŸÑŸÑŸá ÿµŸÑ ÿßŸÑŸÑŸá ÿπŸÑŸäŸá ŸàÿßŸÑŸá Ÿàÿ≥ŸÑŸÖ Ÿäÿß ***** ÿßŸÑÿ®ÿ¥ÿ± Ÿäÿß **** ÿßŸÑÿ£ŸÖÿ© **** ÿßŸÑŸÑŸá Ÿà*** ÿØŸäŸÜŸÉŸÖ ***** ŸàŸÑÿπŸÜÿ™ ÿßŸÑŸÑŸá ÿπŸÖÿ± ÿßÿ®ŸÜ ÿßŸÑÿµŸáÿßŸÉ Ÿäÿß Ÿàÿßÿ®Ÿà *** [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.02941176470588235 \n"," blue 2-gram :  0.17149858514250882 \n"," blue 3-gram :  0.3123287459051282 \n"," blue 4-gram :  0.41412387656655203 \n","\n","Input: #ŸÇÿ∑ÿ±_ÿ≠ŸÑŸäŸÅÿ©_ÿßŸÑÿ¥Ÿäÿ∑ÿßŸÜ ŸáŸä ŸÖŸÜ ÿ™ÿ≥ÿßÿπÿØ ÿßÿ≥ÿ±ÿßÿ¶ŸäŸÑ ŸàÿßŸÖÿ±ŸäŸÉÿß ŸÑÿ™ÿ≠ŸÇŸäŸÇ ÿµŸÅŸÇÿ© ÿßŸÑŸÇÿ±ŸÜ Ÿäÿß ÿπÿ®ÿØÿßŸÑŸÑŸá ÿßŸÑÿπÿ∞ÿ®ÿ© Ÿäÿß Ÿàÿ¨Ÿá ÿßŸÑÿπŸÜÿ≤ÿ© ŸàŸÑŸÉŸÜ ŸÖÿßŸÅÿ¥ÿ±ÿ™Ÿà ÿ∑ŸàŸÑ,ŸÖÿßŸÅŸä ŸÇÿßÿØÿ© ÿßŸÖÿ´ÿßŸÑ,ÿßÿ®ŸàŸÅÿßÿØŸä ŸÑŸÜ Ÿäÿ≥ŸÖÿ≠ ŸÑŸÉŸÖ ÿ®ÿ™ÿ≠ŸÇŸäŸÇ ÿÆŸäÿßŸÜÿ™ŸÉŸÖ \n"," Actual [start] #ŸÇÿ∑ÿ±_ÿ≠ŸÑŸäŸÅÿ©_ÿßŸÑÿ¥Ÿäÿ∑ÿßŸÜ ŸáŸä ŸÖŸÜ ÿ™ÿ≥ÿßÿπÿØ ÿßÿ≥ÿ±ÿßÿ¶ŸäŸÑ ŸàÿßŸÖÿ±ŸäŸÉÿß ŸÑÿ™ÿ≠ŸÇŸäŸÇ ÿµŸÅŸÇÿ© ÿßŸÑŸÇÿ±ŸÜ Ÿäÿß ÿπÿ®ÿØÿßŸÑŸÑŸá ÿßŸÑÿπÿ∞ÿ®ÿ© Ÿäÿß Ÿàÿ¨Ÿá ****** ŸàŸÑŸÉŸÜ ŸÖÿßŸÅÿ¥ÿ±ÿ™Ÿà ÿ∑ŸàŸÑ,ŸÖÿßŸÅŸä ŸÇÿßÿØÿ© ÿßŸÖÿ´ÿßŸÑ,ÿßÿ®ŸàŸÅÿßÿØŸä ŸÑŸÜ Ÿäÿ≥ŸÖÿ≠ ŸÑŸÉŸÖ ÿ®ÿ™ÿ≠ŸÇŸäŸÇ ******* [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.02941176470588235 \n"," blue 2-gram :  0.17149858514250882 \n"," blue 3-gram :  0.3123287459051282 \n"," blue 4-gram :  0.41412387656655203 \n","\n","Input: ÿ∑ÿ®ÿπÿß ŸÖÿ¥ ŸáŸÜÿπÿ±ŸÅ ŸÜÿπŸäÿ¥ ŸÖŸÜ ÿ∫Ÿäÿ±ŸÉ Ÿäÿß ÿ®ŸÜÿ™ ŸÇŸÑÿ®Ÿâ Ÿäÿß ŸÉŸÑÿ®Ÿàÿ®Ÿá ÿßŸÜÿ™Ÿâ ŸÖÿ™ŸÇŸàŸÑŸäÿ¥ ŸÉÿØŸá ÿ™ÿßŸÜŸâ Ÿäÿß ŸÉŸÑÿ®Ÿàÿ®Ÿáüíûüíûüíûüíûüíûüíûüíûüíãüíãüíãüíãüíãüíã \n"," Actual [start] ÿ∑ÿ®ÿπÿß ŸÖÿ¥ ŸáŸÜÿπÿ±ŸÅ ŸÜÿπŸäÿ¥ ŸÖŸÜ ÿ∫Ÿäÿ±ŸÉ Ÿäÿß ÿ®ŸÜÿ™ ŸÇŸÑÿ®Ÿâ Ÿäÿß ****** **** ŸÖÿ™ŸÇŸàŸÑŸäÿ¥ ŸÉÿØŸá ÿ™ÿßŸÜŸâ Ÿäÿß ******üíûüíûüíûüíûüíûüíûüíûüíãüíãüíãüíãüíãüíã [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.02941176470588235 \n"," blue 2-gram :  0.17149858514250882 \n"," blue 3-gram :  0.3123287459051282 \n"," blue 4-gram :  0.41412387656655203 \n","\n","Input: ÿßŸÑŸÑŸá Ÿäÿß ÿÆÿ∞ŸÉ Ÿäÿß ŸÜŸÖŸÇ ÿå Ÿäÿ™ŸÅŸÑÿ≥ŸÅ ŸàŸáŸà ŸÖÿ´ŸÑ ÿßŸÑÿßÿØŸÑÿÆ ÿ®ÿ≥ ŸäŸÜŸÅÿ∞ ÿßŸàÿßŸÖÿ± ÿ≠ŸÖÿØ ÿ®ŸÜ ÿ¨ÿßÿ≥ŸÖ ÿ±ÿßÿ≥ ÿßŸÑÿ≠ŸäŸá ü§Æü§Æ \n"," Actual [start] ÿßŸÑŸÑŸá ***** Ÿäÿß *** ÿå ****** ŸàŸáŸà ŸÖÿ´ŸÑ ****** ÿ®ÿ≥ ŸäŸÜŸÅÿ∞ ÿßŸàÿßŸÖÿ± ÿ≠ŸÖÿØ ÿ®ŸÜ ÿ¨ÿßÿ≥ŸÖ ÿ±ÿßÿ≥ ***** ü§Æü§Æ [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.02941176470588235 \n"," blue 2-gram :  0.17149858514250882 \n"," blue 3-gram :  0.3123287459051282 \n"," blue 4-gram :  0.41412387656655203 \n","\n","Input: ÿÆŸÑŸäŸÉ ŸÅŸâ ÿßŸÉŸÑ ÿπŸäÿ¥ŸÉ Ÿäÿß ÿØŸÑÿØŸàŸÑ Ÿäÿß Ÿàÿ≥ÿÆ Ÿàÿ®ÿßŸÑŸÖŸÜÿßÿ≥ÿ®ÿ© ÿßÿÆÿ± ŸÖÿ±Ÿá ÿßŸÑÿ≤ŸÖÿßŸÑŸÉ ŸÅÿßÿ≤ ÿ®ÿßŸÅÿ±ŸäŸÇŸäÿß ŸÉŸÜÿ™ ÿßŸÜÿ™ ŸÑÿ≥Ÿá ÿ®ÿ™ÿ™ÿßÿÆÿØ ŸÅŸâ ÿßŸÑÿÆÿ±ÿßÿ®ÿßÿ™ üòÄ \n"," Actual [start] ÿÆŸÑŸäŸÉ ŸÅŸâ ÿßŸÉŸÑ ÿπŸäÿ¥ŸÉ Ÿäÿß ***** Ÿäÿß *** Ÿàÿ®ÿßŸÑŸÖŸÜÿßÿ≥ÿ®ÿ© ÿßÿÆÿ± ŸÖÿ±Ÿá ÿßŸÑÿ≤ŸÖÿßŸÑŸÉ ŸÅÿßÿ≤ ÿ®ÿßŸÅÿ±ŸäŸÇŸäÿß ŸÉŸÜÿ™ ÿßŸÜÿ™ ŸÑÿ≥Ÿá ÿ®ÿ™ÿ™ÿßÿÆÿØ ŸÅŸâ ******** üòÄ [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.02941176470588235 \n"," blue 2-gram :  0.17149858514250882 \n"," blue 3-gram :  0.3123287459051282 \n"," blue 4-gram :  0.41412387656655203 \n","\n","Input: ŸÉÿ≥ŸÖŸÉ Ÿäÿß ÿßÿ®ŸÜ ÿßŸÑÿπÿ±ÿµ Ÿäÿß ÿßŸÑŸÑŸä ÿßŸÖŸÉ ÿ≤ÿßŸÜŸäŸá ÿßŸáŸÑŸä ŸÖŸäŸäŸÜ ÿßŸÑŸÑŸä ŸÖÿ≥ÿ™ŸàÿßŸá ŸÉÿØŸá ŸàÿßŸáŸÑŸä ŸÖŸäŸäŸÜ ÿßŸÑŸÑŸä ÿßŸÑÿÆŸÉÿßŸÖ ÿ®ÿ™ÿ≥ÿßŸÜÿØŸá Ÿäÿß ÿßÿ®ŸÜ ÿßŸÑŸÖÿ±Ÿá ÿßŸÑŸÅÿßÿ¨ÿ±Ÿá \n"," Actual [start] **** Ÿäÿß ÿßÿ®ŸÜ ***** Ÿäÿß ÿßŸÑŸÑŸä ÿßŸÖŸÉ ***** ÿßŸáŸÑŸä ŸÖŸäŸäŸÜ ÿßŸÑŸÑŸä ŸÖÿ≥ÿ™ŸàÿßŸá ŸÉÿØŸá ŸàÿßŸáŸÑŸä ŸÖŸäŸäŸÜ ÿßŸÑŸÑŸä ÿßŸÑÿÆŸÉÿßŸÖ ÿ®ÿ™ÿ≥ÿßŸÜÿØŸá Ÿäÿß ÿßÿ®ŸÜ ÿßŸÑŸÖÿ±Ÿá ******* [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.02941176470588235 \n"," blue 2-gram :  0.17149858514250882 \n"," blue 3-gram :  0.3123287459051282 \n"," blue 4-gram :  0.41412387656655203 \n","\n","Input: ŸäÿπŸÜŸä Ÿäÿß ÿßŸäŸáÿßÿ® ÿ¨ŸÑÿßŸÑ Ÿäÿß ÿßÿ®ŸÜ ŸÉÿ≥ ÿßŸÑŸÜÿπÿ¨ÿ© ŸÖÿµÿØÿπ ŸÖŸäÿ™ŸäŸÜ ÿßŸáÿßŸÑŸäŸÜÿß ÿ®ÿßŸÑŸáÿ¨ŸàŸÖ Ÿàÿ®ÿßŸÑÿÆÿ±ÿß Ÿàÿ¨ÿßŸä ÿ™ÿπŸÖŸÑŸä ŸÖŸàÿ±ŸäŸÜŸäŸà ÿØŸÑŸàŸÇÿ™Ÿä \n"," Actual [start] ŸäÿπŸÜŸä Ÿäÿß ÿßŸäŸáÿßÿ® ÿ¨ŸÑÿßŸÑ Ÿäÿß ÿßÿ®ŸÜ ** ÿßŸÑŸÜÿπÿ¨ÿ© ŸÖÿµÿØÿπ ŸÖŸäÿ™ŸäŸÜ ÿßŸáÿßŸÑŸäŸÜÿß ÿ®ÿßŸÑŸáÿ¨ŸàŸÖ Ÿàÿ®***** Ÿàÿ¨ÿßŸä ÿ™ÿπŸÖŸÑŸä ŸÖŸàÿ±ŸäŸÜŸäŸà ÿØŸÑŸàŸÇÿ™Ÿä [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.02941176470588235 \n"," blue 2-gram :  0.17149858514250882 \n"," blue 3-gram :  0.3123287459051282 \n"," blue 4-gram :  0.41412387656655203 \n","\n","Input: * ÿßŸÜÿß ÿ¨ÿßŸäÿ® 60 % ŸàÿπÿßŸàÿ≤ ÿßÿ®ŸÇŸä ŸÖŸáŸÜÿØÿ≥ * ÿ≥Ÿäÿ® 8 ÿ™ŸÑÿßŸÅ ÿ¨ŸÜŸäŸá Ÿàÿ±Ÿàÿ≠ ÿπŸÑŸä ŸÖÿπŸáÿØ ÿ™ŸÇÿßŸàŸä ŸÑŸÑŸáŸÜÿØÿ≥Ÿá ŸàÿßŸÑÿ™ŸÉŸÜŸàŸÑŸàÿ¨Ÿäÿß ŸÇŸÑŸáŸÖ ÿßŸÜÿß ÿ¨ÿßŸäŸÑŸÉŸàÿß ŸÖŸÜ ÿ∑ÿ±ŸÅ ÿ≠ÿßÿ™ŸÖ ÿ®ÿßÿ¥ÿß * ÿ¥ŸÉÿ±ÿß Ÿäÿß ÿ®ÿßÿ¥ÿß * ÿßÿ≥ÿ™ŸÜŸä Ÿäÿß ÿ®ÿ£ŸÅ ŸÅŸäŸÜ ÿßŸÑŸÅŸÑŸàŸàŸàŸàŸàÿ≥ #ÿßŸÇŸÅŸÑŸàÿß_ÿØŸÉÿßŸÉŸäŸÜ_ŸáŸÜÿØÿ≥ÿ© \n"," Actual [start] * ÿßŸÜÿß ÿ¨ÿßŸäÿ® 60 % ŸàÿπÿßŸàÿ≤ ÿßÿ®ŸÇŸä ŸÖŸáŸÜÿØÿ≥ * ÿ≥Ÿäÿ® 8 ÿ™ŸÑÿßŸÅ ÿ¨ŸÜŸäŸá Ÿàÿ±Ÿàÿ≠ ÿπŸÑŸä ŸÖÿπŸáÿØ ÿ™ŸÇÿßŸàŸä ŸÑŸÑŸáŸÜÿØÿ≥Ÿá ŸàÿßŸÑÿ™ŸÉŸÜŸàŸÑŸàÿ¨Ÿäÿß ŸÇŸÑŸáŸÖ ÿßŸÜÿß ÿ¨ÿßŸäŸÑŸÉŸàÿß ŸÖŸÜ ÿ∑ÿ±ŸÅ ÿ≠ÿßÿ™ŸÖ ÿ®ÿßÿ¥ÿß * ÿ¥ŸÉÿ±ÿß Ÿäÿß ÿ®ÿßÿ¥ÿß * ÿßÿ≥ÿ™ŸÜŸä Ÿäÿß *** ŸÅŸäŸÜ ÿßŸÑŸÅŸÑŸàŸàŸàŸàŸàÿ≥ #ÿßŸÇŸÅŸÑŸàÿß_ÿØŸÉÿßŸÉŸäŸÜ_ŸáŸÜÿØÿ≥ÿ© [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.0588235294117647 \n"," blue 2-gram :  0.24253562503633297 \n"," blue 3-gram :  0.392601410850376 \n"," blue 4-gram :  0.4924790605054523 \n","\n","Input: ŸÖÿßŸáÿ∞Ÿá ÿßŸÑŸàÿ∂ÿßÿπŸá Ÿäÿß ŸáŸàŸá ŸáŸÑ ÿ£ÿµÿ®ÿ≠ ÿßÿ™ÿ≠ÿßÿØ ÿßŸÑŸÉÿ±ÿ© ÿßŸÑÿ≥ÿπŸàÿØŸäŸá ŸÜÿØÿß ŸÑŸÑŸáŸÑÿßŸÑ ŸàŸäŸÜÿßŸÅÿ≥Ÿá ŸÉÿ®Ÿäÿ± Ÿäÿß ŸáŸÑÿßŸÑ ŸÉÿ®Ÿäÿ± Ÿäÿß ŸáŸÑÿßŸÑ üíôüíôüíôüíôüíôüíôüíôüíôüíôüíô ‚Ä¶ \n"," Actual [start] ŸÖÿßŸáÿ∞Ÿá ******* Ÿäÿß ŸáŸàŸá ŸáŸÑ ÿ£ÿµÿ®ÿ≠ ÿßÿ™ÿ≠ÿßÿØ ÿßŸÑŸÉÿ±ÿ© ÿßŸÑÿ≥ÿπŸàÿØŸäŸá ŸÜÿØÿß ŸÑŸÑŸáŸÑÿßŸÑ ŸàŸäŸÜÿßŸÅÿ≥Ÿá ŸÉÿ®Ÿäÿ± Ÿäÿß ŸáŸÑÿßŸÑ ŸÉÿ®Ÿäÿ± Ÿäÿß ŸáŸÑÿßŸÑ üíôüíôüíôüíôüíôüíôüíôüíôüíôüíô ‚Ä¶ [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.02941176470588235 \n"," blue 2-gram :  0.17149858514250882 \n"," blue 3-gram :  0.3123287459051282 \n"," blue 4-gram :  0.41412387656655203 \n","\n","Input: ÿ∑ÿ® ÿßÿ≠ÿ® ÿßŸÜŸàŸá ŸÑŸÑÿßÿÆŸàÿ© ÿßŸÑÿ®ŸáÿßŸäŸÖ ÿßŸÑŸÑŸä ŸáŸäŸÅŸáŸÖ ÿ∫ŸÑÿ∑ ÿßŸÜÿß ÿ®ÿ∑ÿ®ŸÑ Ÿà ÿ®ÿ≠ŸÅŸÑ Ÿäÿß ŸÖÿ™ÿÆŸÑŸÅŸäŸÜ Ÿäÿß Ÿáÿ®ŸÑ Ÿàÿ®ÿ≥ ÿ¥ŸÉÿ±ÿß‚úãüòÇ \n"," Actual [start] ÿ∑ÿ® ÿßÿ≠ÿ® ÿßŸÜŸàŸá ŸÑŸÑÿßÿÆŸàÿ© ******* ÿßŸÑŸÑŸä ŸáŸäŸÅŸáŸÖ ÿ∫ŸÑÿ∑ ÿßŸÜÿß **** Ÿà ÿ®ÿ≠ŸÅŸÑ Ÿäÿß ******* Ÿäÿß *** Ÿàÿ®ÿ≥ ÿ¥ŸÉÿ±ÿß‚úãüòÇ [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.02941176470588235 \n"," blue 2-gram :  0.17149858514250882 \n"," blue 3-gram :  0.3123287459051282 \n"," blue 4-gram :  0.41412387656655203 \n","\n","Input: #ÿßŸÑÿßÿ™ÿ≠ÿßÿØ_ÿßŸÑŸÜÿµÿ± ÿßŸÑŸÑŸá Ÿäÿ≠ÿ±ŸÇ ÿßŸÑŸä ŸÖÿÆŸÑŸäŸÉ ÿ™ŸÑÿπÿ® ŸÅŸä ÿßŸÑÿßÿ™ÿ≠ÿßÿØ Ÿäÿß ÿ£ÿ≠ŸÖÿØ ÿπÿ≥Ÿäÿ±Ÿä Ÿäÿß ÿ≥ÿ®ŸÉ üò† \n"," Actual [start] #ÿßŸÑÿßÿ™ÿ≠ÿßÿØ_ÿßŸÑŸÜÿµÿ± ÿßŸÑŸÑŸá **** ÿßŸÑŸä ŸÖÿÆŸÑŸäŸÉ ÿ™ŸÑÿπÿ® ŸÅŸä ÿßŸÑÿßÿ™ÿ≠ÿßÿØ Ÿäÿß ÿ£ÿ≠ŸÖÿØ ÿπÿ≥Ÿäÿ±Ÿä Ÿäÿß *** üò† [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.02941176470588235 \n"," blue 2-gram :  0.17149858514250882 \n"," blue 3-gram :  0.3123287459051282 \n"," blue 4-gram :  0.41412387656655203 \n","\n","Input: ÿßÿ¥ÿπÿ± ÿ®ÿßŸÑÿπÿßÿ± ÿ®ÿßŸÑŸÅÿπŸÑ ŸÑŸäÿ≥ ŸÖŸÜ ÿ±ŸäÿßŸÑ ŸÖÿØÿ±ŸäÿØ ÿ®ŸÑ ŸÖŸÜ ÿßŸÑ**Ÿà&amp;ÿß* ÿßŸÑÿ∞Ÿä ŸäÿØŸäÿ± ÿßŸÑŸÅÿ±ŸäŸÇ ŸÑŸÉ ÿ≥ŸàŸÑÿßÿ±Ÿä ÿ®ŸÜŸÅÿ≥ ÿßŸÑÿπŸÜÿßÿµÿ± ÿ∑ÿπŸÖÿßŸáŸÖ Ÿ£ Ÿäÿß Ÿàÿßÿ∑Ÿä Ÿäÿß ŸÖŸÜÿ≠ÿ∑ Ÿäÿß ÿ≠ŸÇŸäÿ± Ÿà ŸÑŸàÿ®ÿ™Ÿäÿ∫Ÿä ÿßŸÑŸä ÿ®ÿπŸäŸàŸÜŸÉŸÖ ŸÅÿßÿ¥ŸÑ ÿßÿµŸÇÿ∑ŸáŸÖ ÿ®ÿßŸÑŸ§ Ÿäÿß ŸÇÿ∞ÿ± Ÿäÿß ÿ≥ÿßŸÅŸÑ Ÿäÿß Ÿàÿ∂Ÿäÿπ ŸÖŸäÿ±ŸÉÿßÿ™Ÿà ŸÖÿπ ŸÖÿßÿ±ÿ≥ŸäŸÑŸà ÿ±ÿ≠ ŸäŸÉŸàŸÜ üí© ÿ® ÿ™ŸÖ ÿ≤ŸäÿØÿß \n"," Actual [start] ÿßÿ¥ÿπÿ± ****** ÿ®ÿßŸÑŸÅÿπŸÑ ŸÑŸäÿ≥ ŸÖŸÜ ÿ±ŸäÿßŸÑ ŸÖÿØÿ±ŸäÿØ ÿ®ŸÑ ŸÖŸÜ ÿßŸÑ**Ÿà&amp;ÿß* ÿßŸÑÿ∞Ÿä ŸäÿØŸäÿ± ÿßŸÑŸÅÿ±ŸäŸÇ ŸÑŸÉ ÿ≥ŸàŸÑÿßÿ±Ÿä ÿ®ŸÜŸÅÿ≥ ÿßŸÑÿπŸÜÿßÿµÿ± ÿ∑ÿπŸÖÿßŸáŸÖ Ÿ£ Ÿäÿß **** Ÿäÿß **** Ÿäÿß **** Ÿà ŸÑŸàÿ®ÿ™Ÿäÿ∫Ÿä ÿßŸÑŸä ÿ®ÿπŸäŸàŸÜŸÉŸÖ **** ÿßÿµŸÇÿ∑ŸáŸÖ ÿ®ÿßŸÑŸ§ Ÿäÿß *** Ÿäÿß **** Ÿäÿß **** ŸÖŸäÿ±ŸÉÿßÿ™Ÿà ŸÖÿπ ŸÖÿßÿ±ÿ≥ŸäŸÑŸà ÿ±ÿ≠ ŸäŸÉŸàŸÜ üí© ÿ® ÿ™ŸÖ ÿ≤ŸäÿØÿß [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.08823529411764706 \n"," blue 2-gram :  0.2970442628930023 \n"," blue 3-gram :  0.4488094280005903 \n"," blue 4-gram :  0.5450176720923848 \n","\n","Input: #ÿ™ÿ≥ŸÇÿ∑_ÿ®ÿ≥ Ÿäÿß ÿ≥Ÿäÿ≥Ÿä Ÿäÿß ÿ®ÿ¥Ÿäÿ± Ÿäÿß ÿ®ŸÜ ÿ≥ŸÑŸÖÿßŸÜ Ÿäÿß ÿ®ŸÜ ÿ≤ÿßŸäÿØ Ÿäÿß ŸÉŸÑ ÿ≠ÿßŸÉŸÖ ŸÅÿßÿ¨ÿ± ÿßÿ®ŸÜ Ÿàÿ≥ÿÆÿ© ŸÖÿ≥ÿ™ÿ®ÿØ ÿ®ŸäÿßŸÉŸÑ ÿÆŸäÿ± ÿ¥ÿπÿ®Ÿá ‚úåüëä #ŸÑŸÖ_ÿ™ÿ≥ŸÇÿ∑_ÿ®ÿπÿØ ‚úåüëä \n"," Actual [start] #ÿ™ÿ≥ŸÇÿ∑_ÿ®ÿ≥ Ÿäÿß ÿ≥Ÿäÿ≥Ÿä Ÿäÿß ÿ®ÿ¥Ÿäÿ± Ÿäÿß ÿ®ŸÜ ÿ≥ŸÑŸÖÿßŸÜ Ÿäÿß ÿ®ŸÜ ÿ≤ÿßŸäÿØ Ÿäÿß ŸÉŸÑ ÿ≠ÿßŸÉŸÖ **** ÿßÿ®ŸÜ **** ***** ÿ®ŸäÿßŸÉŸÑ ÿÆŸäÿ± ÿ¥ÿπÿ®Ÿá ‚úåüëä #ŸÑŸÖ_ÿ™ÿ≥ŸÇÿ∑_ÿ®ÿπÿØ ‚úåüëä [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.02941176470588235 \n"," blue 2-gram :  0.17149858514250882 \n"," blue 3-gram :  0.3123287459051282 \n"," blue 4-gram :  0.41412387656655203 \n","\n","Input: ŸÑŸÜ ÿ™ŸÉŸàŸÜ ÿßÿ±ÿ≠ŸÖ ŸÖŸÜ ÿßŸÑŸÖŸÖŸÑŸÉŸá Ÿàÿ£ÿ®ŸÜÿßÿ°Ÿáÿß Ÿàÿ≠ŸÉÿßŸÖŸáÿß ÿπŸÑŸâ ŸÇÿ∑ÿ± Ÿàÿ£ŸáŸÑ ŸÇÿ∑ÿ± Ÿäÿß ŸÖÿ±ÿ™ÿ≤ŸÇ .. ÿßŸÑŸÑŸá Ÿäÿ£ÿÆÿ∞ŸÉ Ÿàÿ£ÿ¥ŸÉÿßŸÑŸÉ ŸàŸäŸÅŸÉŸÜÿß ÿ¥ÿ±ŸÉŸÖ Ÿäÿß ÿπÿ®ÿØÿ© ÿßŸÑŸÖÿßŸÑ Ÿäÿß ÿÆŸàŸÜŸá ÿßŸÜÿ™ŸÖ ÿßŸÑŸÅÿ™ŸÜŸá ŸÇÿ®ÿ≠ŸÉŸÖ ÿßŸÑŸÑŸá \n"," Actual [start] ŸÑŸÜ ÿ™ŸÉŸàŸÜ ÿßÿ±ÿ≠ŸÖ ŸÖŸÜ ÿßŸÑŸÖŸÖŸÑŸÉŸá Ÿàÿ£ÿ®ŸÜÿßÿ°Ÿáÿß Ÿàÿ≠ŸÉÿßŸÖŸáÿß ÿπŸÑŸâ ŸÇÿ∑ÿ± Ÿàÿ£ŸáŸÑ ŸÇÿ∑ÿ± Ÿäÿß ***** .. ÿßŸÑŸÑŸá Ÿäÿ£ÿÆÿ∞ŸÉ Ÿà****** ŸàŸäŸÅŸÉŸÜÿß ÿ¥ÿ±ŸÉŸÖ Ÿäÿß **** ÿßŸÑŸÖÿßŸÑ Ÿäÿß **** ÿßŸÜÿ™ŸÖ ****** ***** ÿßŸÑŸÑŸá [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.02941176470588235 \n"," blue 2-gram :  0.17149858514250882 \n"," blue 3-gram :  0.3123287459051282 \n"," blue 4-gram :  0.41412387656655203 \n","\n","Input: Ÿàÿ£ÿπÿ±Ÿá ÿπŸÑŸäŸÉŸÖ ÿ∑ÿ±ÿßÿ®ŸÑÿ≥ Ÿà ŸÖÿµÿ±ÿßÿ™Ÿá ŸÖÿßÿ™ÿ¨Ÿäÿ®Ÿäÿ¥ ÿ≥Ÿäÿ±ÿ™Ÿáÿß Ÿä ŸÇŸàÿßÿØ Ÿäÿß ÿ∞ŸäŸÑ Ÿäÿß ÿ≠ÿßŸÅÿ± ÿπÿØŸä ÿßÿπÿ®ÿØ ÿ≠ŸÅÿ™ÿ± Ÿà ÿÆŸÑŸàŸÜÿß ŸÅŸä ÿ≠ÿßŸÑŸÜÿß Ÿäÿß ŸÉŸàÿßŸÑÿßÿ™ ÿÆŸÑŸàŸÉŸÖ ŸÅŸä ÿßŸÑÿßŸÜÿ≥ÿ≠ÿßÿ® ÿßŸÑÿ™ŸÉÿ™ŸäŸÉŸä ŸÖÿ™ÿßÿπŸÉŸÖ Ÿä ŸÉŸàŸÑÿßÿßÿ™ ÿ≠ Ÿäÿ™ŸÖ ÿßŸÑÿØÿ≠ÿ± ŸÑÿπŸÜÿØ ÿ®ŸÜÿ∫ÿßÿ≤Ÿä ŸàŸäÿ™ŸÖ ÿ™ÿµŸÅŸäÿ© ÿßŸÑÿ∑ÿ≠ÿßŸÑÿ® ŸäŸÑŸä ÿ≤ŸäŸÉ ŸÉÿ≥ ÿ®ÿπŸäÿØ ŸäŸÑÿß Ÿäÿß ŸÇŸàÿßÿØ \n"," Actual [start] Ÿà**** ÿπŸÑŸäŸÉŸÖ ÿ∑ÿ±ÿßÿ®ŸÑÿ≥ Ÿà ŸÖÿµÿ±ÿßÿ™Ÿá ŸÖÿßÿ™ÿ¨Ÿäÿ®Ÿäÿ¥ ÿ≥Ÿäÿ±ÿ™Ÿáÿß Ÿä **** Ÿäÿß *** Ÿäÿß ÿ≠ÿßŸÅÿ± ÿπÿØŸä ÿßÿπÿ®ÿØ ÿ≠ŸÅÿ™ÿ± Ÿà ÿÆŸÑŸàŸÜÿß ŸÅŸä ÿ≠ÿßŸÑŸÜÿß Ÿäÿß ŸÉŸàÿßŸÑÿßÿ™ ÿÆŸÑŸàŸÉŸÖ ŸÅŸä ÿßŸÑÿßŸÜÿ≥ÿ≠ÿßÿ® ÿßŸÑÿ™ŸÉÿ™ŸäŸÉŸä ŸÖÿ™ÿßÿπŸÉŸÖ Ÿä ŸÉŸàŸÑÿßÿßÿ™ ÿ≠ Ÿäÿ™ŸÖ ÿßŸÑÿØÿ≠ÿ± ŸÑÿπŸÜÿØ ÿ®ŸÜÿ∫ÿßÿ≤Ÿä ŸàŸäÿ™ŸÖ ÿ™ÿµŸÅŸäÿ© ÿßŸÑÿ∑ÿ≠ÿßŸÑÿ® ŸäŸÑŸä ÿ≤ŸäŸÉ ** ÿ®ÿπŸäÿØ ŸäŸÑÿß Ÿäÿß **** [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.02941176470588235 \n"," blue 2-gram :  0.17149858514250882 \n"," blue 3-gram :  0.3123287459051282 \n"," blue 4-gram :  0.41412387656655203 \n","\n","Input: ÿ™ÿ≠ÿßŸÑŸÅ ÿßŸÑÿπÿØŸàÿßŸÜ ŸÖÿπ ÿßŸÑŸÖÿ±ÿ™ÿ≤ŸÇÿ© ŸàÿßŸÑÿÆŸàŸÜÿ© ŸàÿßŸÑÿπŸÖŸÑÿßÿ° ÿ≥ŸäÿµÿπŸÇŸàŸÜ Ÿàÿ®ŸÇŸàŸàŸàŸàÿ© ÿ®ŸÇŸàŸàŸàŸàŸàÿ© ŸÑŸÑÿ£ÿ™Ÿä ÿßŸÑŸÇÿ±Ÿäÿ® ÿ¨ÿØÿß Ÿäÿßÿ±ÿ® ÿπÿ¨ŸÑ ÿ®ÿßŸÑŸÅÿ±ÿ¨ Ÿäÿß ÿßŸÑŸÑŸá Ÿäÿß ÿßŸÑŸÑŸá Ÿäÿß ŸÇŸàŸä Ÿäÿß ŸÖÿ™ŸäŸÜ ÿßÿ±ŸäŸÜÿß ŸÅŸäŸáŸÖ ÿπÿ¨ÿßÿ¶ÿ® ŸÇÿØÿ±ÿ™ŸÉ ÿ®ÿ≠ŸÇ ŸÖÿ≠ŸÖÿØ ŸàÿßŸÑŸá ÿßŸÑÿßÿ∑Ÿáÿßÿ± \n"," Actual [start] ÿ™ÿ≠ÿßŸÑŸÅ ÿßŸÑÿπÿØŸàÿßŸÜ ŸÖÿπ ******** Ÿà****** Ÿà******* ÿ≥ŸäÿµÿπŸÇŸàŸÜ Ÿàÿ®ŸÇŸàŸàŸàŸàÿ© ÿ®ŸÇŸàŸàŸàŸàŸàÿ© ŸÑŸÑÿ£ÿ™Ÿä ÿßŸÑŸÇÿ±Ÿäÿ® ÿ¨ÿØÿß Ÿäÿßÿ±ÿ® ÿπÿ¨ŸÑ ÿ®ÿßŸÑŸÅÿ±ÿ¨ Ÿäÿß ÿßŸÑŸÑŸá Ÿäÿß ÿßŸÑŸÑŸá Ÿäÿß ŸÇŸàŸä Ÿäÿß ŸÖÿ™ŸäŸÜ ÿßÿ±ŸäŸÜÿß ŸÅŸäŸáŸÖ ÿπÿ¨ÿßÿ¶ÿ® ŸÇÿØÿ±ÿ™ŸÉ ÿ®ÿ≠ŸÇ ŸÖÿ≠ŸÖÿØ ŸàÿßŸÑŸá ÿßŸÑÿßÿ∑Ÿáÿßÿ± [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.02941176470588235 \n"," blue 2-gram :  0.17149858514250882 \n"," blue 3-gram :  0.3123287459051282 \n"," blue 4-gram :  0.41412387656655203 \n","\n","Input: ŸÜŸÅÿ≥Ÿä ÿßÿØŸäŸÉ ÿ®ÿßŸÑŸÇŸÅÿß Ÿäÿß ÿßÿ®ŸÜ ÿßŸÑŸÉŸÑÿ® Ÿäÿß ŸÖÿπÿ±ÿµ ÿßŸÜÿ™ ÿßÿ®ŸàŸÉ ŸÑÿßÿ®Ÿà ÿßŸÖÿ´ÿßŸÑŸÉ \n"," Actual [start] ŸÜŸÅÿ≥Ÿä ÿßÿØŸäŸÉ ****** Ÿäÿß ÿßÿ®ŸÜ ***** Ÿäÿß **** ÿßŸÜÿ™ ÿßÿ®ŸàŸÉ ŸÑÿßÿ®Ÿà ÿßŸÖÿ´ÿßŸÑŸÉ [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.02941176470588235 \n"," blue 2-gram :  0.17149858514250882 \n"," blue 3-gram :  0.3123287459051282 \n"," blue 4-gram :  0.41412387656655203 \n","\n","Input: Ÿäÿß ÿÆÿßÿ¶ŸÜ Ÿäÿß *** ŸÖÿß ÿ™ÿ≥ŸÑŸÖ ÿ≠ÿ™Ÿâ \n"," Actual [start] Ÿäÿß **** Ÿäÿß *** ŸÖÿß ÿ™ÿ≥ŸÑŸÖ ÿ≠ÿ™Ÿâ [end] \n"," Predicted [start] *** [en]                  \n","blue 1-gram :  0.0588235294117647 \n"," blue 2-gram :  0.24253562503633297 \n"," blue 3-gram :  0.392601410850376 \n"," blue 4-gram :  0.4924790605054523 \n","\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-15f06191ab71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0minput_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_inp_texts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# print(input_sentence[i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0mtranslated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m   \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0;31m# score = sentence_bleu(i, translated, weights=(1, 0, 0, 0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-1d9a73c8479f>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_sentence)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_decoded_sentence_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtokenized_target_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarg_vectorization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecoded_sentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokenized_input_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenized_target_sentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0msampled_token_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \"\"\"\n\u001b[1;32m    414\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 415\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \"\"\"\n\u001b[1;32m    414\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 415\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-feb73a0b6af1>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, encoder_outputs, mask)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         attention_output_1 = self.attention_1(\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         )\n\u001b[1;32m     85\u001b[0m         \u001b[0mout_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattention_output_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/multi_head_attention.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, query, value, key, attention_mask, return_attention_scores, training)\u001b[0m\n\u001b[1;32m    503\u001b[0m     attention_output, attention_scores = self._compute_attention(\n\u001b[1;32m    504\u001b[0m         query, key, value, attention_mask, training)\n\u001b[0;32m--> 505\u001b[0;31m     \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_attention_scores\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/einsum_dense.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m       \u001b[0mret\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/special_math_ops.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(equation, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;34m-\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0mare\u001b[0m \u001b[0minconsistent\u001b[0m \u001b[0;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m   \"\"\"\n\u001b[0;32m--> 751\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_einsum_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/special_math_ops.py\u001b[0m in \u001b[0;36m_einsum_v2\u001b[0;34m(equation, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1178\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mellipsis_label\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0mresolved_equation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresolved_equation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mellipsis_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_linalg_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolved_equation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m     \u001b[0;31m# Send fully specified shapes to opt_einsum, since it cannot handle unknown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_linalg_ops.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(inputs, equation, name)\u001b[0m\n\u001b[1;32m   1071\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 1073\u001b[0;31m         _ctx, \"Einsum\", name, inputs, \"equation\", equation)\n\u001b[0m\u001b[1;32m   1074\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"VjVwnT-tljio","executionInfo":{"status":"aborted","timestamp":1630098957594,"user_tz":-180,"elapsed":10,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# from nltk.translate.bleu_score import sentence_bleu,corpus_bleu\n","\n","# predicted_list = []\n","# test_inp_texts = [pair[0] for pair in test_pairs]\n","# test_targ_texts = [pair[1] for pair in test_pairs]\n","# for i,j in zip(test_inp_texts,test_targ_texts):\n","#     input_sentence = test_inp_texts\n","#     translated = decode_sequence(i)\n","#     predicted = list(translated.split(\",\"))\n","#     print(\"Input:\",i,\"\\n Actual\",j,\"\\n Predicted\",translated)\n","#     # print(translated)\n","  \n","#     # print(predicted)\n","#     score = sentence_bleu(i, translated, weights=(1, 0, 0, 0))\n","#     print(\"blue score : \",score,\"\\n\\n\")\n","   \n","#     predicted_list.append(predicted)\n","    \n","\n","# res = \"\\n\\n\\n\".join(\"Input: {} \\nActual: {} \\nPredicted: {}\".format(x, y,z) for x, y, z in zip(test_inp_texts[:5], test_targ_texts[:5], predicted_list[:5]))\n","# print(res)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nxbDXWsZUVJf","executionInfo":{"status":"aborted","timestamp":1630098957596,"user_tz":-180,"elapsed":11,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# bleu_dic = {}\n","# bleu_dic['1-grams'] = sentence_bleu(test_targ_texts, predicted_list, weights=(1.0, 0, 0, 0))\n","# bleu_dic['1-2-grams'] = corpus_bleu(test_targ_texts, predicted_list, weights=(0.5, 0.5, 0, 0))\n","# bleu_dic['1-3-grams'] = corpus_bleu(test_targ_texts, predicted_list, weights=(0.3, 0.3, 0.3, 0))\n","# bleu_dic['1-4-grams'] = corpus_bleu(test_targ_texts, predicted_list, weights=(0.25, 0.25, 0.25, 0.25))   \n","\n","# print(\" \\n-------------\\n BLUE SCORE : \\n-------------\\n \",bleu_dic, \"\\n\\n\\n-------------\\n\")"],"execution_count":null,"outputs":[]}]}