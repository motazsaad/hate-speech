{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3- Hate Speech Detection Using RNN - GRU .ipynb","provenance":[{"file_id":"1mi1udM9ncE8Suct2hMuqZXBIps8Uyk2V","timestamp":1603265545325},{"file_id":"1qtc895HIHprEhfV3ERX95q_IG_a-G2SX","timestamp":1602962403161}],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"18XmySDBuV4rJSa1ezAS_oGnEMamvkknD","authorship_tag":"ABX9TyOXCdh2mNR4YvrQbqF4Tl3U"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Zr6oWy4s-nhv"},"source":["# Load libraries and Data\n","---\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"Odfxli0izF2p","executionInfo":{"status":"ok","timestamp":1603273037221,"user_tz":-180,"elapsed":4980,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"249458b3-711d-478e-fdaf-e036af6362ee","colab":{"base_uri":"https://localhost:8080/","height":419}},"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Dense, GRU, Dropout, Bidirectional, SpatialDropout1D\n","from tensorflow.keras.utils import to_categorical\n","import pandas as pd\n","data_train = pd.read_json('/content/drive/My Drive/Master thesis/Datasets/Arabic_hatespeech-master-nuha/Hate_Speech/train.json', lines=True)\n","data_test = pd.read_json('/content/drive/My Drive/Master thesis/Datasets/Arabic_hatespeech-master-nuha/Hate_Speech/test.json', lines=True)\n","\n","                  \n","df_train = pd.DataFrame(data_train,columns=['full_text','hate'])\n","df_test = pd.DataFrame(data_test,columns=['full_text'])\n","\n","df_train\n","# data_json.head()"],"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>full_text</th>\n","      <th>hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Ù…Ø¤Ø³Ø³Ø© Ø£Ø±Ø´ÙŠÙ Ø§Ù„Ù…ØºØ±Ø¨ ØªØªØ³Ù„Ù… ÙˆØ«Ø§Ø¦Ù‚ Ø¹Ù† Ø°Ø§ÙƒØ±Ø© Ø§Ù„ÙŠÙ‡ÙˆØ¯...</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Ù…ÙØªÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© Ø­Ù…Ø§Ø³ Ø¥Ø±Ù‡Ø§Ø¨ÙŠØ© ÙˆÙ‚ØªØ§Ù„ Ø§Ù„ÙŠÙ‡ÙˆØ¯ Ø­Ø±Ø§Ù… Ø´...</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Ø£Ù…Ø±Ø§Ø¡ Ø§Ù„ Ø³Ø¹ÙˆØ¯ Ø§Ù„ÙŠÙ‡ÙˆØ¯ ÙŠØ®ÙˆØ¶ÙˆÙ† Ø­Ø±Ø¨Ø§ Ø¹Ù† Ø§Ù„ØµÙ‡ÙŠÙˆÙ†ÙŠÙ‡</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ÙŠØ§Ø­ÙƒØ§Ù… Ø§Ù„Ø¹Ø±Ø¨ Ø£Ù‚Ø³Ù… Ø¨Ø§Ø§Ù„Ù„Ù‡ Ø¹Ø°Ø§Ø¨ Ø§Ù„Ù„Ù‡ ÙˆØ§Ù‚Ø¹ Ø¹Ù„ÙŠÙƒÙ… ...</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Ø¹Ù†Ø¯Ù…Ø§ ÙƒÙ†Øª Ø¨Ø£Ù…Ø±ÙŠÙƒØ§ Ø­ØªÙ… Ø¹Ù„ÙŠ Ø¹Ù…Ù„ÙŠ Ø§Ù† Ø§Ø­ØªÙƒ Ø¨ÙØªÙŠØ§Øª ...</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5564</th>\n","      <td>ğŸ”ºÙ…Ø­Ø§Ø¶Ø±Ø© Ù„Ù„Ø¥Ø®ÙˆØ© Ø§Ù„Ø£Ù„Ø¨Ø§Ù†ÙŠÙŠÙ† Ø¨Ø¹Ù†ÙˆØ§Ù† \"Ø¹Ù‚ÙŠØ¯Ø© Ø£Ù‡Ù„ Ø§Ù„...</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>5565</th>\n","      <td>Ø§Ù„Ø¯ÙˆØ±Ø© Ø§Ù„Ø­Ø¶Ø§Ø±ÙŠØ© Ù‚Ø¯ Ø¯Ø§Ø±Øª ÙˆÙ‡Ø°Ø§ Ø²Ù…Ø§Ù† Ø§Ù†Ø­Ø¯Ø§Ø± Ø£Ù‡Ù„ Ø§...</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>5566</th>\n","      <td>New post (ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ù‚ØµØ© Ø­Ø³Ù† Ø§Ù„Ù…Ù†Ø¯Ù„Ø§ÙˆÙŠ Ù…Ø¹ Ø®ÙˆØ§ØªÙ‡ ...</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>5567</th>\n","      <td>ÙÙŠ ÙØ±Ù‚ Ø¨ÙŠÙ† Ø§Ù„Ø³Ù†Ù‘ÙŠ ÙˆØ§Ù„ÙˆÙ‡Ø§Ø¨ÙŠ \\nÙˆØ´ÙƒØ±Ø§Ù‹</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>5568</th>\n","      <td>Ø£ÙŠÙ‡Ø§ Ø§Ù„Ø³Ù†Ù‘ÙŠ ÙˆØ£ÙŠÙ‡Ø§ Ø§Ù„Ø´ÙŠØ¹ÙŠ Ø´Ø§Ù‡Ø¯ ÙƒÙŠÙ ÙŠØ³ØªØ®ÙÙ‘ÙˆÙ† Ø¨Ø¹Ù‚...</td>\n","      <td>yes</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5569 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["                                              full_text hate\n","0     Ù…Ø¤Ø³Ø³Ø© Ø£Ø±Ø´ÙŠÙ Ø§Ù„Ù…ØºØ±Ø¨ ØªØªØ³Ù„Ù… ÙˆØ«Ø§Ø¦Ù‚ Ø¹Ù† Ø°Ø§ÙƒØ±Ø© Ø§Ù„ÙŠÙ‡ÙˆØ¯...   no\n","1     Ù…ÙØªÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© Ø­Ù…Ø§Ø³ Ø¥Ø±Ù‡Ø§Ø¨ÙŠØ© ÙˆÙ‚ØªØ§Ù„ Ø§Ù„ÙŠÙ‡ÙˆØ¯ Ø­Ø±Ø§Ù… Ø´...   no\n","2         Ø£Ù…Ø±Ø§Ø¡ Ø§Ù„ Ø³Ø¹ÙˆØ¯ Ø§Ù„ÙŠÙ‡ÙˆØ¯ ÙŠØ®ÙˆØ¶ÙˆÙ† Ø­Ø±Ø¨Ø§ Ø¹Ù† Ø§Ù„ØµÙ‡ÙŠÙˆÙ†ÙŠÙ‡  yes\n","3     ÙŠØ§Ø­ÙƒØ§Ù… Ø§Ù„Ø¹Ø±Ø¨ Ø£Ù‚Ø³Ù… Ø¨Ø§Ø§Ù„Ù„Ù‡ Ø¹Ø°Ø§Ø¨ Ø§Ù„Ù„Ù‡ ÙˆØ§Ù‚Ø¹ Ø¹Ù„ÙŠÙƒÙ… ...  yes\n","4     Ø¹Ù†Ø¯Ù…Ø§ ÙƒÙ†Øª Ø¨Ø£Ù…Ø±ÙŠÙƒØ§ Ø­ØªÙ… Ø¹Ù„ÙŠ Ø¹Ù…Ù„ÙŠ Ø§Ù† Ø§Ø­ØªÙƒ Ø¨ÙØªÙŠØ§Øª ...  yes\n","...                                                 ...  ...\n","5564  ğŸ”ºÙ…Ø­Ø§Ø¶Ø±Ø© Ù„Ù„Ø¥Ø®ÙˆØ© Ø§Ù„Ø£Ù„Ø¨Ø§Ù†ÙŠÙŠÙ† Ø¨Ø¹Ù†ÙˆØ§Ù† \"Ø¹Ù‚ÙŠØ¯Ø© Ø£Ù‡Ù„ Ø§Ù„...   no\n","5565  Ø§Ù„Ø¯ÙˆØ±Ø© Ø§Ù„Ø­Ø¶Ø§Ø±ÙŠØ© Ù‚Ø¯ Ø¯Ø§Ø±Øª ÙˆÙ‡Ø°Ø§ Ø²Ù…Ø§Ù† Ø§Ù†Ø­Ø¯Ø§Ø± Ø£Ù‡Ù„ Ø§...   no\n","5566  New post (ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ù‚ØµØ© Ø­Ø³Ù† Ø§Ù„Ù…Ù†Ø¯Ù„Ø§ÙˆÙŠ Ù…Ø¹ Ø®ÙˆØ§ØªÙ‡ ...   no\n","5567                ÙÙŠ ÙØ±Ù‚ Ø¨ÙŠÙ† Ø§Ù„Ø³Ù†Ù‘ÙŠ ÙˆØ§Ù„ÙˆÙ‡Ø§Ø¨ÙŠ \\nÙˆØ´ÙƒØ±Ø§Ù‹   no\n","5568  Ø£ÙŠÙ‡Ø§ Ø§Ù„Ø³Ù†Ù‘ÙŠ ÙˆØ£ÙŠÙ‡Ø§ Ø§Ù„Ø´ÙŠØ¹ÙŠ Ø´Ø§Ù‡Ø¯ ÙƒÙŠÙ ÙŠØ³ØªØ®ÙÙ‘ÙˆÙ† Ø¨Ø¹Ù‚...  yes\n","\n","[5569 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"-zGaa_YW97Hp","executionInfo":{"status":"ok","timestamp":1603273039820,"user_tz":-180,"elapsed":646,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"2922e4a2-6be5-48da-b3d7-2b2d5b70ebcd","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(df_train.shape)\n","print(df_test.shape)\n","# print(df.info)\n","# print(df.describe)"],"execution_count":50,"outputs":[{"output_type":"stream","text":["(5569, 2)\n","(567, 1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5SKGOv7ngGtR"},"source":["# Split data "]},{"cell_type":"code","metadata":{"id":"jZsFgyCmguoi","executionInfo":{"status":"ok","timestamp":1603273042258,"user_tz":-180,"elapsed":697,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(df_train['full_text'].values, df_train['hate'].values, test_size=0.1)"],"execution_count":51,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p41fzbtFgJSt"},"source":["# Data Cleaning\n","---\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"NaWagYWNgbdR","executionInfo":{"status":"ok","timestamp":1603273078602,"user_tz":-180,"elapsed":1271,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# initialize Tokenizer to encode strings into integers\n","tokenizer = Tokenizer()\n","\n","# calculate number of rows in our dataset\n","num_rows = df_train.shape[0]\n","\n","# create vocabulary from all words in our dataset for encoding\n","tokenizer.fit_on_texts(df_train['full_text'].values)\n","\n","# max length of 1 row (number of words)\n","row_max_length = max([len(x.split()) for x in df_train['full_text'].values])\n","\n","# count number of unique words\n","vocabulary_size = len(tokenizer.word_index) + 1\n","\n","# convert words into integers\n","X_train_tokens = tokenizer.texts_to_sequences(X_train)\n","X_test_tokens = tokenizer.texts_to_sequences(X_test)\n","X_sub_tokens = tokenizer.texts_to_sequences(df_test['full_text'].values)\n","\n","# ensure every row has same size - pad missing with zeros\n","X_train_pad = pad_sequences(X_train_tokens, maxlen=row_max_length, padding='post')\n","X_test_pad = pad_sequences(X_test_tokens, maxlen=row_max_length, padding='post')\n","X_sub_pad = pad_sequences(X_sub_tokens, maxlen=row_max_length, padding='post')"],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"id":"noh4VnXCh2y8","executionInfo":{"status":"error","timestamp":1603273853816,"user_tz":-180,"elapsed":4505,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"c626e77c-ae85-4229-d6e8-39499410bbaa","colab":{"base_uri":"https://localhost:8080/","height":459}},"source":["EMBEDDING_DIM = 256\n","\n","model = Sequential()\n","model.add(Embedding(vocabulary_size, EMBEDDING_DIM, input_length=row_max_length))\n","model.add(SpatialDropout1D(0.2))\n","model.add(Bidirectional(GRU(128)))\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.2)) \n","model.add(Dense(1,name='out_layer'))\n","# model.add(Dense(target_length, activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1)\n","\n","# model.fit(sequences_matrix,y_train,batch_size=128,epochs=10,\n","          # validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\n","history = model.fit(X_train_pad, y_train, epochs=5, validation_data=0.2, batch_size=128, callbacks=[callback])"],"execution_count":63,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n"],"name":"stdout"},{"output_type":"error","ename":"UnimplementedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-63-4edbfcb20523>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# model.fit(sequences_matrix,y_train,batch_size=128,epochs=10,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m           \u001b[0;31m# validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnimplementedError\u001b[0m:  Cast string to float is not supported\n\t [[node categorical_crossentropy/Cast (defined at <ipython-input-63-4edbfcb20523>:17) ]] [Op:__inference_train_function_22371]\n\nFunction call stack:\ntrain_function\n"]}]},{"cell_type":"markdown","metadata":{"id":"XlS6q0ulGZsN"},"source":["# Data Cleaning\n","---\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"jXhA94wzJBMe"},"source":["1.   Remove punctuation marks by using Regex.\n"]},{"cell_type":"code","metadata":{"id":"11blYnFX-bMg","executionInfo":{"status":"aborted","timestamp":1603266857553,"user_tz":-180,"elapsed":2123,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["import re,string\n","\n","def remove_punct(text):\n","    text_nopunct = ''\n","    text_nopunct = re.sub('['+string.punctuation+']', '', str(text))\n","    return text_nopunct\n","data['Text_Without_punct'] = data['text'].apply(lambda x: remove_punct(x))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HCs_Zz3oRCL8"},"source":["2.   tokenize the comments by using NLTKâ€™s word_tokenize\n"]},{"cell_type":"code","metadata":{"id":"GyvGjQNNK9NQ","executionInfo":{"status":"aborted","timestamp":1603266857556,"user_tz":-180,"elapsed":2120,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["import nltk\n","nltk.download('punkt')\n","from nltk import word_tokenize\n","tokens = [word_tokenize(sen) for sen in data.Text_Without_punct]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2DxmJpjsSg5s"},"source":["\n","3.  lower case the data\n","\n"]},{"cell_type":"code","metadata":{"id":"1s7EObGCRYPR","executionInfo":{"status":"aborted","timestamp":1603266857558,"user_tz":-180,"elapsed":2120,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["def lower_token(tokens): \n","    return [w.lower() for w in tokens]    \n","    \n","lower_tokens = [lower_token(token) for token in tokens]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F6j4Hh84SsaD"},"source":["4. Remove stop words from data using NLTKâ€™s stopwords."]},{"cell_type":"code","metadata":{"id":"Y1bexVzuSnnT","executionInfo":{"status":"aborted","timestamp":1603266857560,"user_tz":-180,"elapsed":2116,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":[" nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","stoplist = stopwords.words('arabic')\n","def removeStopWords(tokens): \n","    return [word for word in tokens if word not in stoplist]\n","filtered_words = [removeStopWords(sen) for sen in lower_tokens]\n","data['Text_Final'] = [' '.join(sen) for sen in filtered_words]\n","data['tokens'] = filtered_words"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RLr0ed0gStow","executionInfo":{"status":"aborted","timestamp":1603266857561,"user_tz":-180,"elapsed":2110,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QqklDfT9Iort"},"source":["# Splitting Data into Test and Train\n"]},{"cell_type":"code","metadata":{"id":"jXRWyn1yTfEQ","executionInfo":{"status":"aborted","timestamp":1603266857562,"user_tz":-180,"elapsed":2105,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["#Now we split our data set into train and test. We will use 90 % data for training and 10 % for testing.\n","!pip install scikit-learn as sklearn\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","X = data.text.astype(str)\n","Y = data.label\n","le = LabelEncoder()\n","Y = le.fit_transform(Y)\n","Y = Y.reshape(-1,1)\n","#data_train, data_test = train_test_split(data, test_size=0.10, random_state=42)\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MMc-r8JlBdWK"},"source":["# Process the dataÂ¶\n","\n","*   Tokenize the data and convert the text to sequences.\n","*   Add padding to ensure that all the sequences have the same shape.\n","*   There are many ways of taking the max_len and here an arbitrary length of 150 is chosen.\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"sImxKahNlvLE","executionInfo":{"status":"aborted","timestamp":1603266857563,"user_tz":-180,"elapsed":2104,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.preprocessing import sequence\n","import numpy as np\n","\n","max_words = 1000\n","max_len = 150\n","tok = Tokenizer(num_words=max_words)\n","tok.fit_on_texts(X_train)\n","sequences = tok.texts_to_sequences(X_train)\n","sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cQmApeMxCKCj"},"source":["# RNN"]},{"cell_type":"code","metadata":{"id":"AWFSRWtKBbUy","executionInfo":{"status":"aborted","timestamp":1603266857564,"user_tz":-180,"elapsed":2103,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n","from keras.models import Model\n","from keras.optimizers import RMSprop\n","\n","def RNN():\n","    inputs = Input(name='inputs',shape=[max_len])\n","    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n","    layer = LSTM(64)(layer)\n","    layer = Dense(256,name='FC1')(layer)\n","    layer = Activation('relu')(layer)\n","    layer = Dropout(0.5)(layer)\n","    layer = Dense(1,name='out_layer')(layer)\n","    layer = Activation('sigmoid')(layer)\n","    model = Model(inputs=inputs,outputs=layer)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jedzmX16CI5I","executionInfo":{"status":"aborted","timestamp":1603266857565,"user_tz":-180,"elapsed":2098,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["#Call the function and compile the model.\n","model = RNN()\n","model.summary()\n","model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7E_1_kvWCQ5i","executionInfo":{"status":"aborted","timestamp":1603266857566,"user_tz":-180,"elapsed":2091,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["#Fit on the training data.\n","from keras.callbacks import EarlyStopping\n","\n","model.fit(sequences_matrix,y_train,batch_size=128,epochs=10,\n","          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zK30xmbOETQr","executionInfo":{"status":"aborted","timestamp":1603266857569,"user_tz":-180,"elapsed":2092,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["test_sequences = tok.texts_to_sequences(X_test)\n","test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hxpO82oT5H30","executionInfo":{"status":"aborted","timestamp":1603266857570,"user_tz":-180,"elapsed":2086,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["accr = model.evaluate(test_sequences_matrix,y_test)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KcZt-jc35K1K","executionInfo":{"status":"aborted","timestamp":1603266857571,"user_tz":-180,"elapsed":2081,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e82yJonO5PV4","executionInfo":{"status":"aborted","timestamp":1603266857571,"user_tz":-180,"elapsed":2079,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":[""],"execution_count":null,"outputs":[]}]}