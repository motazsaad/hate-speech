{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3- Hate Speech Detection Using RNN - GRU .ipynb","provenance":[{"file_id":"1mi1udM9ncE8Suct2hMuqZXBIps8Uyk2V","timestamp":1603265545325},{"file_id":"1qtc895HIHprEhfV3ERX95q_IG_a-G2SX","timestamp":1602962403161}],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"18XmySDBuV4rJSa1ezAS_oGnEMamvkknD","authorship_tag":"ABX9TyOXCdh2mNR4YvrQbqF4Tl3U"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Zr6oWy4s-nhv"},"source":["# Load libraries and Data\n","---\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"Odfxli0izF2p","executionInfo":{"status":"ok","timestamp":1603273037221,"user_tz":-180,"elapsed":4980,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"249458b3-711d-478e-fdaf-e036af6362ee","colab":{"base_uri":"https://localhost:8080/","height":419}},"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Dense, GRU, Dropout, Bidirectional, SpatialDropout1D\n","from tensorflow.keras.utils import to_categorical\n","import pandas as pd\n","data_train = pd.read_json('/content/drive/My Drive/Master thesis/Datasets/Arabic_hatespeech-master-nuha/Hate_Speech/train.json', lines=True)\n","data_test = pd.read_json('/content/drive/My Drive/Master thesis/Datasets/Arabic_hatespeech-master-nuha/Hate_Speech/test.json', lines=True)\n","\n","                  \n","df_train = pd.DataFrame(data_train,columns=['full_text','hate'])\n","df_test = pd.DataFrame(data_test,columns=['full_text'])\n","\n","df_train\n","# data_json.head()"],"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>full_text</th>\n","      <th>hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>مؤسسة أرشيف المغرب تتسلم وثائق عن ذاكرة اليهود...</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>مفتي السعودية حماس إرهابية وقتال اليهود حرام ش...</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>أمراء ال سعود اليهود يخوضون حربا عن الصهيونيه</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ياحكام العرب أقسم باالله عذاب الله واقع عليكم ...</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>عندما كنت بأمريكا حتم علي عملي ان احتك بفتيات ...</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5564</th>\n","      <td>🔺محاضرة للإخوة الألبانيين بعنوان \"عقيدة أهل ال...</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>5565</th>\n","      <td>الدورة الحضارية قد دارت وهذا زمان انحدار أهل ا...</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>5566</th>\n","      <td>New post (تعرف على قصة حسن المندلاوي مع خواته ...</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>5567</th>\n","      <td>في فرق بين السنّي والوهابي \\nوشكراً</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>5568</th>\n","      <td>أيها السنّي وأيها الشيعي شاهد كيف يستخفّون بعق...</td>\n","      <td>yes</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5569 rows × 2 columns</p>\n","</div>"],"text/plain":["                                              full_text hate\n","0     مؤسسة أرشيف المغرب تتسلم وثائق عن ذاكرة اليهود...   no\n","1     مفتي السعودية حماس إرهابية وقتال اليهود حرام ش...   no\n","2         أمراء ال سعود اليهود يخوضون حربا عن الصهيونيه  yes\n","3     ياحكام العرب أقسم باالله عذاب الله واقع عليكم ...  yes\n","4     عندما كنت بأمريكا حتم علي عملي ان احتك بفتيات ...  yes\n","...                                                 ...  ...\n","5564  🔺محاضرة للإخوة الألبانيين بعنوان \"عقيدة أهل ال...   no\n","5565  الدورة الحضارية قد دارت وهذا زمان انحدار أهل ا...   no\n","5566  New post (تعرف على قصة حسن المندلاوي مع خواته ...   no\n","5567                في فرق بين السنّي والوهابي \\nوشكراً   no\n","5568  أيها السنّي وأيها الشيعي شاهد كيف يستخفّون بعق...  yes\n","\n","[5569 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"id":"-zGaa_YW97Hp","executionInfo":{"status":"ok","timestamp":1603273039820,"user_tz":-180,"elapsed":646,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"2922e4a2-6be5-48da-b3d7-2b2d5b70ebcd","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(df_train.shape)\n","print(df_test.shape)\n","# print(df.info)\n","# print(df.describe)"],"execution_count":50,"outputs":[{"output_type":"stream","text":["(5569, 2)\n","(567, 1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5SKGOv7ngGtR"},"source":["# Split data "]},{"cell_type":"code","metadata":{"id":"jZsFgyCmguoi","executionInfo":{"status":"ok","timestamp":1603273042258,"user_tz":-180,"elapsed":697,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(df_train['full_text'].values, df_train['hate'].values, test_size=0.1)"],"execution_count":51,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p41fzbtFgJSt"},"source":["# Data Cleaning\n","---\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"NaWagYWNgbdR","executionInfo":{"status":"ok","timestamp":1603273078602,"user_tz":-180,"elapsed":1271,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# initialize Tokenizer to encode strings into integers\n","tokenizer = Tokenizer()\n","\n","# calculate number of rows in our dataset\n","num_rows = df_train.shape[0]\n","\n","# create vocabulary from all words in our dataset for encoding\n","tokenizer.fit_on_texts(df_train['full_text'].values)\n","\n","# max length of 1 row (number of words)\n","row_max_length = max([len(x.split()) for x in df_train['full_text'].values])\n","\n","# count number of unique words\n","vocabulary_size = len(tokenizer.word_index) + 1\n","\n","# convert words into integers\n","X_train_tokens = tokenizer.texts_to_sequences(X_train)\n","X_test_tokens = tokenizer.texts_to_sequences(X_test)\n","X_sub_tokens = tokenizer.texts_to_sequences(df_test['full_text'].values)\n","\n","# ensure every row has same size - pad missing with zeros\n","X_train_pad = pad_sequences(X_train_tokens, maxlen=row_max_length, padding='post')\n","X_test_pad = pad_sequences(X_test_tokens, maxlen=row_max_length, padding='post')\n","X_sub_pad = pad_sequences(X_sub_tokens, maxlen=row_max_length, padding='post')"],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"id":"noh4VnXCh2y8","executionInfo":{"status":"error","timestamp":1603273853816,"user_tz":-180,"elapsed":4505,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"c626e77c-ae85-4229-d6e8-39499410bbaa","colab":{"base_uri":"https://localhost:8080/","height":459}},"source":["EMBEDDING_DIM = 256\n","\n","model = Sequential()\n","model.add(Embedding(vocabulary_size, EMBEDDING_DIM, input_length=row_max_length))\n","model.add(SpatialDropout1D(0.2))\n","model.add(Bidirectional(GRU(128)))\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.2)) \n","model.add(Dense(1,name='out_layer'))\n","# model.add(Dense(target_length, activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1)\n","\n","# model.fit(sequences_matrix,y_train,batch_size=128,epochs=10,\n","          # validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\n","history = model.fit(X_train_pad, y_train, epochs=5, validation_data=0.2, batch_size=128, callbacks=[callback])"],"execution_count":63,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n"],"name":"stdout"},{"output_type":"error","ename":"UnimplementedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-63-4edbfcb20523>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# model.fit(sequences_matrix,y_train,batch_size=128,epochs=10,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m           \u001b[0;31m# validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnimplementedError\u001b[0m:  Cast string to float is not supported\n\t [[node categorical_crossentropy/Cast (defined at <ipython-input-63-4edbfcb20523>:17) ]] [Op:__inference_train_function_22371]\n\nFunction call stack:\ntrain_function\n"]}]},{"cell_type":"markdown","metadata":{"id":"XlS6q0ulGZsN"},"source":["# Data Cleaning\n","---\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"jXhA94wzJBMe"},"source":["1.   Remove punctuation marks by using Regex.\n"]},{"cell_type":"code","metadata":{"id":"11blYnFX-bMg","executionInfo":{"status":"aborted","timestamp":1603266857553,"user_tz":-180,"elapsed":2123,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["import re,string\n","\n","def remove_punct(text):\n","    text_nopunct = ''\n","    text_nopunct = re.sub('['+string.punctuation+']', '', str(text))\n","    return text_nopunct\n","data['Text_Without_punct'] = data['text'].apply(lambda x: remove_punct(x))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HCs_Zz3oRCL8"},"source":["2.   tokenize the comments by using NLTK’s word_tokenize\n"]},{"cell_type":"code","metadata":{"id":"GyvGjQNNK9NQ","executionInfo":{"status":"aborted","timestamp":1603266857556,"user_tz":-180,"elapsed":2120,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["import nltk\n","nltk.download('punkt')\n","from nltk import word_tokenize\n","tokens = [word_tokenize(sen) for sen in data.Text_Without_punct]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2DxmJpjsSg5s"},"source":["\n","3.  lower case the data\n","\n"]},{"cell_type":"code","metadata":{"id":"1s7EObGCRYPR","executionInfo":{"status":"aborted","timestamp":1603266857558,"user_tz":-180,"elapsed":2120,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["def lower_token(tokens): \n","    return [w.lower() for w in tokens]    \n","    \n","lower_tokens = [lower_token(token) for token in tokens]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F6j4Hh84SsaD"},"source":["4. Remove stop words from data using NLTK’s stopwords."]},{"cell_type":"code","metadata":{"id":"Y1bexVzuSnnT","executionInfo":{"status":"aborted","timestamp":1603266857560,"user_tz":-180,"elapsed":2116,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":[" nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","stoplist = stopwords.words('arabic')\n","def removeStopWords(tokens): \n","    return [word for word in tokens if word not in stoplist]\n","filtered_words = [removeStopWords(sen) for sen in lower_tokens]\n","data['Text_Final'] = [' '.join(sen) for sen in filtered_words]\n","data['tokens'] = filtered_words"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RLr0ed0gStow","executionInfo":{"status":"aborted","timestamp":1603266857561,"user_tz":-180,"elapsed":2110,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QqklDfT9Iort"},"source":["# Splitting Data into Test and Train\n"]},{"cell_type":"code","metadata":{"id":"jXRWyn1yTfEQ","executionInfo":{"status":"aborted","timestamp":1603266857562,"user_tz":-180,"elapsed":2105,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["#Now we split our data set into train and test. We will use 90 % data for training and 10 % for testing.\n","!pip install scikit-learn as sklearn\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","X = data.text.astype(str)\n","Y = data.label\n","le = LabelEncoder()\n","Y = le.fit_transform(Y)\n","Y = Y.reshape(-1,1)\n","#data_train, data_test = train_test_split(data, test_size=0.10, random_state=42)\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MMc-r8JlBdWK"},"source":["# Process the data¶\n","\n","*   Tokenize the data and convert the text to sequences.\n","*   Add padding to ensure that all the sequences have the same shape.\n","*   There are many ways of taking the max_len and here an arbitrary length of 150 is chosen.\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"sImxKahNlvLE","executionInfo":{"status":"aborted","timestamp":1603266857563,"user_tz":-180,"elapsed":2104,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.preprocessing import sequence\n","import numpy as np\n","\n","max_words = 1000\n","max_len = 150\n","tok = Tokenizer(num_words=max_words)\n","tok.fit_on_texts(X_train)\n","sequences = tok.texts_to_sequences(X_train)\n","sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cQmApeMxCKCj"},"source":["# RNN"]},{"cell_type":"code","metadata":{"id":"AWFSRWtKBbUy","executionInfo":{"status":"aborted","timestamp":1603266857564,"user_tz":-180,"elapsed":2103,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n","from keras.models import Model\n","from keras.optimizers import RMSprop\n","\n","def RNN():\n","    inputs = Input(name='inputs',shape=[max_len])\n","    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n","    layer = LSTM(64)(layer)\n","    layer = Dense(256,name='FC1')(layer)\n","    layer = Activation('relu')(layer)\n","    layer = Dropout(0.5)(layer)\n","    layer = Dense(1,name='out_layer')(layer)\n","    layer = Activation('sigmoid')(layer)\n","    model = Model(inputs=inputs,outputs=layer)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jedzmX16CI5I","executionInfo":{"status":"aborted","timestamp":1603266857565,"user_tz":-180,"elapsed":2098,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["#Call the function and compile the model.\n","model = RNN()\n","model.summary()\n","model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7E_1_kvWCQ5i","executionInfo":{"status":"aborted","timestamp":1603266857566,"user_tz":-180,"elapsed":2091,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["#Fit on the training data.\n","from keras.callbacks import EarlyStopping\n","\n","model.fit(sequences_matrix,y_train,batch_size=128,epochs=10,\n","          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zK30xmbOETQr","executionInfo":{"status":"aborted","timestamp":1603266857569,"user_tz":-180,"elapsed":2092,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["test_sequences = tok.texts_to_sequences(X_test)\n","test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hxpO82oT5H30","executionInfo":{"status":"aborted","timestamp":1603266857570,"user_tz":-180,"elapsed":2086,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["accr = model.evaluate(test_sequences_matrix,y_test)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KcZt-jc35K1K","executionInfo":{"status":"aborted","timestamp":1603266857571,"user_tz":-180,"elapsed":2081,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e82yJonO5PV4","executionInfo":{"status":"aborted","timestamp":1603266857571,"user_tz":-180,"elapsed":2079,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":[""],"execution_count":null,"outputs":[]}]}