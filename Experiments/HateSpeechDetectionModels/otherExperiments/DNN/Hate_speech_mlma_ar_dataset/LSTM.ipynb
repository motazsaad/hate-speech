{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1IlchhEJAkE_xa_Mn9v3Y7KVPG8KBRU1I","authorship_tag":"ABX9TyPOvRWi9t7RKvdcbZV5kxkX"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"KDzJQ1kksyTm"},"source":["# Importing the libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","plt.style.use('fivethirtyeight')\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n","from keras.optimizers import SGD\n","import math\n","from sklearn.metrics import mean_squared_error\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZgJhz_txG9Ye"},"source":["dataset = pd.read_excel('/content/drive/My Drive/Master thesis/DataSet-forUsing/4-hate_speech_mlma_ar_dataset.xlsx')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"alwtLSc4s3k3","executionInfo":{"status":"ok","timestamp":1604101793790,"user_tz":-120,"elapsed":1040,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"e62fff93-4624-474f-b5b7-7ea777a7ca35","colab":{"base_uri":"https://localhost:8080/"}},"source":["# First, we get the data\n","\n","dataset = pd.read_excel('/content/drive/My Drive/Master thesis/DataSet-forUsing/4-hate_speech_mlma_ar_dataset.xlsx',usecols=['tweet', 'sentiment'])\n","dataset.head()\n","dataset.info()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 3353 entries, 0 to 3352\n","Data columns (total 2 columns):\n"," #   Column     Non-Null Count  Dtype \n","---  ------     --------------  ----- \n"," 0   tweet      3345 non-null   object\n"," 1   sentiment  3353 non-null   object\n","dtypes: object(2)\n","memory usage: 52.5+ KB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A_WPhFm2tCsa","executionInfo":{"status":"ok","timestamp":1604101796457,"user_tz":-120,"elapsed":1352,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"c9ce0b40-9733-44c8-d27a-a9f1301194e9","colab":{"base_uri":"https://localhost:8080/"}},"source":["dataset[\"HS_NOT\"] = dataset.apply(lambda x: \"Not-HS\" if x[\"sentiment\"] in ['normal'] else \"HS\",axis =1)\n","df = pd.DataFrame(data=dataset)\n","print(df.info)\n","properties = list(df.columns.values)\n","properties.remove('HS_NOT')\n","print(properties)\n","X = df['tweet']\n","y = df['HS_NOT']\n","# X = df.iloc[:,[0]].head\n","\n","# X=np.asarray(X)\n","print(X)\n","# Y =df.iloc[:,[-1]].values\n","print(Y)\n","# ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n","# Y = np.array(ct.fit_transform(Y))\n","# print(Y)\n","# y_df = pd.DataFrame(Y)\n","# y_hate = np.array(y_df[0])\n","# y_normal = np.array(y_df[1])\n","# print(y_hate)\n","# print(y_normal)\n","from sklearn.feature_extraction.text import CountVectorizer\n","cv = CountVectorizer(max_features = 2000)\n","X = cv.fit_transform(X.values.astype('U'))\n","\n","from sklearn.compose import ColumnTransformer, make_column_transformer\n","from sklearn.preprocessing import OneHotEncoder\n","\n","ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n","Y = np.array(ct.fit_transform(Y))\n","\n","# VOCAB_SIZE=1000\n","# layer = tf.keras.layers.experimental.preprocessing.TextVectorization()\n","# layer.adapt(X)\n","# vectorized_text = layer(data)\n","print(X)\n","print(Y)\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<bound method DataFrame.info of                                                   tweet  ...  HS_NOT\n","0     صلاة الفجر خير لك من ترديد بول البعير وسبي الن...  ...      HS\n","1     صراحة نفسي اشوف ولاد الوسخة اللي قالوا مدرب اج...  ...      HS\n","2     طيب! هي متبرجة وعبايتها ملونه وطالعة من بيتهم ...  ...      HS\n","3     @user @user انا اوافقك بخصوص السوريين و العراق...  ...  Not-HS\n","4     هذه السعودية التي شعبها شعب الخيم و بول البعير...  ...  Not-HS\n","...                                                 ...  ...     ...\n","3348  @user يمشي بخطا ادارتها قيد من الأمريكان ونهب ...  ...      HS\n","3349  @user مهما حصل هندوس عليهم شويه الرويبضه بس نخ...  ...      HS\n","3350           الكلب لا يعض اذن اخوه كذابين خنازير @url  ...      HS\n","3351  @user لأنه صغير ويكتب في قناة خنازير فلن نقرأ ...  ...      HS\n","3352      الحريم أجمع افلوس وايفون قديم وواتساب ?? ساعة  ...  Not-HS\n","\n","[3353 rows x 3 columns]>\n","['tweet', 'sentiment']\n","0       صلاة الفجر خير لك من ترديد بول البعير وسبي الن...\n","1       صراحة نفسي اشوف ولاد الوسخة اللي قالوا مدرب اج...\n","2       طيب! هي متبرجة وعبايتها ملونه وطالعة من بيتهم ...\n","3       @user @user انا اوافقك بخصوص السوريين و العراق...\n","4       هذه السعودية التي شعبها شعب الخيم و بول البعير...\n","                              ...                        \n","3348    @user يمشي بخطا ادارتها قيد من الأمريكان ونهب ...\n","3349    @user مهما حصل هندوس عليهم شويه الرويبضه بس نخ...\n","3350             الكلب لا يعض اذن اخوه كذابين خنازير @url\n","3351    @user لأنه صغير ويكتب في قناة خنازير فلن نقرأ ...\n","3352        الحريم أجمع افلوس وايفون قديم وواتساب ?? ساعة\n","Name: tweet, Length: 3353, dtype: object\n","[[1. 0.]\n"," [1. 0.]\n"," [1. 0.]\n"," ...\n"," [1. 0.]\n"," [1. 0.]\n"," [0. 1.]]\n","  (0, 1103)\t1\n","  (0, 358)\t1\n","  (0, 890)\t1\n","  (0, 1459)\t1\n","  (0, 1640)\t1\n","  (0, 657)\t1\n","  (0, 192)\t1\n","  (0, 439)\t1\n","  (1, 1098)\t1\n","  (1, 1692)\t1\n","  (1, 115)\t1\n","  (1, 1851)\t1\n","  (1, 462)\t1\n","  (1, 396)\t1\n","  (1, 1302)\t1\n","  (1, 76)\t1\n","  (1, 1644)\t1\n","  (1, 1471)\t1\n","  (1, 949)\t1\n","  (1, 4)\t1\n","  (2, 1640)\t1\n","  (2, 4)\t1\n","  (2, 1130)\t1\n","  (2, 1751)\t1\n","  (2, 1536)\t1\n","  :\t:\n","  (3348, 1747)\t1\n","  (3348, 334)\t1\n","  (3348, 1480)\t1\n","  (3349, 5)\t1\n","  (3349, 602)\t1\n","  (3349, 1735)\t1\n","  (3349, 1192)\t1\n","  (3349, 832)\t1\n","  (3349, 1650)\t1\n","  (3349, 1077)\t1\n","  (3350, 4)\t1\n","  (3350, 883)\t1\n","  (3350, 384)\t1\n","  (3350, 1422)\t1\n","  (3350, 1371)\t1\n","  (3351, 5)\t1\n","  (3351, 1102)\t1\n","  (3351, 883)\t1\n","  (3351, 1282)\t1\n","  (3351, 1328)\t1\n","  (3351, 1419)\t1\n","  (3351, 1697)\t1\n","  (3352, 229)\t1\n","  (3352, 984)\t1\n","  (3352, 1311)\t1\n","[[0. 1. 0.]\n"," [0. 1. 0.]\n"," [0. 1. 0.]\n"," ...\n"," [0. 1. 0.]\n"," [0. 1. 0.]\n"," [1. 0. 1.]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hy2eQ9HNaxqJ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AFikkERIUY6r"},"source":["# from sklearn.feature_extraction.text import CountVectorizer\n","# dt_trasformed = dataset[['HS_NOT', 'tweet']]\n","\n","# training_set = dataset['tweet']\n","# # test_set = dataset[2854:].iloc[:,[0,2]].values\n","# cv = CountVectorizer(max_features = 2000)\n","# X = cv.fit_transform(training_set.values.astype('U'))\n","# X\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"duz6eYyAa-FL","executionInfo":{"status":"ok","timestamp":1604103099582,"user_tz":-120,"elapsed":996,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["\n","# LSTM with Dropout for sequence classification in the IMDB dataset\n","import numpy\n","from keras.models import Sequential\n","\n","from keras.preprocessing import sequence\n","\n","# mytrain = []\n","# for i in range(0,X_train.shape[0]):\n","#     mytrain.append(np.ones(len(X_train[i])))\n","# mytrain = np.asarray(mytrain)\n","\n","# # truncate and pad input sequences\n","# max_review_length = 500\n","# X_train = sequence.pad_sequences(X_train.shape shape(1,))\n","# X_test = sequence.pad_sequences(X_test,maxlen=max_review_length)"],"execution_count":150,"outputs":[]},{"cell_type":"code","metadata":{"id":"AHx0sdpvZ3wF","executionInfo":{"status":"error","timestamp":1604103118113,"user_tz":-120,"elapsed":4271,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"3cd532a0-8d6a-4570-9b42-94ddfc21b9f1","colab":{"base_uri":"https://localhost:8080/","height":785}},"source":["from keras.preprocessing import sequence\n","\n","model = tf.keras.Sequential([\n","                                 tf.keras.Input(shape=(1,)),\n","\n","                    # tf.keras.layers.Embedding\n","  tf.keras.layers.Embedding(1000, 64, input_length=10),\n","\n","   tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n","    tf.keras.layers.Dense(64, activation='relu'),\n","    tf.keras.layers.Dense(1),\n","    \n","    \n","])\n","\n","model.compile(optimizer='adam',\n","              loss='mse',\n","              metrics=['accuracy'])\n","print(model.summary())\n","\n","history = model.fit(X_train, y_train, epochs=34, batch_size=64)\n"],"execution_count":151,"outputs":[{"output_type":"stream","text":["Model: \"sequential_15\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_16 (Embedding)     (None, 1, 64)             64000     \n","_________________________________________________________________\n","bidirectional_15 (Bidirectio (None, 128)               66048     \n","_________________________________________________________________\n","dense_30 (Dense)             (None, 64)                8256      \n","_________________________________________________________________\n","dense_31 (Dense)             (None, 1)                 65        \n","=================================================================\n","Total params: 138,369\n","Trainable params: 138,369\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n","Epoch 1/34\n","WARNING:tensorflow:Model was constructed with shape (None, 1) for input Tensor(\"input_2:0\", shape=(None, 1), dtype=float32), but it was called on an input with incompatible shape (None, 2000).\n","WARNING:tensorflow:Model was constructed with shape (None, 1) for input Tensor(\"input_2:0\", shape=(None, 1), dtype=float32), but it was called on an input with incompatible shape (None, 2000).\n"],"name":"stdout"},{"output_type":"error","ename":"UnimplementedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-151-97ff60f1d57f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m34\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnimplementedError\u001b[0m:  Cast string to float is not supported\n\t [[node mean_squared_error/Cast (defined at <ipython-input-151-97ff60f1d57f>:21) ]] [Op:__inference_train_function_72538]\n\nFunction call stack:\ntrain_function\n"]}]},{"cell_type":"code","metadata":{"id":"rga7nww1e9uY"},"source":["#to data preprocessing\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","\n","X = df.tweet\n","Y = df.HS_NOT\n","le = LabelEncoder()\n","Y = le.fit_transform(Y)\n","Y = Y.reshape(-1,1)\n","ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n","Y = np.array(ct.fit_transform(Y))\n","\n","#Scaling the training set\n","sc = MinMaxScaler()\n","training_set_scaled = sc.fit_transform(Y)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uJMFzHqBUB2-"},"source":["\n","X_train, X_test, y_train, y_test = train_test_split(X, y_hate, test_size = 0.20, random_state = 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MUbFQ1D4D6Nm"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UU4M7rfjVSRc"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RVsMFgYZIhO2"},"source":["# X_train = X_train.reshape(-1, 1)\n","# X_test  = X_test.reshape(-1, 1)\n","# y_test = y_test.reshape(-1, 1)\n","\n","# The LSTM architecture\n","regressor = Sequential()\n","# First LSTM layer with Dropout regularisation\n","regressor.add(LSTM(100, input_shape=(X_train.shape[1], train_X.shape[2])))\n","regressor.add(Dropout(0.2))\n","# # Second LSTM layer\n","# regressor.add(LSTM(units=50, return_sequences=True))\n","# regressor.add(Dropout(0.2))\n","# # Third LSTM layer\n","# regressor.add(LSTM(units=50, return_sequences=True))\n","# regressor.add(Dropout(0.2))\n","# Fourth LSTM layer\n","regressor.add(LSTM(units=50))\n","regressor.add(Dropout(0.2))\n","# The output layer\n","regressor.add(Dense(units=1))\n","\n","# Compiling the RNN\n","regressor.compile(optimizer='rmsprop',loss='mean_squared_error')\n","# Fitting to the training set\n","regressor.fit(X_train,y_train,epochs=50,batch_size=32)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ctXueOjNIznn"},"source":[""],"execution_count":null,"outputs":[]}]}