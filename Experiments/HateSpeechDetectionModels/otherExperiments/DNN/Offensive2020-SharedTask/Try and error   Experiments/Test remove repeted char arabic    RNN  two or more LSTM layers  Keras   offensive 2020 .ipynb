{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Test remove repeted char arabic |  RNN |two or more LSTM layers| Keras | offensive 2020 .ipynb","provenance":[{"file_id":"15x_UVSDUTLaoN_ACYGY3qgJ2LZWKnQa8","timestamp":1610486474243},{"file_id":"1ja8KruY-9DfTF1rn39m247fDgpa14q3m","timestamp":1608410488458},{"file_id":"1QkkGQfDCiFKqPTvfmxnNeL-MIiRfaJph","timestamp":1607460955296}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wTfA1AZrvcfb","executionInfo":{"status":"ok","timestamp":1611614345124,"user_tz":-120,"elapsed":21126,"user":{"displayName":"Anas Anwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh14e7jeZHMvucS_ZIrKraOikI8M1-rjfy0Wgq3=s64","userId":"17042339119135018792"}},"outputId":"a39e2cbb-7b5b-42ba-91ab-30ba1018e6a5"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x3iHYaNQGasL","executionInfo":{"status":"ok","timestamp":1611614349968,"user_tz":-120,"elapsed":2444,"user":{"displayName":"Anas Anwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh14e7jeZHMvucS_ZIrKraOikI8M1-rjfy0Wgq3=s64","userId":"17042339119135018792"}}},"source":["import tensorflow as tf\r\n","import numpy as np\r\n","from tensorflow import keras\r\n","from tensorflow.keras import layers"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a_WYr2FiGbQ-","executionInfo":{"status":"ok","timestamp":1611614356706,"user_tz":-120,"elapsed":5485,"user":{"displayName":"Anas Anwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh14e7jeZHMvucS_ZIrKraOikI8M1-rjfy0Wgq3=s64","userId":"17042339119135018792"}},"outputId":"477ef2b4-484b-4687-e014-ff85db999466"},"source":["!cat '/content/drive/MyDrive/MasterThesis/Datasets/Offensive2020/fortest/train/HS/13.txt'"],"execution_count":3,"outputs":[{"output_type":"stream","text":["@USER @USER @USER ÙŠØ§ Ù„Ø·ÙŠÙ.. ÙŠØ§ Ø³Ø§ØªØ± ..Ø£Ø­Ù…Ø¯ÙˆØ§ Ø±Ø¨ÙƒÙ… Ø¥Ù†Ù‡Ø§ Ù…Ø³ØªÙ‚Ø¹Ø¯Ø©ğŸŒšÙƒÙŠÙ Ù„Ùˆ Ø¥Ù†Ù‡Ø§ ÙˆØ§Ù‚ÙÙ‡ğŸ‘Œ\tOFF\tNOT_HS\r\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eBNAX1DHGeph","executionInfo":{"status":"ok","timestamp":1611614364281,"user_tz":-120,"elapsed":6831,"user":{"displayName":"Anas Anwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh14e7jeZHMvucS_ZIrKraOikI8M1-rjfy0Wgq3=s64","userId":"17042339119135018792"}},"outputId":"bd2787c9-ad63-47ef-a870-763820503aa3"},"source":["batch_size = 32\r\n","raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\r\n","    \"/content/drive/MyDrive/MasterThesis/Datasets/Offensive2020/fortest/train\",\r\n","    batch_size=batch_size,\r\n","    validation_split=0.2,\r\n","    subset=\"training\",\r\n","    seed=1337,\r\n","   \r\n",")\r\n","raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\r\n","    \"/content/drive/MyDrive/MasterThesis/Datasets/Offensive2020/fortest/dev\",\r\n","    batch_size=batch_size,\r\n","    validation_split=0.2,\r\n","    subset=\"validation\",\r\n","    seed=1337,\r\n","    \r\n",")\r\n","raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\r\n","    \"/content/drive/MyDrive/MasterThesis/Datasets/Offensive2020/fortest/test\", batch_size=batch_size\r\n",")\r\n","\r\n","print(\r\n","    \"Number of batches in raw_train_ds: %d\"\r\n","    % tf.data.experimental.cardinality(raw_train_ds)\r\n",")\r\n","print(\r\n","    \"Number of batches in raw_val_ds: %d\" % tf.data.experimental.cardinality(raw_val_ds)\r\n",")\r\n","print(\r\n","    \"Number of batches in raw_test_ds: %d\"\r\n","    % tf.data.experimental.cardinality(raw_test_ds)\r\n",")"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Found 26 files belonging to 2 classes.\n","Using 21 files for training.\n","Found 25 files belonging to 2 classes.\n","Using 5 files for validation.\n","Found 24 files belonging to 2 classes.\n","Number of batches in raw_train_ds: 1\n","Number of batches in raw_val_ds: 1\n","Number of batches in raw_test_ds: 1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CcD9iYX0Gx0D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611614371320,"user_tz":-120,"elapsed":6278,"user":{"displayName":"Anas Anwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh14e7jeZHMvucS_ZIrKraOikI8M1-rjfy0Wgq3=s64","userId":"17042339119135018792"}},"outputId":"8f798429-acad-4b2e-9a9a-b44dbdca9460"},"source":["# It's important to take a look at your raw data to ensure your normalization\r\n","# and tokenization will work as expected. We can do that by taking a few\r\n","# examples from the training set and looking at them.\r\n","# This is one of the places where eager execution shines:\r\n","# we can just evaluate these tensors using .numpy()\r\n","# instead of needing to evaluate them in a Session/Graph context.\r\n","for text_batch, label_batch in raw_train_ds.take(1):\r\n","    for i in range(7):\r\n","        print(text_batch.numpy()[i].decode('utf-8').strip())\r\n","        print(label_batch.numpy()[i])\r\n","        print('--------------------------------')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["@USER Ø§Ø¹Ù„Ø§Ù…ÙŠ Ù‡Ù„Ø§Ù„ÙŠ ÙˆØ´ ØªØ±Ø¬ÙŠ Ù…Ù†Ù‡ Ø§ÙŠ ÙˆØ§Ù„Ù„Ù‡ Ø§Ù„Ù‰ Ù‚Ø§Ù„ Ù…Ø­Ù…Ø¯ Ø§Ù„Ø¹ÙˆÙŠØ³ Ø­Ø±Ø§Ù‚ğŸ”¥ğŸ”¥ğŸ”¥Ø­Ø§Ø±Ù‚ Ù‚Ù„Ø¨Ùƒ ÙŠØ§ Ø²Ù‚Ø§Ù† ÙŠØ§ Ø§Ù„Ù…Ø·ÙŠÙ‹ÙˆÙŠØ¹ Ù…Ù† Ø­Ø±Ù‚ Ø¹Ø³Ø§Ù‡ Ù„Ù„Ø­Ø±Ù‚ ÙŠØ§ Ø±Ø¨ Ø¬Ø¹Ù„Ù†ÙŠ Ø§Ø´ÙˆÙ ÙÙŠÙƒ ÙŠÙˆÙ… Ø§Ø³ÙˆØ¯ Ø§Ù†Øª ÙˆØ¹Ø§Ø¦Ù„ØªÙƒ ÙŠØ§ Ø§Ø¨Ù† Ø§Ù„ÙƒÙ„Ø¨\tOFF\tNOT_HS\n","0\n","--------------------------------\n","ÙŠØ§ Ø§Ù„ØªØ§Ø¬ Ø¹ Ø§Ù„Ø±Ø§Ø³ ÙŠØ§ Ø§Ù„Ø³Ø§Ø¯Ø©<LF>ÙŠØ§ Ù…Ø§Ù„Ùƒ Ø§Ù„Ø±ÙˆØ­ ÙˆØ±Ø§Ø¹ÙŠÙ‡Ø§â¤ï¸\tNOT_OFF\tNOT_HS\n","1\n","--------------------------------\n","ÙØ¯ÙˆÙ‡ ÙŠØ§ Ø¨Ø®Øª ÙØ¯ÙˆÙ‡ ÙŠØ§ Ø²Ù…Ù† ÙˆØ§Ø­Ø¯ Ù…Ù†ÙƒÙ… ÙŠØ¬ÙŠØ¨Ù‡\tNOT_OFF\tNOT_HS\n","1\n","--------------------------------\n","@USER ÙŠØ§ Ø¨Ø¬Ù… ÙŠØ§ Ø¹Ø¬Ù… ÙŠØ§ Ù†Ø¬Ù… ÙƒÙ„Ù†Ø§ ÙØ§Ù„Ù‡ÙˆØ§ Ø³ÙˆØ§\tOFF\tNOT_HS\n","0\n","--------------------------------\n","@USER @USER @USER ÙŠØ§ Ù„Ø·ÙŠÙ.. ÙŠØ§ Ø³Ø§ØªØ± ..Ø£Ø­Ù…Ø¯ÙˆØ§ Ø±Ø¨ÙƒÙ… Ø¥Ù†Ù‡Ø§ Ù…Ø³ØªÙ‚Ø¹Ø¯Ø©ğŸŒšÙƒÙŠÙ Ù„Ùˆ Ø¥Ù†Ù‡Ø§ ÙˆØ§Ù‚ÙÙ‡ğŸ‘Œ\tOFF\tNOT_HS\n","0\n","--------------------------------\n","@USER ÙŠØ§ Ø¬Ø¯Ø¹Ø§Ù† Ø§Ù„Ø¹Ù„Ù‚ Ø¯Ø§ Ù„Ø³Ù‡ Ø¨ÙŠÙ‚ÙˆÙ„ÙŠ Ù‡Ø°Ø§ÙƒØ± Ø§Ù„Ø§Ø³Ø¦Ù„Ø© ÙƒÙØ§ÙŠØ© ØŒ Ùˆ Ø±Ø§Ø­ ÙØªØ­ ØªÙˆÙŠØªØ± .. ÙŠØ§ ÙØ§Ø´Ù„ .. ÙŠØ§ ÙØ§Ø´Ù„ ÙŠØ§ ÙØ§Ø´Ù„ ÙŠØ§ ÙØ§Ø´Ù„ ğŸ˜‚ğŸ˜‚ğŸ˜‚\tOFF\tNOT_HS\n","0\n","--------------------------------\n","@USER Ø§Ø®Ø® ÙŠØ§ Ù‚Ù„Ø¨Ø¨ÙŠ ÙŠØ§ Ù‡Ø§Ù„Ø­Ù„Ù‚Ù‡ ğŸ˜©ğŸ˜­â™¥ï¸ Ù…ØªØ¹Ù‡ Ø¹Ù„Ù‰ Ø¨ÙƒØ§Ø¡ Ø¹Ù„Ù‰ Ø­Ù…Ø§Ø³ ÙƒÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø¯Ø§Ø®Ù„Ù‡ Ø¨Ø¨Ø¹Ø¶\tNOT_OFF\tNOT_HS\n","1\n","--------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7oSIQ1Gxj9ks","colab":{"base_uri":"https://localhost:8080/","height":341},"executionInfo":{"status":"error","timestamp":1611615759795,"user_tz":-120,"elapsed":650,"user":{"displayName":"Anas Anwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh14e7jeZHMvucS_ZIrKraOikI8M1-rjfy0Wgq3=s64","userId":"17042339119135018792"}},"outputId":"444ad656-ae82-4b84-bdca-38722c54033b"},"source":["import re\r\n","import string\r\n","import sys\r\n","import argparse\r\n","from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\r\n","\r\n","\r\n","def custom_standardization(input_data):\r\n","    # lowercase = tf.strings.lower(input_data)\r\n","    # stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\r\n","    print(input_data.print())\r\n","    print(\"-------------------\")\r\n","    exit\r\n","    # input_string = re.sub(r\"([\\S])\\1+\", r\"\\1\", input_data)\r\n","    stripped_html = tf.strings.regex_replace(input_data, \"[a-zA-Z]|\\d+|[Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©]\", \" \")\r\n","    stripped_html = tf.strings.regex_replace(stripped_html, \"[.ØŒ,\\\\-_â€â€œÙªÙÙ‹]\", \" \")\r\n","    \r\n","    stripped_html = tf.strings.regex_replace(stripped_html, \"[Ø¥Ø£Ø¢Ø§]\", \"Ø§\")\r\n","    stripped_html = tf.strings.regex_replace(stripped_html, \"Ø©\", \"Ù‡\")\r\n","    stripped_html = tf.strings.regex_replace(stripped_html, \"([\\S])\\1+\", \"\\1\")\r\n","    return tf.strings.regex_replace(\r\n","        stripped_html, \"[%s]\" % re.escape(string.punctuation), \"\"\r\n","    )\r\n","\r\n","\r\n","\r\n","# Model constants.\r\n","max_features = 20000\r\n","embedding_dim = 128\r\n","sequence_length = 500\r\n","\r\n","vectorize_layer = TextVectorization(\r\n","    standardize=custom_standardization,\r\n","    max_tokens=max_features,\r\n","    output_mode=\"int\",\r\n","    output_sequence_length=sequence_length,\r\n",")\r\n","\r\n","\r\n","text_ds = raw_train_ds.map(lambda x, y: x)\r\n","vectorize_layer.adapt(text_ds)\r\n"],"execution_count":22,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-a6d26c188964>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mtext_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_train_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mvectorize_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/preprocessing/text_vectorization.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data, reset_state)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_legacy_output_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m       \u001b[0mpreprocessed_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m       raise ValueError(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1803\u001b[0m     \"\"\"\n\u001b[1;32m   1804\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1805\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1806\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1807\u001b[0m       return ParallelMapDataset(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4206\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4207\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   4208\u001b[0m     variant_tensor = gen_dataset_ops.map_dataset(\n\u001b[1;32m   4209\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3523\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3524\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3525\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3527\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3050\u001b[0m     \"\"\"\n\u001b[1;32m   3051\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 3052\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   3053\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3054\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3017\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3018\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3019\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3020\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m       captured = object_identity.ObjectIdentitySet(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3516\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3517\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3518\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3519\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3520\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3451\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3453\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3454\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3455\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    348\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/preprocessing/text_vectorization.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    575\u001b[0m                                         \"\")\n\u001b[1;32m    576\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m       raise ValueError((\"%s is not a supported standardization. \"\n","\u001b[0;32m<ipython-input-22-a6d26c188964>\u001b[0m in \u001b[0;36mcustom_standardization\u001b[0;34m(input_data)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# lowercase = tf.strings.lower(input_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mexit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'print'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iGdIU4EV_IBi","executionInfo":{"status":"ok","timestamp":1611486000691,"user_tz":-120,"elapsed":772,"user":{"displayName":"Anas Anwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh14e7jeZHMvucS_ZIrKraOikI8M1-rjfy0Wgq3=s64","userId":"17042339119135018792"}},"outputId":"0eb81115-5ed0-4956-e219-bf86b4392669"},"source":["vocab = np.array(vectorize_layer.get_vocabulary())\n","vocab[:100]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['', '[UNK]', 'ÙŠØ§', 'Ù…Ù†', 'Ø¹Ù„Ù‰', 'Ø§Ø¨Ù†', 'Ùˆ', 'ÙƒÙ„', 'ÙØ§Ø´Ù„', 'Ø³Ù„Ù…Ø§Ù†',\n","       'Ø§Ù†Øª', 'ÙˆØ§Ù„Ù„Ù‡', 'Ù‚Ù„Ø¨ÙŠ', 'Ù‚Ø§Ù„', 'Ø¹Ø§Ø´', 'Ø²Ù…Ø§Ù„Ùƒ', 'ÙŠÙˆÙ…', 'ÙˆØ§Ø­Ø¯',\n","       'Ù…Ù…Ø­ÙˆÙ†', 'Ù…Ø´', 'Ù„Ùˆ', 'Ù„Ø³Ù‡', 'ÙƒØ±ØªÙˆÙ†Ù‡', 'Ù‚Ù„Ø¨Ùƒ', 'ÙÙŠÙ†', 'ÙÙŠÙƒ', 'ÙØ¯ÙˆÙ‡',\n","       'Ø±Ø¨', 'Ø­ÙŠÙˆØ§Ù†', 'Ø­Ù„Ùˆ', 'Ø­Ù‚ÙŠÙ‚ÙŠ', 'Ø­ØªÙ‰', 'Ø¨Ù„Ø§Ø¯ÙŠ', 'Ø¨Ø³', 'Ø§Ù†Ù‡Ø§', 'Ø§Ù†Ø§',\n","       'Ø§Ù…ÙŠ', 'Ø§Ù„ÙŠÙ…Ù†', 'Ø§Ù„Ù„Ù‡', 'Ø§Ù„Ø´Ø±Ù…ÙˆØ·Ù‡', 'Ø§Ù„Ø¯ÙˆØ±ÙŠ', 'Ø§Ù„Ø­Ø²Ù…', 'Ø§Ø­Ø¨',\n","       'ğŸ˜©ğŸ˜­â™¥ï¸', 'ğŸ˜‚ğŸ˜‚ğŸ˜‚', 'ğŸ˜', 'ğŸ¼', 'âœ‹ï¸', 'âšªğŸ”´', 'ÙŠÙ…Ù†', 'ÙŠÙ…ÙƒÙ†', 'ÙŠØºÙ†ÙŠ', 'ÙŠØ¹Ù†ÙŠ',\n","       'ÙŠØ±ÙˆØ­', 'ÙŠØ­Ø±Ù‚', 'ÙŠØ¬ÙŠØ¨Ù‡', 'ÙŠØ§Ø±Ø¨', 'ÙŠØ§Ø®Ø¯', 'ÙŠ', 'ÙˆÙŠÙ„Ø§', 'ÙˆÙŠÙƒØ³Ø±',\n","       'ÙˆÙŠØ¹', 'ÙˆÙ‚Ø¯Ø±Ù‡', 'ÙˆØ¹Ø§Ø¦Ù„ØªÙƒ', 'ÙˆØ´', 'ÙˆØ±Ø§Ø¹ÙŠÙ‡Ø§â¤ï¸', 'ÙˆØ¬ÙˆÙ‡ÙƒÙ…', 'ÙˆØ¬Ø¹',\n","       'ÙˆØ¨Ù†Ø²ÙŠÙ†ÙƒÙ…', 'ÙˆØ§Ù‚ÙÙ‡ğŸ‘Œ', 'ÙˆØ§Ø³ØªØ§Ø°Ù†', 'Ù‡ÙŠØ¹Ù…Ù„ÙˆØ§', 'Ù‡ÙˆØ§', 'Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡',\n","       'Ù‡Ù†Ø§Ø§Ø§Ø§Ø§', 'Ù‡Ù…Ø§', 'Ù‡Ù„Ø§Ù„ÙŠ', 'Ù‡Ø°Ø§ÙƒØ±', 'Ù‡Ø§Ù‡Ø§Ù‡Ø§Ù‡Ø§Ù‡Ø§', 'Ù‡Ø§Ù„Ø­Ù„Ù‚Ù‡',\n","       'Ù†ÙƒØ³Ø¨', 'Ù†Ù‚Ù', 'Ù†ÙØ¶Ù„', 'Ù†ÙØ³ÙŠ', 'Ù†ØµØ§Ø¨ÙŠÙ†', 'Ù†Ø¬Ù…', 'Ù†ØªØ¹Ø§Ø¯Ù„', 'Ù†Ø§ÙƒÙ‡Ø§',\n","       'Ù…ÙŠØ¬ÙŠØ´', 'Ù…ÙˆØ²Ù‡', 'Ù…Ù‡Ù…', 'Ù…Ù†Ù‡', 'Ù…Ù†ÙƒÙ…', 'Ù…Ù†Ø®Ø³Ø±Ø´', 'Ù…Ù…Ø­ÙˆÙˆÙ†',\n","       'Ù…Ù…Ø­ÙˆÙ†Ù‡', 'Ù…Ù„Ùƒ', 'Ù…Ø¹ÙÙ†ÙŠÙ†', 'Ù…Ø¹Ø±Øµ', 'Ù…ØµØ±ÙŠ'], dtype='<U11')"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"ZNssU_LzDm6V"},"source":["# # s=tf.strings.regex_replace(\"Ù…Ø´ÙƒÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆØ±\",r'(\\w)\\1*','')\r\n","# repeat_pattern = re.compile(r'(\\w)\\1*')\r\n","# y=tf.strings.regex_full_match(\r\n","#     \"happpppppppy\",\r\n","#     \"(\\w)\\1*\",\r\n","#     name=None\r\n","# )\r\n","# # str(s, encoding='cp1252')\r\n","# # s.decode('utf8').encode('latin1').decode('utf8')\r\n","# # s=tf.strings.unicode_transcode(str(s), \"US ASCII\", \"UTF-8\").numpy()\r\n","# # print()\r\n","# # print(u''.encode('utf-8')+s)\r\n","# # y=tf.constant(\"Ù…Ø´ÙƒÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆØ±\")\r\n","# print(y)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FKokewub8uK7"},"source":["# # re.sub(r'(.)\\1+', r'\\1', \"haaaaapppppyyy\")  \r\n","# # re.sub(r'(\\w)\\1+', r'\\1', \"Ù…Ø´ÙƒÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆÙˆØ±\")  \r\n","# repeat_pattern = re.compile(r'(\\w)\\1*')\r\n","# repeat_pattern.sub(r'\\1','Ù…Ø´ÙƒÙˆÙˆÙˆÙˆÙˆÙˆÙˆØ±')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BxJIanrPG2KK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611484495226,"user_tz":-120,"elapsed":717,"user":{"displayName":"Anas Anwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh14e7jeZHMvucS_ZIrKraOikI8M1-rjfy0Wgq3=s64","userId":"17042339119135018792"}},"outputId":"1ff1f650-6540-47e5-cdcf-311cf57014d3"},"source":["vocab = np.array(vectorize_layer.get_vocabulary())\r\n","vocab[:100]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['', '[UNK]', 'ÙŠØ§', 'Ù…Ù†', 'Ø¹Ù„Ù‰', 'Ø§Ø¨Ù†', 'Ùˆ', 'ÙƒÙ„', 'ÙØ§Ø´Ù„', 'Ø³Ù„Ù…Ø§Ù†',\n","       'Ø§Ù†Øª', 'ÙˆØ§Ù„Ù„Ù‡', 'Ù‚Ù„Ø¨ÙŠ', 'Ù‚Ø§Ù„', 'Ø¹Ø§Ø´', 'Ø²Ù…Ø§Ù„Ùƒ', 'ÙŠÙˆÙ…', 'ÙˆØ§Ø­Ø¯',\n","       'Ù…Ù…Ø­ÙˆÙ†', 'Ù…Ø´', 'Ù„Ùˆ', 'Ù„Ø³Ù‡', 'ÙƒØ±ØªÙˆÙ†Ù‡', 'Ù‚Ù„Ø¨Ùƒ', 'ÙÙŠÙ†', 'ÙÙŠÙƒ', 'ÙØ¯ÙˆÙ‡',\n","       'Ø±Ø¨', 'Ø­ÙŠÙˆØ§Ù†', 'Ø­Ù„Ùˆ', 'Ø­Ù‚ÙŠÙ‚ÙŠ', 'Ø­ØªÙ‰', 'Ø¨Ù„Ø§Ø¯ÙŠ', 'Ø¨Ø³', 'Ø§Ù†Ù‡Ø§', 'Ø§Ù†Ø§',\n","       'Ø§Ù…ÙŠ', 'Ø§Ù„ÙŠÙ…Ù†', 'Ø§Ù„Ù„Ù‡', 'Ø§Ù„Ø´Ø±Ù…ÙˆØ·Ù‡', 'Ø§Ù„Ø¯ÙˆØ±ÙŠ', 'Ø§Ù„Ø­Ø²Ù…', 'Ø§Ø­Ø¨',\n","       'ğŸ˜©ğŸ˜­â™¥ï¸', 'ğŸ˜‚ğŸ˜‚ğŸ˜‚', 'ğŸ˜', 'ğŸ¼', 'âœ‹ï¸', 'âšªğŸ”´', 'ÙŠÙ…Ù†', 'ÙŠÙ…ÙƒÙ†', 'ÙŠØºÙ†ÙŠ', 'ÙŠØ¹Ù†ÙŠ',\n","       'ÙŠØ±ÙˆØ­', 'ÙŠØ­Ø±Ù‚', 'ÙŠØ¬ÙŠØ¨Ù‡', 'ÙŠØ§Ø±Ø¨', 'ÙŠØ§Ø®Ø¯', 'ÙŠ', 'ÙˆÙŠÙ„Ø§', 'ÙˆÙŠÙƒØ³Ø±',\n","       'ÙˆÙŠØ¹', 'ÙˆÙ‚Ø¯Ø±Ù‡', 'ÙˆØ¹Ø§Ø¦Ù„ØªÙƒ', 'ÙˆØ´', 'ÙˆØ±Ø§Ø¹ÙŠÙ‡Ø§â¤ï¸', 'ÙˆØ¬ÙˆÙ‡ÙƒÙ…', 'ÙˆØ¬Ø¹',\n","       'ÙˆØ¨Ù†Ø²ÙŠÙ†ÙƒÙ…', 'ÙˆØ§Ù‚ÙÙ‡ğŸ‘Œ', 'ÙˆØ§Ø³ØªØ§Ø°Ù†', 'Ù‡ÙŠØ¹Ù…Ù„ÙˆØ§', 'Ù‡ÙˆØ§', 'Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡',\n","       'Ù‡Ù†Ø§Ø§Ø§Ø§Ø§', 'Ù‡Ù…Ø§', 'Ù‡Ù„Ø§Ù„ÙŠ', 'Ù‡Ø°Ø§ÙƒØ±', 'Ù‡Ø§Ù‡Ø§Ù‡Ø§Ù‡Ø§Ù‡Ø§', 'Ù‡Ø§Ù„Ø­Ù„Ù‚Ù‡',\n","       'Ù†ÙƒØ³Ø¨', 'Ù†Ù‚Ù', 'Ù†ÙØ¶Ù„', 'Ù†ÙØ³ÙŠ', 'Ù†ØµØ§Ø¨ÙŠÙ†', 'Ù†Ø¬Ù…', 'Ù†ØªØ¹Ø§Ø¯Ù„', 'Ù†Ø§ÙƒÙ‡Ø§',\n","       'Ù…ÙŠØ¬ÙŠØ´', 'Ù…ÙˆØ²Ù‡', 'Ù…Ù‡Ù…', 'Ù…Ù†Ù‡', 'Ù…Ù†ÙƒÙ…', 'Ù…Ù†Ø®Ø³Ø±Ø´', 'Ù…Ù…Ø­ÙˆÙˆÙ†',\n","       'Ù…Ù…Ø­ÙˆÙ†Ù‡', 'Ù…Ù„Ùƒ', 'Ù…Ø¹ÙÙ†ÙŠÙ†', 'Ù…Ø¹Ø±Øµ', 'Ù…ØµØ±ÙŠ'], dtype='<U11')"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"-kNQmzlnaR7o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611482475177,"user_tz":-120,"elapsed":643,"user":{"displayName":"Anas Anwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh14e7jeZHMvucS_ZIrKraOikI8M1-rjfy0Wgq3=s64","userId":"17042339119135018792"}},"outputId":"6aa0442a-6b68-4995-992d-698e044788bd"},"source":["encoded_example = vectorize_layer(text_batch)[:20].numpy()\r\n","encoded_example"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[268,  76,  64, ...,   0,   0,   0],\n","       [  2, 257, 149, ...,   0,   0,   0],\n","       [ 26,   2, 214, ...,   0,   0,   0],\n","       ...,\n","       [  2,  27,   2, ...,   0,   0,   0],\n","       [ 24,   2, 181, ...,   0,   0,   0],\n","       [209, 226,   2, ...,   0,   0,   0]])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"SCMlCLF3ache","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611484505453,"user_tz":-120,"elapsed":671,"user":{"displayName":"Anas Anwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh14e7jeZHMvucS_ZIrKraOikI8M1-rjfy0Wgq3=s64","userId":"17042339119135018792"}},"outputId":"6075924f-6fe9-4128-f5fb-f0a9467e87c7"},"source":["for n in range(5):\r\n","  print(\"Original: \", text_batch[n].numpy().decode())\r\n","  print(\"Round-trip: \", \" \".join(vocab[encoded_example[n]]))\r\n","  print()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Original:  RT @USER: Ø¬Ø§Ù„Ø³ Ø£Ø³Ù…Ø¹ Ø£Ø­Ù…Ø¯ Ù‚Ø§Ø³Ù… ÙŠØºÙ†ÙŠ: \"Ø£Ø­Ø¨Ùƒ Ù…Ù† ÙƒÙ„ Ù‚Ù„Ø¨ÙŠ ÙŠØ§ Ø¨Ù„Ø§Ø¯ÙŠ ÙŠØ§ ÙŠÙ…Ù†\". Ø­ØªÙ‰ Ø£Ù†Ø§ ÙˆØ§Ù„Ù„Ù‡ Ø£Ø­Ø¨ Ø§Ù„ÙŠÙ…Ù† Ù…Ù† ÙƒÙ„ Ù‚Ù„Ø¨ÙŠ Ø£Ø­Ø¨ Ø¨Ù„Ø§Ø¯ÙŠ Ù…Ù† Ø·Ø±ÙÙ‡Ø§ Ù„Ø·Ø±ÙÙ‡Ø§ \"Ø¨â€¦\tNOT_OFF\tNOT_HS\r\n","\n","Round-trip:  Ø§Ø¹Ù„Ø§Ù…ÙŠ Ù‡Ù„Ø§Ù„ÙŠ ÙˆØ´ ØªØ±Ø¬ÙŠ Ù…Ù†Ù‡ Ø§ÙŠ ÙˆØ§Ù„Ù„Ù‡ Ø§Ù„Ù‰ Ù‚Ø§Ù„ Ù…Ø­Ù…Ø¯ Ø§Ù„Ø¹ÙˆÙŠØ³ Ø­Ø±Ø§Ù‚ğŸ”¥ğŸ”¥ğŸ”¥Ø­Ø§Ø±Ù‚ Ù‚Ù„Ø¨Ùƒ ÙŠØ§ Ø²Ù‚Ø§Ù† ÙŠØ§ Ø§Ù„Ù…Ø·ÙŠ ÙˆÙŠØ¹ Ù…Ù† Ø­Ø±Ù‚ Ø¹Ø³Ø§Ù‡ Ù„Ù„Ø­Ø±Ù‚ ÙŠØ§ Ø±Ø¨ Ø¬Ø¹Ù„Ù†ÙŠ Ø§Ø´ÙˆÙ ÙÙŠÙƒ ÙŠÙˆÙ… Ø§Ø³ÙˆØ¯ Ø§Ù†Øª ÙˆØ¹Ø§Ø¦Ù„ØªÙƒ ÙŠØ§ Ø§Ø¨Ù† Ø§Ù„ÙƒÙ„Ø¨                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n","\n","Original:  ÙŠØ§ Ø¨ÙƒÙˆÙ† Ø¨Ø­ÙŠØ§ØªÙƒ Ø§Ù„Ø£Ù‡Ù… ÙŠØ§ Ø¥Ù…Ø§ Ù…Ø§ Ø¨Ø¯ÙŠ Ø£ÙƒÙˆÙ† ğŸ¼\tNOT_OFF\tNOT_HS\r\n","\n","Round-trip:  ÙŠØ§ Ø§Ù„ØªØ§Ø¬ Ø¹ Ø§Ù„Ø±Ø§Ø³ ÙŠØ§ Ø§Ù„Ø³Ø§Ø¯Ù‡ ÙŠØ§ Ù…Ø§Ù„Ùƒ Ø§Ù„Ø±ÙˆØ­ ÙˆØ±Ø§Ø¹ÙŠÙ‡Ø§â¤ï¸                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n","\n","Original:  Ù‡Ù…Ø§ Ø¨ÙŠØ¹Ù…Ù„ÙˆØ§ Ø§ÙŠÙ‡ !! Ø§Ù†Øª ÙŠØ§ Ø­ÙŠÙˆØ§Ù† Ø§Ù†Øª ÙŠØ§ Ø§Ø·Ø±Ø±Ø±Ø´ Ø§Ù†Ø§ Ø¨Ø³Ù‚Ø· Ù‡Ù†Ø§Ø§Ø§Ø§Ø§ URL\tOFF\tNOT_HS\r\n","\n","Round-trip:  ÙØ¯ÙˆÙ‡ ÙŠØ§ Ø¨Ø®Øª ÙØ¯ÙˆÙ‡ ÙŠØ§ Ø²Ù…Ù† ÙˆØ§Ø­Ø¯ Ù…Ù†ÙƒÙ… ÙŠØ¬ÙŠØ¨Ù‡                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n","\n","Original:  RT @USER: @USER Ø§Ù„Ø¨Ø±Ø§Ø¨ Ø¹Ù†Ø¯Ù‰ Ø¨ÙŠÙ‚ÙˆÙ„Ù‰ Ø¨ÙŠØ®ÙŠØ±ÙˆÙƒ ÙŠØ§ ÙƒØ±ØªÙˆÙ†Ø© ÙŠØ§ Ø®Ù…Ø³ÙŠÙ† Ø¬Ù†ÙŠÙ‡ ÙˆØ§Ø³ØªØ£Ø°Ù† ÙŠØ±ÙˆØ­ ÙŠØ§Ø®Ø¯ ÙƒØ±ØªÙˆÙ†Ø© ğŸ˜\tNOT_OFF\tNOT_HS\r\n","\n","Round-trip:  ÙŠØ§ Ø¨Ø¬Ù… ÙŠØ§ Ø¹Ø¬Ù… ÙŠØ§ Ù†Ø¬Ù… ÙƒÙ„Ù†Ø§ ÙØ§Ù„Ù‡ÙˆØ§ Ø³ÙˆØ§                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n","\n","Original:  Ø´Ø®ØµÙŠØ© Ø®ÙŠØ§Ù„ÙŠØ© Ù…Ù…Ø­ÙˆÙ†Ø©: Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ù…Ù…Ø§Ø­ÙŠÙ†!<LF>Ø¥Ù†Ø³Ø§Ù† Ø­Ù‚ÙŠÙ‚ÙŠ Ù…Ù…Ø­ÙˆÙ†: ÙŠØ§ Ù…Ù…Ø­ÙˆÙ† ÙŠØ§ Ø­ÙŠÙˆØ§Ù† ØªØ¹Ø§Ù„ Ø§Ù‚Ø·Ø¹ Ù„Ùƒ Ø²Ø¨Ùƒ Ø­ØªÙ‰ Ù„Ùˆ Ø¬Ø­Ø± ÙØ§Ø± ØªØ¨ØºØ§ ØªÙ†ÙŠÙƒÙˆ ÙŠØ§ Ù…Ù…Ø­ÙˆÙˆÙ† Ù‚Ø§Ù„ Ù†ÙØ³ÙŠ Ø§ØªÙ…ØªØ¹ Ù‚Ø§Ù„\tOFF\tNOT_HS\r\n","\n","Round-trip:  ÙŠØ§ Ù„Ø·ÙŠÙ ÙŠØ§ Ø³Ø§ØªØ± Ø§Ø­Ù…Ø¯ÙˆØ§ Ø±Ø¨ÙƒÙ… Ø§Ù†Ù‡Ø§ Ù…Ø³ØªÙ‚Ø¹Ø¯Ù‡ğŸŒšÙƒÙŠÙ Ù„Ùˆ Ø§Ù†Ù‡Ø§ ÙˆØ§Ù‚ÙÙ‡ğŸ‘Œ                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"duPBAns5X3F_"},"source":["# from numpy import array\r\n","# from numpy import asarray\r\n","# from numpy import zeros\r\n","\r\n","# embeddings_dictionary = dict()\r\n","# glove_file = open('E:/Datasets/Word Embeddings/glove.6B.100d.txt', encoding=\"utf8\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bxiWBqGba04S"},"source":["# Create the model"]},{"cell_type":"code","metadata":{"id":"CS_rTLWxaqoE"},"source":["model = tf.keras.Sequential([\r\n","    vectorize_layer,\r\n","    tf.keras.layers.Embedding(len(vectorize_layer.get_vocabulary()), 64, mask_zero=True),\r\n","    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\r\n","    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\r\n","    tf.keras.layers.Dense(64, activation='relu'),\r\n","    tf.keras.layers.Dropout(0.5),\r\n","    tf.keras.layers.Dense(1)\r\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rosrX61Ya4mF"},"source":["model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\r\n","              optimizer=tf.keras.optimizers.Adam(1e-4),\r\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3jyJmWGwbDy_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611340225900,"user_tz":-120,"elapsed":20671,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"03a62544-65f9-4491-cdcf-516a1aaa111d"},"source":["from keras.callbacks import EarlyStopping\r\n","\r\n","history = model.fit(raw_train_ds, epochs=30,\r\n","                    validation_data=raw_val_ds, \r\n","                    validation_steps=30,\r\n","                    callbacks=[EarlyStopping(monitor='val_loss',patience=5)]\r\n","                    )\r\n","\r\n","\r\n","# history=model.fit(train_ds, validation_data=val_ds, epochs=epochs,\r\n","#           callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","1/1 [==============================] - ETA: 0s - loss: 0.6920 - accuracy: 0.6190WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 30 batches). You may need to use the repeat() function when building your dataset.\n","1/1 [==============================] - 18s 18s/step - loss: 0.6920 - accuracy: 0.6190 - val_loss: 0.6957 - val_accuracy: 0.4000\n","Epoch 2/30\n","1/1 [==============================] - 0s 67ms/step - loss: 0.6932 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 3/30\n","1/1 [==============================] - 0s 66ms/step - loss: 0.6915 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 4/30\n","1/1 [==============================] - 0s 67ms/step - loss: 0.6910 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 5/30\n","1/1 [==============================] - 0s 68ms/step - loss: 0.6910 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 6/30\n","1/1 [==============================] - 0s 65ms/step - loss: 0.6890 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 7/30\n","1/1 [==============================] - 0s 79ms/step - loss: 0.6919 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 8/30\n","1/1 [==============================] - 0s 68ms/step - loss: 0.6890 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 9/30\n","1/1 [==============================] - 0s 74ms/step - loss: 0.6904 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 10/30\n","1/1 [==============================] - 0s 71ms/step - loss: 0.6890 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 11/30\n","1/1 [==============================] - 0s 80ms/step - loss: 0.6897 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 12/30\n","1/1 [==============================] - 0s 74ms/step - loss: 0.6891 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 13/30\n","1/1 [==============================] - 0s 75ms/step - loss: 0.6881 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 14/30\n","1/1 [==============================] - 0s 73ms/step - loss: 0.6875 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 15/30\n","1/1 [==============================] - 0s 69ms/step - loss: 0.6870 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 16/30\n","1/1 [==============================] - 0s 66ms/step - loss: 0.6873 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 17/30\n","1/1 [==============================] - 0s 79ms/step - loss: 0.6867 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 18/30\n","1/1 [==============================] - 0s 67ms/step - loss: 0.6888 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 19/30\n","1/1 [==============================] - 0s 78ms/step - loss: 0.6866 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 20/30\n","1/1 [==============================] - 0s 72ms/step - loss: 0.6860 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 21/30\n","1/1 [==============================] - 0s 73ms/step - loss: 0.6873 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 22/30\n","1/1 [==============================] - 0s 66ms/step - loss: 0.6847 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 23/30\n","1/1 [==============================] - 0s 72ms/step - loss: 0.6830 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 24/30\n","1/1 [==============================] - 0s 68ms/step - loss: 0.6850 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 25/30\n","1/1 [==============================] - 0s 73ms/step - loss: 0.6849 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 26/30\n","1/1 [==============================] - 0s 72ms/step - loss: 0.6826 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 27/30\n","1/1 [==============================] - 0s 74ms/step - loss: 0.6830 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 28/30\n","1/1 [==============================] - 0s 67ms/step - loss: 0.6834 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 29/30\n","1/1 [==============================] - 0s 67ms/step - loss: 0.6797 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 30/30\n","1/1 [==============================] - 0s 71ms/step - loss: 0.6808 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1HNhwjehbVjv"},"source":["test_loss, test_acc = model.evaluate(raw_test_ds)\r\n","\r\n","print('Test Loss: {}'.format(test_loss))\r\n","print('Test Accuracy: {}'.format(test_acc))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y3mzafzzlP5A"},"source":["import matplotlib.pyplot as plt\r\n","acc = history.history['accuracy']\r\n","val_acc = history.history['val_accuracy']\r\n","\r\n","loss=history.history['loss']\r\n","val_loss=history.history['val_loss']\r\n","\r\n","#epochs_range = range(22)\r\n","\r\n","plt.figure(figsize=(15, 15))\r\n","plt.subplot(1, 2, 1)\r\n","plt.plot(acc, label='Training Accuracy')\r\n","plt.plot(val_acc, label='Validation Accuracy')\r\n","plt.legend(loc='lower right')\r\n","plt.title('Training and Validation Accuracy')\r\n","\r\n","plt.subplot(1, 2, 2)\r\n","plt.plot(loss, label='Training Loss')\r\n","plt.plot(val_loss, label='Validation Loss')\r\n","plt.legend(loc='upper right')\r\n","plt.title('Training and Validation Loss')\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T8zls0wytbv4"},"source":["sample_text = (' ÙŠØ§ Ø­Ø¨ÙŠØ¨ÙŠ Ø¨ÙƒÙ„ ØµÙØ§ØªÛ ÙŠØ§ Ø¯Ù…ÙˆØ¹ Ùˆ ÙŠØ§ Ø®Ø¶ÙˆØ¹  ')\r\n","predictions = model.predict(np.array([sample_text]))\r\n","predictions\r\n","#NOT hate speech"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UQce8atfuw2Q"},"source":["sample_text = (' Ø§Ù„Ù‚Ù… ÙŠØ§ Ø§ÙŠØ·Ø§Ù„ÙŠ ÙŠØ§ Ø§Ø¨Ù† Ø§Ù„ÙƒÙ„Ø¨ Ø§Ù†Øª Ùˆ Ø¨Ø§ØµÙƒ ÙŠÙ„Ø¹Ù† Ø§Ù‡Ù„Ùƒ  ')\r\n","predictions = model.predict(np.array([sample_text]))\r\n","predictions\r\n","#Hate"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FxLuitza5as7"},"source":[""],"execution_count":null,"outputs":[]}]}