{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Test remove repeted char arabic |  RNN |two or more LSTM layers| Keras | offensive 2020 .ipynb","provenance":[{"file_id":"15x_UVSDUTLaoN_ACYGY3qgJ2LZWKnQa8","timestamp":1610486474243},{"file_id":"1ja8KruY-9DfTF1rn39m247fDgpa14q3m","timestamp":1608410488458},{"file_id":"1QkkGQfDCiFKqPTvfmxnNeL-MIiRfaJph","timestamp":1607460955296}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wTfA1AZrvcfb","executionInfo":{"status":"ok","timestamp":1611614345124,"user_tz":-120,"elapsed":21126,"user":{"displayName":"Anas Anwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh14e7jeZHMvucS_ZIrKraOikI8M1-rjfy0Wgq3=s64","userId":"17042339119135018792"}},"outputId":"a39e2cbb-7b5b-42ba-91ab-30ba1018e6a5"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x3iHYaNQGasL","executionInfo":{"status":"ok","timestamp":1611614349968,"user_tz":-120,"elapsed":2444,"user":{"displayName":"Anas Anwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh14e7jeZHMvucS_ZIrKraOikI8M1-rjfy0Wgq3=s64","userId":"17042339119135018792"}}},"source":["import tensorflow as tf\r\n","import numpy as np\r\n","from tensorflow import keras\r\n","from tensorflow.keras import layers"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a_WYr2FiGbQ-","executionInfo":{"status":"ok","timestamp":1611614356706,"user_tz":-120,"elapsed":5485,"user":{"displayName":"Anas Anwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh14e7jeZHMvucS_ZIrKraOikI8M1-rjfy0Wgq3=s64","userId":"17042339119135018792"}},"outputId":"477ef2b4-484b-4687-e014-ff85db999466"},"source":["!cat '/content/drive/MyDrive/MasterThesis/Datasets/Offensive2020/fortest/train/HS/13.txt'"],"execution_count":3,"outputs":[{"output_type":"stream","text":["@USER @USER @USER يا لطيف.. يا ساتر ..أحمدوا ربكم إنها مستقعدة🌚كيف لو إنها واقفه👌\tOFF\tNOT_HS\r\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eBNAX1DHGeph","executionInfo":{"status":"ok","timestamp":1611614364281,"user_tz":-120,"elapsed":6831,"user":{"displayName":"Anas Anwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh14e7jeZHMvucS_ZIrKraOikI8M1-rjfy0Wgq3=s64","userId":"17042339119135018792"}},"outputId":"bd2787c9-ad63-47ef-a870-763820503aa3"},"source":["batch_size = 32\r\n","raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\r\n","    \"/content/drive/MyDrive/MasterThesis/Datasets/Offensive2020/fortest/train\",\r\n","    batch_size=batch_size,\r\n","    validation_split=0.2,\r\n","    subset=\"training\",\r\n","    seed=1337,\r\n","   \r\n",")\r\n","raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\r\n","    \"/content/drive/MyDrive/MasterThesis/Datasets/Offensive2020/fortest/dev\",\r\n","    batch_size=batch_size,\r\n","    validation_split=0.2,\r\n","    subset=\"validation\",\r\n","    seed=1337,\r\n","    \r\n",")\r\n","raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\r\n","    \"/content/drive/MyDrive/MasterThesis/Datasets/Offensive2020/fortest/test\", batch_size=batch_size\r\n",")\r\n","\r\n","print(\r\n","    \"Number of batches in raw_train_ds: %d\"\r\n","    % tf.data.experimental.cardinality(raw_train_ds)\r\n",")\r\n","print(\r\n","    \"Number of batches in raw_val_ds: %d\" % tf.data.experimental.cardinality(raw_val_ds)\r\n",")\r\n","print(\r\n","    \"Number of batches in raw_test_ds: %d\"\r\n","    % tf.data.experimental.cardinality(raw_test_ds)\r\n",")"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Found 26 files belonging to 2 classes.\n","Using 21 files for training.\n","Found 25 files belonging to 2 classes.\n","Using 5 files for validation.\n","Found 24 files belonging to 2 classes.\n","Number of batches in raw_train_ds: 1\n","Number of batches in raw_val_ds: 1\n","Number of batches in raw_test_ds: 1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CcD9iYX0Gx0D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611614371320,"user_tz":-120,"elapsed":6278,"user":{"displayName":"Anas Anwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh14e7jeZHMvucS_ZIrKraOikI8M1-rjfy0Wgq3=s64","userId":"17042339119135018792"}},"outputId":"8f798429-acad-4b2e-9a9a-b44dbdca9460"},"source":["# It's important to take a look at your raw data to ensure your normalization\r\n","# and tokenization will work as expected. We can do that by taking a few\r\n","# examples from the training set and looking at them.\r\n","# This is one of the places where eager execution shines:\r\n","# we can just evaluate these tensors using .numpy()\r\n","# instead of needing to evaluate them in a Session/Graph context.\r\n","for text_batch, label_batch in raw_train_ds.take(1):\r\n","    for i in range(7):\r\n","        print(text_batch.numpy()[i].decode('utf-8').strip())\r\n","        print(label_batch.numpy()[i])\r\n","        print('--------------------------------')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["@USER اعلامي هلالي وش ترجي منه اي والله الى قال محمد العويس حراق🔥🔥🔥حارق قلبك يا زقان يا المطيًويع من حرق عساه للحرق يا رب جعلني اشوف فيك يوم اسود انت وعائلتك يا ابن الكلب\tOFF\tNOT_HS\n","0\n","--------------------------------\n","يا التاج ع الراس يا السادة<LF>يا مالك الروح وراعيها❤️\tNOT_OFF\tNOT_HS\n","1\n","--------------------------------\n","فدوه يا بخت فدوه يا زمن واحد منكم يجيبه\tNOT_OFF\tNOT_HS\n","1\n","--------------------------------\n","@USER يا بجم يا عجم يا نجم كلنا فالهوا سوا\tOFF\tNOT_HS\n","0\n","--------------------------------\n","@USER @USER @USER يا لطيف.. يا ساتر ..أحمدوا ربكم إنها مستقعدة🌚كيف لو إنها واقفه👌\tOFF\tNOT_HS\n","0\n","--------------------------------\n","@USER يا جدعان العلق دا لسه بيقولي هذاكر الاسئلة كفاية ، و راح فتح تويتر .. يا فاشل .. يا فاشل يا فاشل يا فاشل 😂😂😂\tOFF\tNOT_HS\n","0\n","--------------------------------\n","@USER اخخ يا قلببي يا هالحلقه 😩😭♥️ متعه على بكاء على حماس كل المشاعر داخله ببعض\tNOT_OFF\tNOT_HS\n","1\n","--------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7oSIQ1Gxj9ks","colab":{"base_uri":"https://localhost:8080/","height":341},"executionInfo":{"status":"error","timestamp":1611615759795,"user_tz":-120,"elapsed":650,"user":{"displayName":"Anas Anwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh14e7jeZHMvucS_ZIrKraOikI8M1-rjfy0Wgq3=s64","userId":"17042339119135018792"}},"outputId":"444ad656-ae82-4b84-bdca-38722c54033b"},"source":["import re\r\n","import string\r\n","import sys\r\n","import argparse\r\n","from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\r\n","\r\n","\r\n","def custom_standardization(input_data):\r\n","    # lowercase = tf.strings.lower(input_data)\r\n","    # stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\r\n","    print(input_data.print())\r\n","    print(\"-------------------\")\r\n","    exit\r\n","    # input_string = re.sub(r\"([\\S])\\1+\", r\"\\1\", input_data)\r\n","    stripped_html = tf.strings.regex_replace(input_data, \"[a-zA-Z]|\\d+|[٠١٢٣٤٥٦٧٨٩]\", \" \")\r\n","    stripped_html = tf.strings.regex_replace(stripped_html, \"[.،,\\\\-_”“٪ًَ]\", \" \")\r\n","    \r\n","    stripped_html = tf.strings.regex_replace(stripped_html, \"[إأآا]\", \"ا\")\r\n","    stripped_html = tf.strings.regex_replace(stripped_html, \"ة\", \"ه\")\r\n","    stripped_html = tf.strings.regex_replace(stripped_html, \"([\\S])\\1+\", \"\\1\")\r\n","    return tf.strings.regex_replace(\r\n","        stripped_html, \"[%s]\" % re.escape(string.punctuation), \"\"\r\n","    )\r\n","\r\n","\r\n","\r\n","# Model constants.\r\n","max_features = 20000\r\n","embedding_dim = 128\r\n","sequence_length = 500\r\n","\r\n","vectorize_layer = TextVectorization(\r\n","    standardize=custom_standardization,\r\n","    max_tokens=max_features,\r\n","    output_mode=\"int\",\r\n","    output_sequence_length=sequence_length,\r\n",")\r\n","\r\n","\r\n","text_ds = raw_train_ds.map(lambda x, y: x)\r\n","vectorize_layer.adapt(text_ds)\r\n"],"execution_count":22,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-a6d26c188964>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mtext_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_train_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mvectorize_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/preprocessing/text_vectorization.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data, reset_state)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_legacy_output_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m       \u001b[0mpreprocessed_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m       raise ValueError(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1803\u001b[0m     \"\"\"\n\u001b[1;32m   1804\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1805\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1806\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1807\u001b[0m       return ParallelMapDataset(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4206\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4207\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   4208\u001b[0m     variant_tensor = gen_dataset_ops.map_dataset(\n\u001b[1;32m   4209\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3523\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3524\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3525\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3527\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3050\u001b[0m     \"\"\"\n\u001b[1;32m   3051\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 3052\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   3053\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3054\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3017\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3018\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3019\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3020\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m       captured = object_identity.ObjectIdentitySet(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3516\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3517\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3518\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3519\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3520\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3451\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3453\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3454\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3455\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    348\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/preprocessing/text_vectorization.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    575\u001b[0m                                         \"\")\n\u001b[1;32m    576\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m       raise ValueError((\"%s is not a supported standardization. \"\n","\u001b[0;32m<ipython-input-22-a6d26c188964>\u001b[0m in \u001b[0;36mcustom_standardization\u001b[0;34m(input_data)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# lowercase = tf.strings.lower(input_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mexit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'print'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iGdIU4EV_IBi","executionInfo":{"status":"ok","timestamp":1611486000691,"user_tz":-120,"elapsed":772,"user":{"displayName":"Anas Anwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh14e7jeZHMvucS_ZIrKraOikI8M1-rjfy0Wgq3=s64","userId":"17042339119135018792"}},"outputId":"0eb81115-5ed0-4956-e219-bf86b4392669"},"source":["vocab = np.array(vectorize_layer.get_vocabulary())\n","vocab[:100]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['', '[UNK]', 'يا', 'من', 'على', 'ابن', 'و', 'كل', 'فاشل', 'سلمان',\n","       'انت', 'والله', 'قلبي', 'قال', 'عاش', 'زمالك', 'يوم', 'واحد',\n","       'ممحون', 'مش', 'لو', 'لسه', 'كرتونه', 'قلبك', 'فين', 'فيك', 'فدوه',\n","       'رب', 'حيوان', 'حلو', 'حقيقي', 'حتى', 'بلادي', 'بس', 'انها', 'انا',\n","       'امي', 'اليمن', 'الله', 'الشرموطه', 'الدوري', 'الحزم', 'احب',\n","       '😩😭♥️', '😂😂😂', '😁', '🎼', '✋️', '⚪🔴', 'يمن', 'يمكن', 'يغني', 'يعني',\n","       'يروح', 'يحرق', 'يجيبه', 'يارب', 'ياخد', 'ي', 'ويلا', 'ويكسر',\n","       'ويع', 'وقدره', 'وعائلتك', 'وش', 'وراعيها❤️', 'وجوهكم', 'وجع',\n","       'وبنزينكم', 'واقفه👌', 'واستاذن', 'هيعملوا', 'هوا', 'ههههههه',\n","       'هنااااا', 'هما', 'هلالي', 'هذاكر', 'هاهاهاهاها', 'هالحلقه',\n","       'نكسب', 'نقف', 'نفضل', 'نفسي', 'نصابين', 'نجم', 'نتعادل', 'ناكها',\n","       'ميجيش', 'موزه', 'مهم', 'منه', 'منكم', 'منخسرش', 'ممحوون',\n","       'ممحونه', 'ملك', 'معفنين', 'معرص', 'مصري'], dtype='<U11')"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"ZNssU_LzDm6V"},"source":["# # s=tf.strings.regex_replace(\"مشكووووووووور\",r'(\\w)\\1*','')\r\n","# repeat_pattern = re.compile(r'(\\w)\\1*')\r\n","# y=tf.strings.regex_full_match(\r\n","#     \"happpppppppy\",\r\n","#     \"(\\w)\\1*\",\r\n","#     name=None\r\n","# )\r\n","# # str(s, encoding='cp1252')\r\n","# # s.decode('utf8').encode('latin1').decode('utf8')\r\n","# # s=tf.strings.unicode_transcode(str(s), \"US ASCII\", \"UTF-8\").numpy()\r\n","# # print()\r\n","# # print(u''.encode('utf-8')+s)\r\n","# # y=tf.constant(\"مشكووووووووووور\")\r\n","# print(y)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FKokewub8uK7"},"source":["# # re.sub(r'(.)\\1+', r'\\1', \"haaaaapppppyyy\")  \r\n","# # re.sub(r'(\\w)\\1+', r'\\1', \"مشكووووووووووور\")  \r\n","# repeat_pattern = re.compile(r'(\\w)\\1*')\r\n","# repeat_pattern.sub(r'\\1','مشكووووووور')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BxJIanrPG2KK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611484495226,"user_tz":-120,"elapsed":717,"user":{"displayName":"Anas Anwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh14e7jeZHMvucS_ZIrKraOikI8M1-rjfy0Wgq3=s64","userId":"17042339119135018792"}},"outputId":"1ff1f650-6540-47e5-cdcf-311cf57014d3"},"source":["vocab = np.array(vectorize_layer.get_vocabulary())\r\n","vocab[:100]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['', '[UNK]', 'يا', 'من', 'على', 'ابن', 'و', 'كل', 'فاشل', 'سلمان',\n","       'انت', 'والله', 'قلبي', 'قال', 'عاش', 'زمالك', 'يوم', 'واحد',\n","       'ممحون', 'مش', 'لو', 'لسه', 'كرتونه', 'قلبك', 'فين', 'فيك', 'فدوه',\n","       'رب', 'حيوان', 'حلو', 'حقيقي', 'حتى', 'بلادي', 'بس', 'انها', 'انا',\n","       'امي', 'اليمن', 'الله', 'الشرموطه', 'الدوري', 'الحزم', 'احب',\n","       '😩😭♥️', '😂😂😂', '😁', '🎼', '✋️', '⚪🔴', 'يمن', 'يمكن', 'يغني', 'يعني',\n","       'يروح', 'يحرق', 'يجيبه', 'يارب', 'ياخد', 'ي', 'ويلا', 'ويكسر',\n","       'ويع', 'وقدره', 'وعائلتك', 'وش', 'وراعيها❤️', 'وجوهكم', 'وجع',\n","       'وبنزينكم', 'واقفه👌', 'واستاذن', 'هيعملوا', 'هوا', 'ههههههه',\n","       'هنااااا', 'هما', 'هلالي', 'هذاكر', 'هاهاهاهاها', 'هالحلقه',\n","       'نكسب', 'نقف', 'نفضل', 'نفسي', 'نصابين', 'نجم', 'نتعادل', 'ناكها',\n","       'ميجيش', 'موزه', 'مهم', 'منه', 'منكم', 'منخسرش', 'ممحوون',\n","       'ممحونه', 'ملك', 'معفنين', 'معرص', 'مصري'], dtype='<U11')"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"-kNQmzlnaR7o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611482475177,"user_tz":-120,"elapsed":643,"user":{"displayName":"Anas Anwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh14e7jeZHMvucS_ZIrKraOikI8M1-rjfy0Wgq3=s64","userId":"17042339119135018792"}},"outputId":"6aa0442a-6b68-4995-992d-698e044788bd"},"source":["encoded_example = vectorize_layer(text_batch)[:20].numpy()\r\n","encoded_example"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[268,  76,  64, ...,   0,   0,   0],\n","       [  2, 257, 149, ...,   0,   0,   0],\n","       [ 26,   2, 214, ...,   0,   0,   0],\n","       ...,\n","       [  2,  27,   2, ...,   0,   0,   0],\n","       [ 24,   2, 181, ...,   0,   0,   0],\n","       [209, 226,   2, ...,   0,   0,   0]])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"SCMlCLF3ache","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611484505453,"user_tz":-120,"elapsed":671,"user":{"displayName":"Anas Anwar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh14e7jeZHMvucS_ZIrKraOikI8M1-rjfy0Wgq3=s64","userId":"17042339119135018792"}},"outputId":"6075924f-6fe9-4128-f5fb-f0a9467e87c7"},"source":["for n in range(5):\r\n","  print(\"Original: \", text_batch[n].numpy().decode())\r\n","  print(\"Round-trip: \", \" \".join(vocab[encoded_example[n]]))\r\n","  print()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Original:  RT @USER: جالس أسمع أحمد قاسم يغني: \"أحبك من كل قلبي يا بلادي يا يمن\". حتى أنا والله أحب اليمن من كل قلبي أحب بلادي من طرفها لطرفها \"ب…\tNOT_OFF\tNOT_HS\r\n","\n","Round-trip:  اعلامي هلالي وش ترجي منه اي والله الى قال محمد العويس حراق🔥🔥🔥حارق قلبك يا زقان يا المطي ويع من حرق عساه للحرق يا رب جعلني اشوف فيك يوم اسود انت وعائلتك يا ابن الكلب                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n","\n","Original:  يا بكون بحياتك الأهم يا إما ما بدي أكون 🎼\tNOT_OFF\tNOT_HS\r\n","\n","Round-trip:  يا التاج ع الراس يا الساده يا مالك الروح وراعيها❤️                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n","\n","Original:  هما بيعملوا ايه !! انت يا حيوان انت يا اطرررش انا بسقط هنااااا URL\tOFF\tNOT_HS\r\n","\n","Round-trip:  فدوه يا بخت فدوه يا زمن واحد منكم يجيبه                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n","\n","Original:  RT @USER: @USER البراب عندى بيقولى بيخيروك يا كرتونة يا خمسين جنيه واستأذن يروح ياخد كرتونة 😁\tNOT_OFF\tNOT_HS\r\n","\n","Round-trip:  يا بجم يا عجم يا نجم كلنا فالهوا سوا                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n","\n","Original:  شخصية خيالية ممحونة: حقوق المماحين!<LF>إنسان حقيقي ممحون: يا ممحون يا حيوان تعال اقطع لك زبك حتى لو جحر فار تبغا تنيكو يا ممحوون قال نفسي اتمتع قال\tOFF\tNOT_HS\r\n","\n","Round-trip:  يا لطيف يا ساتر احمدوا ربكم انها مستقعده🌚كيف لو انها واقفه👌                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"duPBAns5X3F_"},"source":["# from numpy import array\r\n","# from numpy import asarray\r\n","# from numpy import zeros\r\n","\r\n","# embeddings_dictionary = dict()\r\n","# glove_file = open('E:/Datasets/Word Embeddings/glove.6B.100d.txt', encoding=\"utf8\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bxiWBqGba04S"},"source":["# Create the model"]},{"cell_type":"code","metadata":{"id":"CS_rTLWxaqoE"},"source":["model = tf.keras.Sequential([\r\n","    vectorize_layer,\r\n","    tf.keras.layers.Embedding(len(vectorize_layer.get_vocabulary()), 64, mask_zero=True),\r\n","    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\r\n","    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\r\n","    tf.keras.layers.Dense(64, activation='relu'),\r\n","    tf.keras.layers.Dropout(0.5),\r\n","    tf.keras.layers.Dense(1)\r\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rosrX61Ya4mF"},"source":["model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\r\n","              optimizer=tf.keras.optimizers.Adam(1e-4),\r\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3jyJmWGwbDy_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611340225900,"user_tz":-120,"elapsed":20671,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"03a62544-65f9-4491-cdcf-516a1aaa111d"},"source":["from keras.callbacks import EarlyStopping\r\n","\r\n","history = model.fit(raw_train_ds, epochs=30,\r\n","                    validation_data=raw_val_ds, \r\n","                    validation_steps=30,\r\n","                    callbacks=[EarlyStopping(monitor='val_loss',patience=5)]\r\n","                    )\r\n","\r\n","\r\n","# history=model.fit(train_ds, validation_data=val_ds, epochs=epochs,\r\n","#           callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","1/1 [==============================] - ETA: 0s - loss: 0.6920 - accuracy: 0.6190WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 30 batches). You may need to use the repeat() function when building your dataset.\n","1/1 [==============================] - 18s 18s/step - loss: 0.6920 - accuracy: 0.6190 - val_loss: 0.6957 - val_accuracy: 0.4000\n","Epoch 2/30\n","1/1 [==============================] - 0s 67ms/step - loss: 0.6932 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 3/30\n","1/1 [==============================] - 0s 66ms/step - loss: 0.6915 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 4/30\n","1/1 [==============================] - 0s 67ms/step - loss: 0.6910 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 5/30\n","1/1 [==============================] - 0s 68ms/step - loss: 0.6910 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 6/30\n","1/1 [==============================] - 0s 65ms/step - loss: 0.6890 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 7/30\n","1/1 [==============================] - 0s 79ms/step - loss: 0.6919 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 8/30\n","1/1 [==============================] - 0s 68ms/step - loss: 0.6890 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 9/30\n","1/1 [==============================] - 0s 74ms/step - loss: 0.6904 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 10/30\n","1/1 [==============================] - 0s 71ms/step - loss: 0.6890 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 11/30\n","1/1 [==============================] - 0s 80ms/step - loss: 0.6897 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 12/30\n","1/1 [==============================] - 0s 74ms/step - loss: 0.6891 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 13/30\n","1/1 [==============================] - 0s 75ms/step - loss: 0.6881 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 14/30\n","1/1 [==============================] - 0s 73ms/step - loss: 0.6875 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 15/30\n","1/1 [==============================] - 0s 69ms/step - loss: 0.6870 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 16/30\n","1/1 [==============================] - 0s 66ms/step - loss: 0.6873 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 17/30\n","1/1 [==============================] - 0s 79ms/step - loss: 0.6867 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 18/30\n","1/1 [==============================] - 0s 67ms/step - loss: 0.6888 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 19/30\n","1/1 [==============================] - 0s 78ms/step - loss: 0.6866 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 20/30\n","1/1 [==============================] - 0s 72ms/step - loss: 0.6860 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 21/30\n","1/1 [==============================] - 0s 73ms/step - loss: 0.6873 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 22/30\n","1/1 [==============================] - 0s 66ms/step - loss: 0.6847 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 23/30\n","1/1 [==============================] - 0s 72ms/step - loss: 0.6830 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 24/30\n","1/1 [==============================] - 0s 68ms/step - loss: 0.6850 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 25/30\n","1/1 [==============================] - 0s 73ms/step - loss: 0.6849 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 26/30\n","1/1 [==============================] - 0s 72ms/step - loss: 0.6826 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 27/30\n","1/1 [==============================] - 0s 74ms/step - loss: 0.6830 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 28/30\n","1/1 [==============================] - 0s 67ms/step - loss: 0.6834 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 29/30\n","1/1 [==============================] - 0s 67ms/step - loss: 0.6797 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n","Epoch 30/30\n","1/1 [==============================] - 0s 71ms/step - loss: 0.6808 - accuracy: 0.6190\n","WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1HNhwjehbVjv"},"source":["test_loss, test_acc = model.evaluate(raw_test_ds)\r\n","\r\n","print('Test Loss: {}'.format(test_loss))\r\n","print('Test Accuracy: {}'.format(test_acc))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y3mzafzzlP5A"},"source":["import matplotlib.pyplot as plt\r\n","acc = history.history['accuracy']\r\n","val_acc = history.history['val_accuracy']\r\n","\r\n","loss=history.history['loss']\r\n","val_loss=history.history['val_loss']\r\n","\r\n","#epochs_range = range(22)\r\n","\r\n","plt.figure(figsize=(15, 15))\r\n","plt.subplot(1, 2, 1)\r\n","plt.plot(acc, label='Training Accuracy')\r\n","plt.plot(val_acc, label='Validation Accuracy')\r\n","plt.legend(loc='lower right')\r\n","plt.title('Training and Validation Accuracy')\r\n","\r\n","plt.subplot(1, 2, 2)\r\n","plt.plot(loss, label='Training Loss')\r\n","plt.plot(val_loss, label='Validation Loss')\r\n","plt.legend(loc='upper right')\r\n","plt.title('Training and Validation Loss')\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T8zls0wytbv4"},"source":["sample_text = (' يا حبيبي بكل صفاتہ يا دموع و يا خضوع  ')\r\n","predictions = model.predict(np.array([sample_text]))\r\n","predictions\r\n","#NOT hate speech"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UQce8atfuw2Q"},"source":["sample_text = (' القم يا ايطالي يا ابن الكلب انت و باصك يلعن اهلك  ')\r\n","predictions = model.predict(np.array([sample_text]))\r\n","predictions\r\n","#Hate"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FxLuitza5as7"},"source":[""],"execution_count":null,"outputs":[]}]}