{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Copy of text_classification_Keras_HS_offiensive2020.ipynb","provenance":[{"file_id":"1KLqCDh2qbdkCUoTM9x0RmaCNGjAb1XpS","timestamp":1605434443274}],"collapsed_sections":[],"mount_file_id":"1aag2eFdMLJYr_hx0inNy0fZAk0jbaDw9","authorship_tag":"ABX9TyMRZ/0ACNEgDnsExh0dxGLd"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"mYJ3KGNAa0Ix"},"source":["import tensorflow as tf\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0fdOKnwDrabZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14210,"status":"ok","timestamp":1605453686627,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"},"user_tz":-120},"outputId":"dd09b4c5-d469-462a-fe0b-9f3e4ae94936"},"source":["!cat '/content/drive/My Drive/MasterThesis/Datasets/Offensive2020/train/HS/1002.txt'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["RT @USER: خلاص يا استيعابي يا جزمه بكره اختبار deal with itايش حركات الإجازه هذي خلاص عاد\tOFF\tNOT_HS\r\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gfRAxzRxLxcC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47954,"status":"ok","timestamp":1605453722735,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"},"user_tz":-120},"outputId":"ce18394c-cb2c-44b1-de8e-ecca169ead47"},"source":["batch_size = 32\n","raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n","    \"/content/drive/My Drive/MasterThesis/Datasets/Offensive2020/train\",\n","    batch_size=batch_size,\n","    validation_split=0.2,\n","    subset=\"training\",\n","    seed=1337,\n",")\n","raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n","    \"/content/drive/My Drive/MasterThesis/Datasets/Offensive2020/dev\",\n","    batch_size=batch_size,\n","    validation_split=0.2,\n","    subset=\"validation\",\n","    seed=1337,\n",")\n","raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n","    \"/content/drive/My Drive/MasterThesis/Datasets/Offensive2020/test\", batch_size=batch_size\n",")\n","\n","print(\n","    \"Number of batches in raw_train_ds: %d\"\n","    % tf.data.experimental.cardinality(raw_train_ds)\n",")\n","print(\n","    \"Number of batches in raw_val_ds: %d\" % tf.data.experimental.cardinality(raw_val_ds)\n",")\n","print(\n","    \"Number of batches in raw_test_ds: %d\"\n","    % tf.data.experimental.cardinality(raw_test_ds)\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 7000 files belonging to 2 classes.\n","Using 5600 files for training.\n","Found 7000 files belonging to 2 classes.\n","Using 1400 files for validation.\n","Found 3470 files belonging to 2 classes.\n","Number of batches in raw_train_ds: 175\n","Number of batches in raw_val_ds: 44\n","Number of batches in raw_test_ds: 109\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ydTH5bCXK_kS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":174157,"status":"ok","timestamp":1605453854041,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"},"user_tz":-120},"outputId":"eaf08627-8281-4df5-bb22-561aea2716fc"},"source":["# It's important to take a look at your raw data to ensure your normalization\n","# and tokenization will work as expected. We can do that by taking a few\n","# examples from the training set and looking at them.\n","# This is one of the places where eager execution shines:\n","# we can just evaluate these tensors using .numpy()\n","# instead of needing to evaluate them in a Session/Graph context.\n","for text_batch, label_batch in raw_train_ds.take(1):\n","    for i in range(5):\n","        print(text_batch.numpy()[i].decode('utf-8').strip())\n","        print(label_batch.numpy()[i])\n","        print('--------------------------------')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["عندي مشكلة كبيرة مع الناس اللي تشرحلهاا انت ايه وعيوبك ايه ومابتحبش ايه فايعملوا كل اللي انت حذرتهم منه ومايتخيلوش رد فعلك ويقولوا اتصدمناا فيك، ياعالم يا جزم يا ولاد الافاعي اومال اناا كنت بشرح في ايه من الاول\tOFF\tNOT_HS\n","0\n","--------------------------------\n","@USER عاااااااااااااااااااااااااااااااش يا ميرووو يا ميرا يا ميرتااااا احبك❤️❤️❤️😭\tNOT_OFF\tNOT_HS\n","1\n","--------------------------------\n","المشكلة في البلد دي إنك لو قلت للحلو يا حلو في عيونه يا إما بياخد قلم في نفسه أو بيخزقلك عيونك..!\tNOT_OFF\tNOT_HS\n","1\n","--------------------------------\n","#اطمن_انت_مش_لوحدك<LF>الخرفان انتخت الي الابد<LF>حاسس بيك يا مهتز يا ابن المط..رر.الاقبال النهاردة كان تاريخي لا نفع معاهم اطمن و لا بلالين و لا كتابة علي الحيطان و لا الفلوس و لا الحلل و لا الغطيان <LF>يا قهرتك يا مهتز<LF>يا فضيحتكم يا خرفان<LF>الخرفان هيتجننو <LF>السيسي هينفخكم ١٠ سنين اني هههه\tOFF\tHS\n","0\n","--------------------------------\n","@USER يا زيدي يا زيدي <LF>ايه الشعر ده المتنبي في زمانه<LF>هههههههه\tNOT_OFF\tNOT_HS\n","1\n","--------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QxrhvJ1MBjhm","colab":{"background_save":true}},"source":["from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n","import string\n","import re\n","\n","def custom_standardization(input_data):\n","    lowercase = tf.strings.lower(input_data)\n","    stripped_html = tf.strings.regex_replace(lowercase, \"<LF>\", \" \")\n","    return tf.strings.regex_replace(\n","        stripped_html, \"[%s]\" % re.escape(string.punctuation), \"\"\n","    )\n","\n","max_features = 20000\n","embedding_dim = 128\n","sequence_length = 500\n","\n","\n","vectorize_layer = TextVectorization(\n","    standardize=custom_standardization,\n","    max_tokens=max_features,\n","    output_mode=\"int\",\n","    output_sequence_length=sequence_length,\n",")\n","\n","\n","text_ds = raw_train_ds.map(lambda x, y: x)\n","vectorize_layer.adapt(text_ds)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VwhbmPnsi4S-","colab":{"background_save":true}},"source":["def vectorize_text(text, label):\n","    text = tf.expand_dims(text, -1)\n","    return vectorize_layer(text), label\n","\n","\n","# Vectorize the data.\n","train_ds = raw_train_ds.map(vectorize_text)\n","val_ds = raw_val_ds.map(vectorize_text)\n","test_ds = raw_test_ds.map(vectorize_text)\n","\n","# Do async prefetching / buffering of the data for best performance on GPU.\n","train_ds = train_ds.cache().prefetch(buffer_size=10)\n","val_ds = val_ds.cache().prefetch(buffer_size=10)\n","test_ds = test_ds.cache().prefetch(buffer_size=10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xv-M7bb6khq1"},"source":["## Build a model "]},{"cell_type":"code","metadata":{"id":"WCohoIbMhVj9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a476b4ec-10cb-49f9-cc83-08929795507d"},"source":["from tensorflow.keras import layers\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(max_features, 64),\n","    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n","    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n","    tf.keras.layers.Dense(64, activation='relu'),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.Dense(1)\n","])\n","model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n","              optimizer=tf.keras.optimizers.Adam(1e-4),\n","              metrics=['accuracy'])\n","history = model.fit(train_ds, epochs=10,\n","                    validation_data=val_ds,\n","                    validation_steps=30)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","175/175 [==============================] - ETA: 0s - loss: 0.5485 - accuracy: 0.6164"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yUxWhjJRkvX2"},"source":["## Train the model"]},{"cell_type":"code","metadata":{"id":"6f40euEzkly4"},"source":["# epochs = 3\n","\n","# # Fit the model using the train and test datasets.\n","# history = model.fit(train_ds, validation_data=val_ds, epochs=epochs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"edg-1dgVk31a"},"source":["## Evaluate the model on the test set\n"]},{"cell_type":"code","metadata":{"id":"LpyFcJNDlTa_"},"source":["test_loss, test_acc = model.evaluate(test_ds)\n","\n","print('Test Loss: {}'.format(test_loss))\n","print('Test Accuracy: {}'.format(test_acc))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B83gmSdHlAAJ"},"source":["## plotlib"]},{"cell_type":"code","metadata":{"id":"HKvke9H8k-DJ"},"source":["import matplotlib.pyplot as plt\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","\n","#epochs_range = range(22)\n","\n","plt.figure(figsize=(15, 15))\n","plt.subplot(1, 2, 1)\n","plt.plot(acc, label='Training Accuracy')\n","plt.plot(val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(loss, label='Training Loss')\n","plt.plot(val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hKOwfY9olYJG"},"source":[""],"execution_count":null,"outputs":[]}]}