{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"text_classification_Keras_RNN_HS_offiensive2020.ipynb","provenance":[{"file_id":"1KLqCDh2qbdkCUoTM9x0RmaCNGjAb1XpS","timestamp":1607421370359}],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1v44ybwShRPuXy2ZQWxU2fLphhuOW46kh","authorship_tag":"ABX9TyOf1Wvf9c5vW3r6AkWCpLj7"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"Ek7o3RHY68X0","executionInfo":{"status":"ok","timestamp":1607459177955,"user_tz":-120,"elapsed":1125,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# !pip install tensorflow --upgrade\r\n"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"mYJ3KGNAa0Ix","executionInfo":{"status":"ok","timestamp":1607459181201,"user_tz":-120,"elapsed":738,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["import tensorflow as tf\n","import numpy as np"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"0fdOKnwDrabZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607459188197,"user_tz":-120,"elapsed":1066,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"3c30a49b-75da-4839-ec9d-36c065ab75df"},"source":["!cat '/content/drive/My Drive/MasterThesis/Datasets/Offensive2020/trainDev/NOT_OFF/1000.txt'"],"execution_count":33,"outputs":[{"output_type":"stream","text":["@USER @USER ان شاء الله يا غالي حبيبي يا محمد<LF>ودايما متجمعين علي عشق الكيان\tNOT_OFF\tNOT_HS\r\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gfRAxzRxLxcC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607459189169,"user_tz":-120,"elapsed":2029,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"6b152b20-5474-4edc-ee6c-b835c14b487d"},"source":["batch_size = 32\n","raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n","    \"/content/drive/My Drive/MasterThesis/Datasets/Offensive2020/trainDev\",\n","    batch_size=batch_size,\n","    validation_split=0.2,\n","    subset=\"training\",\n","    seed=1337,\n","   \n",")\n","raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n","    \"/content/drive/My Drive/MasterThesis/Datasets/Offensive2020/trainDev\",\n","    batch_size=batch_size,\n","    validation_split=0.2,\n","    subset=\"validation\",\n","    seed=1337,\n","    \n",")\n","raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n","    \"/content/drive/My Drive/MasterThesis/Datasets/Offensive2020/test\", batch_size=batch_size\n",")\n","\n","print(\n","    \"Number of batches in raw_train_ds: %d\"\n","    % tf.data.experimental.cardinality(raw_train_ds)\n",")\n","print(\n","    \"Number of batches in raw_val_ds: %d\" % tf.data.experimental.cardinality(raw_val_ds)\n",")\n","print(\n","    \"Number of batches in raw_test_ds: %d\"\n","    % tf.data.experimental.cardinality(raw_test_ds)\n",")"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Found 8000 files belonging to 2 classes.\n","Using 6400 files for training.\n","Found 8000 files belonging to 2 classes.\n","Using 1600 files for validation.\n","Found 2000 files belonging to 2 classes.\n","Number of batches in raw_train_ds: 200\n","Number of batches in raw_val_ds: 50\n","Number of batches in raw_test_ds: 63\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ydTH5bCXK_kS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607459192733,"user_tz":-120,"elapsed":995,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"6ac90246-1255-45f2-ff90-225e8152c887"},"source":["# It's important to take a look at your raw data to ensure your normalization\n","# and tokenization will work as expected. We can do that by taking a few\n","# examples from the training set and looking at them.\n","# This is one of the places where eager execution shines:\n","# we can just evaluate these tensors using .numpy()\n","# instead of needing to evaluate them in a Session/Graph context.\n","for text_batch, label_batch in raw_train_ds.take(1):\n","    for i in range(5):\n","        print(text_batch.numpy()[i].decode('utf-8').strip())\n","        print(label_batch.numpy()[i])\n","        print('--------------------------------')"],"execution_count":35,"outputs":[{"output_type":"stream","text":["RT @USER: يا رب يا عزيز يا جبار .. انك القادر على كل شيء .. يا رب فرحه اتحاديه تُنسينا كل الهموم والمشاكل الي صارت هالموسم يا رب العباد…\tNOT_OFF\tNOT_HS\n","0\n","--------------------------------\n","@USER @USER يا جامع يا رقيب يا رب تلقاها\tNOT_OFF\tNOT_HS\n","0\n","--------------------------------\n","راهنت عليك ولم اخسر ❤️❤️<LF>يا وحش يا جلاد يا كبير<LF>يا مرعب يا قناص يا يصياد<LF>🖤💛🖤💛🖤💛🖤💛<LF>#الاتحاد_النصر URL\tNOT_OFF\tNOT_HS\n","0\n","--------------------------------\n","RT @USER: كانت أيام يا وطني<LF>زي الأحلام يا وطني 🎶\tNOT_OFF\tNOT_HS\n","0\n","--------------------------------\n","تمثيل يا رزان تمثيل يا رزان تمثيل يا رزان تمثيل يا رزان تمثيل يا رزان تمثيل يا رزان\tNOT_OFF\tNOT_HS\n","0\n","--------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gqj9sdkEmgvW","executionInfo":{"status":"ok","timestamp":1607459194957,"user_tz":-120,"elapsed":842,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# demoji.download_codes()"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"e-Hvm7q3BX4y","executionInfo":{"status":"ok","timestamp":1607459237712,"user_tz":-120,"elapsed":7139,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["import string\r\n","import re\r\n","\r\n","# Having looked at our data above, we see that the raw text contains HTML break\r\n","# tags of the form '<br />'. These tags will not be removed by the default\r\n","# standardizer (which doesn't strip HTML). Because of this, we will need to\r\n","# create a custom standardization function.\r\n","def custom_standardization(input_data):\r\n","    lowercase = tf.strings.lower(input_data)\r\n","    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\r\n","    return tf.strings.regex_replace(\r\n","        stripped_html, \"[%s]\" % re.escape(string.punctuation), \"\"\r\n","    )\r\n","\r\n","\r\n","# Model constants.\r\n","max_features = 20000\r\n","embedding_dim = 128\r\n","sequence_length = 500\r\n","\r\n","# Now that we have our custom standardization, we can instantiate our text\r\n","# vectorization layer. We are using this layer to normalize, split, and map\r\n","# strings to integers, so we set our 'output_mode' to 'int'.\r\n","# Note that we're using the default split function,\r\n","# and the custom standardization defined above.\r\n","# We also set an explicit maximum sequence length, since the CNNs later in our\r\n","# model won't support ragged sequences.\r\n","vectorize_layer = TextVectorization(\r\n","    # standardize=custom_standardization,\r\n","    max_tokens=max_features,\r\n","    output_mode=\"int\",\r\n","    output_sequence_length=sequence_length,\r\n",")\r\n","\r\n","# Now that the vocab layer has been created, call `adapt` on a text-only\r\n","# dataset to create the vocabulary. You don't have to batch, but for very large\r\n","# datasets this means you're not keeping spare copies of the dataset in memory.\r\n","\r\n","# Let's make a text-only dataset (no labels):\r\n","text_ds = raw_train_ds.map(lambda x, y: x)\r\n","# Let's call `adapt`:\r\n","vectorize_layer.adapt(text_ds)"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"id":"QxrhvJ1MBjhm","executionInfo":{"status":"ok","timestamp":1607459239975,"user_tz":-120,"elapsed":776,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n","# import string\n","# import re\n","# def custom_standardization(input_data):\n","#     # lowercase = tf.strings.lower(input_data)\n","#     # stripped_html = tf.strings.regex_replace(lowercase, \"<LF>\", \" \")\n","#     stripped_html = tf.strings.regex_replace(input_data, \"[a-zA-Z]|\\d+|[٠١٢٣٤٥٦٧٨٩]\", \" \")\n","#     after_remove_punctuation = tf.strings.regex_replace(stripped_html, \"[.،,!?؟\\\\-”“٪ًَ]\", \" \")\n","    \n","#     after_remove_hamza = tf.strings.regex_replace(after_remove_punctuation, \"[إأآا]\", \"ا\")\n","#     after_remove_Altaa = tf.strings.regex_replace(after_remove_hamza, \"ة\", \"ه\")\n","#     after_remove_emoji=tf.strings.regex_replace(after_remove_Altaa, \"[(\\U0001F600-\\U0001F92F|\\U0001F300-\\U0001F5FF|\\U0001F680-\\U0001F6FF|\\U0001F190-\\U0001F1FF|\\U00002702-\\U000027B0|\\U0001F926-\\U0001FA9F|\\u200d|\\u2640-\\u2642|\\u2600-\\u2B55|\\u23cf|\\u23e9|\\u231a|\\ufe0f)|\\u2069|\\u2066]+\", \" \")\n","#     after_remove_repeating_char = tf.strings.regex_replace(after_remove_emoji, \"r'(.)\\1+'\", \"r'\\1\\1'\")\n","\n","#     return tf.strings.regex_replace(\n","#        after_remove_repeating_char, \"[%s]\" % re.escape(string.punctuation), \"\"\n","#     )\n","   \n","# max_features = 20000\n","# embedding_dim = 128\n","# sequence_length = 500\n","\n","# vectorize_layer = TextVectorization(\n","#     # standardize=custom_standardization,\n","#     max_tokens=max_features,\n","#     output_mode=\"int\",\n","#     output_sequence_length=sequence_length,\n","# )\n","\n","# text_ds = raw_train_ds.map(lambda x, y: x)\n","# vectorize_layer.adapt(text_ds)\n"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"VwhbmPnsi4S-","executionInfo":{"status":"ok","timestamp":1607459241999,"user_tz":-120,"elapsed":686,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["def vectorize_text(text, label):\n","    text = tf.expand_dims(text, -1)\n","    return vectorize_layer(text), label\n","\n","\n","# Vectorize the data.\n","train_ds = raw_train_ds.map(vectorize_text)\n","val_ds = raw_val_ds.map(vectorize_text)\n","test_ds = raw_test_ds.map(vectorize_text)\n","\n","# Do async prefetching / buffering of the data for best performance on GPU.\n","train_ds = train_ds.cache().prefetch(buffer_size=10)\n","val_ds = val_ds.cache().prefetch(buffer_size=10)\n","test_ds = test_ds.cache().prefetch(buffer_size=10)"],"execution_count":52,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y0f9DNMrXQ5o","executionInfo":{"status":"ok","timestamp":1607459243195,"user_tz":-120,"elapsed":741,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# vocab = np.array(vectorize_layer.get_vocabulary())\n","# vocab[:50]"],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"id":"mFmq_L7hXUWm","executionInfo":{"status":"ok","timestamp":1607459204415,"user_tz":-120,"elapsed":2161,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# vectorize_layer"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"Brh_6hl-XNrJ","executionInfo":{"status":"ok","timestamp":1607459204416,"user_tz":-120,"elapsed":2115,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# encoded_example = vectorize_layer(text_batch)[:50].numpy()\n","# encoded_example"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"l-oM174FXM0H","executionInfo":{"status":"ok","timestamp":1607459204417,"user_tz":-120,"elapsed":2082,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# for n in range(4):\n","#   print(\"Original: \", text_batch[n].numpy().decode('utf-8').strip())\n","#   print(\"Round-trip: \", \" \".join(vocab[encoded_example[n]]))\n","#   print()"],"execution_count":43,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xv-M7bb6khq1"},"source":["## Build a model "]},{"cell_type":"code","metadata":{"id":"WCohoIbMhVj9","executionInfo":{"status":"ok","timestamp":1607459246474,"user_tz":-120,"elapsed":675,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# from tensorflow.keras import layers\n","# model = tf.keras.Sequential([\n","#     tf.keras.layers.Embedding(max_features, 64),\n","#     tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n","#     tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n","#     tf.keras.layers.Dense(64, activation='relu'),\n","#     tf.keras.layers.Dropout(0.5),\n","#     tf.keras.layers.Dense(1)\n","# ])\n","\n","model = tf.keras.Sequential([\n","    vectorize_layer,\n","    tf.keras.layers.Embedding(\n","        input_dim=len(vectorize_layer.get_vocabulary()),\n","        output_dim=64,\n","        # Use masking to handle the variable sequence lengths\n","        mask_zero=True),\n","    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n","    tf.keras.layers.Dense(64, activation='relu'),\n","    tf.keras.layers.Dense(1)\n","])"],"execution_count":54,"outputs":[]},{"cell_type":"code","metadata":{"id":"2F6ngMDZZnXJ","executionInfo":{"status":"ok","timestamp":1607459248555,"user_tz":-120,"elapsed":1341,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# print([layer.supports_masking for layer in model.layers])"],"execution_count":55,"outputs":[]},{"cell_type":"code","metadata":{"id":"UoyqzZOYZrIM","executionInfo":{"status":"ok","timestamp":1607459248869,"user_tz":-120,"elapsed":1374,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# # predict on a sample text without padding.\n","\n","# sample_text = ('وانت يا لص يا متصهين لا تمثل المجتمع الكوردي')\n","# predictions = model.predict(np.array([sample_text]))\n","# print(predictions[0])"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"id":"jQbTtw1SZt2Z","executionInfo":{"status":"ok","timestamp":1607459248870,"user_tz":-120,"elapsed":1181,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["\n","# # predict on a sample text with padding\n","\n","# padding = \" ال\" * 2000\n","# predictions = model.predict(np.array([sample_text, padding]))\n","# print(predictions[0])"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"id":"fGqb_es5ZxfX","executionInfo":{"status":"ok","timestamp":1607459248872,"user_tz":-120,"elapsed":686,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n","              optimizer=tf.keras.optimizers.Adam(1e-4),\n","              metrics=['accuracy'])\n","# model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"],"execution_count":58,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yUxWhjJRkvX2"},"source":["## Train the model"]},{"cell_type":"code","metadata":{"id":"6f40euEzkly4","colab":{"base_uri":"https://localhost:8080/","height":935},"executionInfo":{"status":"error","timestamp":1607459252084,"user_tz":-120,"elapsed":644,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"32d2a81b-ce72-4bcf-9b30-c4eb1466a7d0"},"source":["history = model.fit(train_ds, \n","                    epochs=10,\n","                    validation_data=val_ds,\n","                    validation_steps=30\n","                    )\n","                  \n","                  \n","                    # steps_per_epoch=30\n","                    "],"execution_count":59,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n"],"name":"stdout"},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-59-817b6a10f966>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                     )\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:386 call\n        outputs = layer(inputs, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/preprocessing/text_vectorization.py:571 call\n        inputs = self._preprocess(inputs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/preprocessing/text_vectorization.py:527 _preprocess\n        lowercase_inputs = gen_string_ops.string_lower(inputs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_string_ops.py:1028 string_lower\n        \"StringLower\", input=input, encoding=encoding, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:493 _apply_op_helper\n        (prefix, dtypes.as_dtype(input_arg.type).name))\n\n    TypeError: Input 'input' of 'StringLower' Op has type int64 that does not match expected type of string.\n"]}]},{"cell_type":"markdown","metadata":{"id":"edg-1dgVk31a"},"source":["## Evaluate the model on the test set\n"]},{"cell_type":"code","metadata":{"id":"LpyFcJNDlTa_","executionInfo":{"status":"aborted","timestamp":1607459204421,"user_tz":-120,"elapsed":1553,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["test_loss, test_acc = model.evaluate(test_ds)\n","\n","print('Test Loss: {}'.format(test_loss))\n","print('Test Accuracy: {}'.format(test_acc))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B83gmSdHlAAJ"},"source":["## plotlib"]},{"cell_type":"code","metadata":{"id":"HKvke9H8k-DJ","executionInfo":{"status":"aborted","timestamp":1607459204422,"user_tz":-120,"elapsed":1464,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["import matplotlib.pyplot as plt\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","\n","#epochs_range = range(22)\n","\n","plt.figure(figsize=(15, 15))\n","plt.subplot(1, 2, 1)\n","plt.plot(acc, label='Training Accuracy')\n","plt.plot(val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(loss, label='Training Loss')\n","plt.plot(val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hKOwfY9olYJG","executionInfo":{"status":"aborted","timestamp":1607459205068,"user_tz":-120,"elapsed":2062,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# !pip install tensorflow.js"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5PeP4cXzZJzd","executionInfo":{"status":"aborted","timestamp":1607459205069,"user_tz":-120,"elapsed":2035,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":[""],"execution_count":null,"outputs":[]}]}