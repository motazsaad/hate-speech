{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"text_classification_Keras_CNN_HS_offiensive2020.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1KLqCDh2qbdkCUoTM9x0RmaCNGjAb1XpS","authorship_tag":"ABX9TyMfdoVBMcl9fEG53rEN3FTG"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"mYJ3KGNAa0Ix","executionInfo":{"status":"ok","timestamp":1622878750572,"user_tz":-180,"elapsed":1625,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["import tensorflow as tf\n","import numpy as np"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0fdOKnwDrabZ","executionInfo":{"status":"ok","timestamp":1622878807555,"user_tz":-180,"elapsed":46494,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"403476c6-3d0e-44fa-c33f-c8bac376f044"},"source":["!cat '/content/drive/My Drive/MasterThesis/Datasets/Offensive2020/trainDev/NOT_OFF/1000.txt'"],"execution_count":2,"outputs":[{"output_type":"stream","text":["@USER @USER Ø§Ù† Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡ ÙŠØ§ ØºØ§Ù„ÙŠ Ø­Ø¨ÙŠØ¨ÙŠ ÙŠØ§ Ù…Ø­Ù…Ø¯<LF>ÙˆØ¯Ø§ÙŠÙ…Ø§ Ù…ØªØ¬Ù…Ø¹ÙŠÙ† Ø¹Ù„ÙŠ Ø¹Ø´Ù‚ Ø§Ù„ÙƒÙŠØ§Ù†\tNOT_OFF\tNOT_HS\r\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gfRAxzRxLxcC","executionInfo":{"status":"ok","timestamp":1622879332673,"user_tz":-180,"elapsed":16490,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"360111eb-e4b5-40ad-dba0-7fad353ca96d"},"source":["batch_size = 32\n","raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n","    \"/content/drive/My Drive/MasterThesis/Datasets/Offensive2020/trainDev\",\n","    batch_size=batch_size,\n","    validation_split=0.2,\n","    subset=\"training\",\n","    seed=1337\n","   \n",")\n","raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n","    \"/content/drive/My Drive/MasterThesis/Datasets/Offensive2020/trainDev\",\n","    batch_size=batch_size,\n","    validation_split=0.2,\n","    subset=\"validation\",\n","    seed=1337,\n","    \n",")\n","raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n","    \"/content/drive/My Drive/MasterThesis/Datasets/Offensive2020/test\", batch_size=batch_size\n",")\n","\n","print(\n","    \"Number of batches in raw_train_ds: %d\"\n","    % tf.data.experimental.cardinality(raw_train_ds)\n",")\n","print(\n","    \"Number of batches in raw_val_ds: %d\" % tf.data.experimental.cardinality(raw_val_ds)\n",")\n","print(\n","    \"Number of batches in raw_test_ds: %d\"\n","    % tf.data.experimental.cardinality(raw_test_ds)\n",")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Found 8000 files belonging to 2 classes.\n","Using 6400 files for training.\n","Found 8000 files belonging to 2 classes.\n","Using 1600 files for validation.\n","Found 2000 files belonging to 2 classes.\n","Number of batches in raw_train_ds: 200\n","Number of batches in raw_val_ds: 50\n","Number of batches in raw_test_ds: 63\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ydTH5bCXK_kS","executionInfo":{"status":"ok","timestamp":1609738288214,"user_tz":-120,"elapsed":274489,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"32d50d88-b2e4-4a2e-9a45-1f55e904fc98"},"source":["# It's important to take a look at your raw data to ensure your normalization\n","# and tokenization will work as expected. We can do that by taking a few\n","# examples from the training set and looking at them.\n","# This is one of the places where eager execution shines:\n","# we can just evaluate these tensors using .numpy()\n","# instead of needing to evaluate them in a Session/Graph context.\n","for text_batch, label_batch in raw_train_ds.take(1):\n","    for i in range(10):\n","        print(text_batch.numpy()[i].decode('utf-8').strip())\n","        print(label_batch.numpy()[i])\n","        print('--------------------------------')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["RT @USER: ÙŠØ§ Ø±Ø¨ ÙŠØ§ Ø¹Ø²ÙŠØ² ÙŠØ§ Ø¬Ø¨Ø§Ø± .. Ø§Ù†Ùƒ Ø§Ù„Ù‚Ø§Ø¯Ø± Ø¹Ù„Ù‰ ÙƒÙ„ Ø´ÙŠØ¡ .. ÙŠØ§ Ø±Ø¨ ÙØ±Ø­Ù‡ Ø§ØªØ­Ø§Ø¯ÙŠÙ‡ ØªÙÙ†Ø³ÙŠÙ†Ø§ ÙƒÙ„ Ø§Ù„Ù‡Ù…ÙˆÙ… ÙˆØ§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„ÙŠ ØµØ§Ø±Øª Ù‡Ø§Ù„Ù…ÙˆØ³Ù… ÙŠØ§ Ø±Ø¨ Ø§Ù„Ø¹Ø¨Ø§Ø¯â€¦\tNOT_OFF\tNOT_HS\n","0\n","--------------------------------\n","@USER @USER ÙŠØ§ Ø¬Ø§Ù…Ø¹ ÙŠØ§ Ø±Ù‚ÙŠØ¨ ÙŠØ§ Ø±Ø¨ ØªÙ„Ù‚Ø§Ù‡Ø§\tNOT_OFF\tNOT_HS\n","0\n","--------------------------------\n","Ø±Ø§Ù‡Ù†Øª Ø¹Ù„ÙŠÙƒ ÙˆÙ„Ù… Ø§Ø®Ø³Ø± â¤ï¸â¤ï¸<LF>ÙŠØ§ ÙˆØ­Ø´ ÙŠØ§ Ø¬Ù„Ø§Ø¯ ÙŠØ§ ÙƒØ¨ÙŠØ±<LF>ÙŠØ§ Ù…Ø±Ø¹Ø¨ ÙŠØ§ Ù‚Ù†Ø§Øµ ÙŠØ§ ÙŠØµÙŠØ§Ø¯<LF>ğŸ–¤ğŸ’›ğŸ–¤ğŸ’›ğŸ–¤ğŸ’›ğŸ–¤ğŸ’›<LF>#Ø§Ù„Ø§ØªØ­Ø§Ø¯_Ø§Ù„Ù†ØµØ± URL\tNOT_OFF\tNOT_HS\n","0\n","--------------------------------\n","RT @USER: ÙƒØ§Ù†Øª Ø£ÙŠØ§Ù… ÙŠØ§ ÙˆØ·Ù†ÙŠ<LF>Ø²ÙŠ Ø§Ù„Ø£Ø­Ù„Ø§Ù… ÙŠØ§ ÙˆØ·Ù†ÙŠ ğŸ¶\tNOT_OFF\tNOT_HS\n","0\n","--------------------------------\n","ØªÙ…Ø«ÙŠÙ„ ÙŠØ§ Ø±Ø²Ø§Ù† ØªÙ…Ø«ÙŠÙ„ ÙŠØ§ Ø±Ø²Ø§Ù† ØªÙ…Ø«ÙŠÙ„ ÙŠØ§ Ø±Ø²Ø§Ù† ØªÙ…Ø«ÙŠÙ„ ÙŠØ§ Ø±Ø²Ø§Ù† ØªÙ…Ø«ÙŠÙ„ ÙŠØ§ Ø±Ø²Ø§Ù† ØªÙ…Ø«ÙŠÙ„ ÙŠØ§ Ø±Ø²Ø§Ù†\tNOT_OFF\tNOT_HS\n","0\n","--------------------------------\n","ÙŠØ§ HBO ÙŠØ§ Ø´Ø±Ù…ÙˆØ·Ø© ØªÙ†Ø²Ù„ÙŠ Ø§Ù„Ø­Ù„Ù‚Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ù…Ù† GOT ÙˆØ§Ù†Ø§ Ù…Ø¹Ø±ÙØ´ ÙŠØ§ Ù„Ø¨ÙˆØ© .. Ø£Ø®Øµ Ø¹Ù„ÙŠÙƒÙŠ Ø´Ø±ÙƒØ© Ø¥Ù†ØªØ§Ø¬ ÙˆØ«Ø®Ø© ğŸ˜ğŸ˜‚\tOFF\tNOT_HS\n","1\n","--------------------------------\n","@USER ÙŠØ§ Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒ ÙŠØ§ Ø¹Ù…ÙŠØ¯ ğŸ’™ğŸ’› Ø³Ù„Ø·Ø§Ù† Ø¨Ø·Ù„ ÙˆØ±Ø§Ø­ ÙŠØ¨Ù‚Ù‰ Ø¨Ø·Ù„ Ù…Ù‡Ù…Ø§ Ø­ØµÙ„ Ø­Ù†Ø§ Ø¹ÙŠØ§Ù„ Ø§Ù„Ù†ØµØ± Ø¨ÙƒÙ„ Ø§Ù„Ø§Ø­ÙˆØ§Ù„\tNOT_OFF\tNOT_HS\n","0\n","--------------------------------\n","@USER @USER ÙŠØ§ Ø¯Ø­Ø§Ø¨Ø´Ù‡ ÙŠØ§ ÙƒØ±Ø§Ù… ...<LF>Ø§Ù„Ø¬Ù†ÙˆØ¨ Ø§Ù†Ø³ÙˆÙ‡ ,<LF>Ø§Ù†ØªØ¨Ù‡ÙˆØ§ Ø¹Ù„Ù‰ Ø¨Ù„Ø§Ø¯ÙƒÙ… Ù„Ø§ Ø§Ø­Ø¯ ÙÙ‰ Ø§Ù„Ø¬Ù†ÙˆØ¨ Ù…Ù‡ØªÙ… Ø¨Ø§Ù„ÙŠÙ…Ù† <LF>Ù‡Ù‡Ù‡Ù‡Ù‡<LF>Ø§Ù†Ø¸Ø±ÙˆØ§ Ù…Ø§Ø°Ø§ ÙƒØ§Ù† Ù„Ø¯ÙŠÙƒÙ… Ù‚Ø¨Ù„ 90 ÙˆÙ‚Ø§Ø±Ù†ÙˆÙ‡ Ø¨Ù…Ø§ Ø§Ø°Ø§ Ù„Ø¯ÙŠÙƒÙ… Ø´Ø¦ Ø§ØµÙ„Ø§ Ø§Ù„Ø§Ù† ØŸ\tNOT_OFF\tNOT_HS\n","0\n","--------------------------------\n","@USER ØªØ®Ø³Ø§ Ø§Ù†Øª ÙˆØ§Ø´Ø¨Ø§Ù‡Ùƒ ÙŠØ§ Ø±Ø®Ù…Ù‡ ÙŠØ§ Ø¹Ø§Ù…Ù‡ Ø§Ù„Ø¹Ù† Ø§Ù„Ù„Ù‡ Ø§Ø¨Ùˆ Ø´Ø§Ø±Ø¨Ùƒ ÙŠÙ‚Ø±Ø¯ ÙŠØ§Ù‚Ø°Ø± Ø§Ø¹Ø·ÙŠÙƒ Ø­Ø¸Ø± Ø¹Ø´Ø§Ù† Ù…Ø§ Ø§Ø´ÙˆÙ Ø­Ø³Ø§Ø¨Ùƒ Ø§Ù„Ø®Ø§ÙŠØ³ Ø§Ù„ÙŠ Ù…Ø«Ù„Ùƒ Ø§Ù„Ø¹Ù† Ø§Ù„Ù„Ù‡ Ø§Ø¨Ùˆ Ø´Ø§Ø±Ø¨Ùƒ ÙŠØ§ Ø­ÙŠÙˆØ§Ù†\tOFF\tNOT_HS\n","1\n","--------------------------------\n","ÙŠØ§ Ø­Ù„Ø§ØªÙ‡ ÙŠØ§ Ø­Ù„Ø§ØªÙ‡ ÙŠØ§ Ø­Ù„Ø§ØªÙ‡\tNOT_OFF\tNOT_HS\n","0\n","--------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q9txzbz_V_Mq","executionInfo":{"status":"ok","timestamp":1622879342533,"user_tz":-180,"elapsed":404,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# xx = re.sub(r\"(.)\\1+\", r\"\\1\", \"Ø³Ù„Ø§Ø§Ø§Ø§Ø§Ø§Ù…\")\n","xx=tf.strings.regex_replace(\"Ø³Ù„Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ø§Ù…\", \"r'(.)\\1+'\", \"r'\\1\\1'\")\n","for i in xx.numpy():\n","    tf.compat.as_str_any(i)\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"VswmdllsTM3e","executionInfo":{"status":"ok","timestamp":1622879511086,"user_tz":-180,"elapsed":401,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n","import string\n","import re\n","text_cleaning_re = \"[a-zA-Z]|\\d+|[Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©]|[.#ØŒ<>:@,\\\\-_â€â€œÙªÙÙ‹]\"\n","\n","def custom_standardization(text):\n","    p_tashkeel = re.compile(r'[\\u0617-\\u061A\\u064B-\\u0652]')\n","    text = re.sub(p_tashkeel,\"\", str(text))\n","    # text = text.replace('ÙˆÙˆ', 'Ùˆ')\n","    # text = text.replace('ÙŠÙŠ', 'ÙŠ')\n","    # text = text.replace('Ø§Ø§', 'Ø§')\n","    text = re.sub(text_cleaning_re, ' ', str(text).lower()).strip()\n","    #remove longation\n","    text = re.sub(r'(.)\\1+', r'\\1\\1', str(text)) \n","    text = re.sub(\"[Ø¥Ø£Ø¢Ø§]\", \"Ø§\", str(text))\n","    text = re.sub(r\"([?!Â¿])\", r\" \\1 \", str(text))\n","    text = re.sub(\"Ù‰\", \"ÙŠ\", str(text))\n","    # text = re.sub(\"Ø¤\", \"Ø¡\", text)\n","    # text = re.sub(\"Ø¦\", \"Ø¡\", text)\n","    text = re.sub(\"Ø©\", \"Ù‡\", str(text))\n","\n","\n","    # x = tf.strings.regex_replace(input_data,\"r'(.)\\1+'\", \"r'\\1'\")\n","    # stripped_html = re.sub(r'(.)\\1+', r'\\1',str(input_data, 'utf-8'))\n","    # stripped_html = tf.strings.regex_replace(stripped_html, \"<LF>\", \" \")\n","    # stripped_html = tf.strings.regex_replace(stripped_html, \"[a-zA-Z]|\\d+|[Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©]\", \" \")\n","    # stripped_html = tf.strings.regex_replace(stripped_html, \"[.ØŒ,\\\\-_â€â€œÙªÙÙ‹]\", \" \")\n","    \n","    # stripped_html = tf.strings.regex_replace(stripped_html, \"[Ø¥Ø£Ø¢Ø§]\", \"Ø§\")\n","    # stripped_html = tf.strings.regex_replace(stripped_html, \"Ø©\", \"Ù‡\")\n","  \n","    return tf.strings.regex_replace(\n","       text, \"[%s]\" % re.escape(string.punctuation), \"\"\n","    )"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ae4qks6aS34D","executionInfo":{"status":"ok","timestamp":1622879512551,"user_tz":-180,"elapsed":306,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"951a1b06-6b23-4674-9d43-6542a72b38c4"},"source":["custom_standardization('Ù…Ø´ÙƒÙˆÙˆÙˆÙˆÙˆÙˆØ±')"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=string, numpy=b'\\xd9\\x85\\xd8\\xb4\\xd9\\x83\\xd9\\x88\\xd9\\x88\\xd8\\xb1'>"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"QxrhvJ1MBjhm","colab":{"base_uri":"https://localhost:8080/","height":340},"executionInfo":{"status":"error","timestamp":1622879708598,"user_tz":-180,"elapsed":363,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"24b22767-9c8c-4c0b-81a1-f285a5265ec7"},"source":["from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n","import string\n","import re\n","# @tf.function()\n","def custom_standardization(input_data):\n","    # lowercase = tf.strings.lower(input_data)\n","    # input_data = tf.ragged.strings.bytes_split(input_data)\n","    \n","    # input_data = tf.constant(input_data)\n","    # text_chars = tf.constant([ord(char) for char in input_data])\n","\n","    # stripped_html = re.sub(r'(.)\\1+', r'\\1',input_data.numpy() )\n","\n","\n","    # stripped_html = re.sub(r'(.)\\1+', r'\\1',str(input_data.eval())) \n","    # stripped_html = re.sub(r'(.)\\1+', r'\\1', str(lowercase))\n","    # z=tf.strings.regex_replace(lowercase,  \"(.)\\1+\", \"\\1\")\n","\n","\n","    # x= tf.compat.as_str_any(input_data)\n","    stripped_html = re.sub(r'(.)\\1+', r'\\1',input_data)\n","    stripped_html = tf.strings.regex_replace(stripped_html, \"<LF>\", \" \")\n","    stripped_html = tf.strings.regex_replace(stripped_html, \"[a-zA-Z]|\\d+|[Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©]\", \" \")\n","    stripped_html = tf.strings.regex_replace(stripped_html, \"[.ØŒ,\\\\-_â€â€œÙªÙÙ‹]\", \" \")\n","    \n","    stripped_html = tf.strings.regex_replace(stripped_html, \"[Ø¥Ø£Ø¢Ø§]\", \"Ø§\")\n","    stripped_html = tf.strings.regex_replace(stripped_html, \"Ø©\", \"Ù‡\")\n","    # stripped_html = re.sub(r'(.)\\1+', r'\\1', tf.compat.as_str(stripped_html,encoding='utf-8'))\n","\n","    # corpus =[]\n","    # for i in range(len(input_data)):\n","    # lowercase = re.sub(r\"(.)\\1+\", r\"\\1\", str(input_data))\n","    # lowercase=tf.strings.unicode_decode(lowercase,input_encoding='UTF-8')\n","        # tweet = re.sub(r\"\\s+https://t.co/[a-zA-Z0-9]*\\s\",\" \", tweet)\n","        # tweet = re.sub(r\"\\s+https://t.co/[a-zA-Z0-9]*$\",\" \", tweet)\n","        # tweet = tweet.lower()\n","        # corpus.append(tweet)\n","    # lowercase = tf.strings.lower(input_data)\n","    # # lowercase=lowercase.decode('utf-8')\n","    # # stripped_html = re.sub(r'(.)\\1+', 'r'\\1', str(lowercase))\n","    # stripped_html = tf.strings.regex_replace(lowercase, \"<LF>\", \" \")\n","    # stripped_html = tf.strings.regex_replace(stripped_html, \"[a-zA-Z]|\\d+|[Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©]\", \" \")\n","    # stripped_html = tf.strings.regex_replace(stripped_html, \"[.ØŒ,\\\\_-â€â€œÙªÙÙ‹]\", \" \")\n","    \n","    # stripped_html = tf.strings.regex_replace(stripped_html, \"[Ø¥Ø£Ø¢Ø§]\", \"Ø§\")\n","    # stripped_html = tf.strings.regex_replace(stripped_html, \"Ø©\", \"Ù‡\")\n","    # stripped_html=tf.strings.regex_replace(stripped_html, \"[(\\U0001F600-\\U0001F92F|\\U0001F300-\\U0001F5FF|\\U0001F680-\\U0001F6FF|\\U0001F190-\\U0001F1FF|\\U00002702-\\U000027B0|\\U0001F926-\\U0001FA9F|\\u200d|\\u2640-\\u2642|\\u2600-\\u2B55|\\u23cf|\\u23e9|\\u231a|\\ufe0f)|\\u2069|\\u2066]+\", \" \")\n","    # stripped_html = tf.strings.regex_replace(stripped_html, \"r'(.)\\1+'\", \"r'\\1\\1'\")\n","\n","    return tf.strings.regex_replace(\n","       stripped_html, \"[%s]\" % re.escape(string.punctuation), \"\"\n","    )\n","   \n","#max_features = 20000 #13% \n","max_features = 50000 #13% \n","embedding_dim = 128\n","sequence_length = 500\n","\n","vectorize_layer = TextVectorization(\n","    standardize=custom_standardization,\n","    max_tokens=max_features,\n","    output_mode=\"int\",\n","    output_sequence_length=sequence_length,\n",")\n","\n","text_ds = raw_train_ds.map(lambda x, y: x)\n","# text_ds\n","vectorize_layer.adapt(text_ds)\n"],"execution_count":13,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-8a6038fd24bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mtext_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_train_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m# text_ds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0mvectorize_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/preprocessing/text_vectorization.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data, reset_state)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_legacy_output_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m       \u001b[0mpreprocessed_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m       raise ValueError(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1923\u001b[0m         warnings.warn(\"The `deterministic` argument has no effect unless the \"\n\u001b[1;32m   1924\u001b[0m                       \"`num_parallel_calls` argument is specified.\")\n\u001b[0;32m-> 1925\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1926\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m       return ParallelMapDataset(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4485\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4486\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4487\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   4488\u001b[0m     variant_tensor = gen_dataset_ops.map_dataset(\n\u001b[1;32m   4489\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3710\u001b[0m     \u001b[0mresource_tracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResourceTracker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3711\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3712\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3713\u001b[0m       \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3714\u001b[0m       \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3133\u001b[0m     \"\"\"\n\u001b[1;32m   3134\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 3135\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   3136\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3137\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3098\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3099\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3100\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3101\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3102\u001b[0m       captured = object_identity.ObjectIdentitySet(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3289\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3685\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3686\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3687\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3688\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3689\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3615\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3616\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3617\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3618\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3619\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/preprocessing/text_vectorization.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    513\u001b[0m                                         \"\")\n\u001b[1;32m    514\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m       raise ValueError((\"%s is not a supported standardization. \"\n","\u001b[0;32m<ipython-input-13-8a6038fd24bb>\u001b[0m in \u001b[0;36mcustom_standardization\u001b[0;34m(input_data)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# x= tf.compat.as_str_any(input_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mstripped_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'(.)\\1+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr'\\1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mstripped_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregex_replace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstripped_html\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"<LF>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mstripped_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregex_replace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstripped_html\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"[a-zA-Z]|\\d+|[Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"]}]},{"cell_type":"code","metadata":{"id":"VwhbmPnsi4S-"},"source":["def vectorize_text(text, label):\n","    text = tf.expand_dims(text, -1)\n","    return vectorize_layer(text), label\n","\n","\n","# Vectorize the data.\n","train_ds = raw_train_ds.map(vectorize_text)\n","val_ds = raw_val_ds.map(vectorize_text)\n","test_ds = raw_test_ds.map(vectorize_text)\n","\n","# Do async prefetching / buffering of the data for best performance on GPU.\n","train_ds = train_ds.cache().prefetch(buffer_size=10)\n","val_ds = val_ds.cache().prefetch(buffer_size=10)\n","test_ds = test_ds.cache().prefetch(buffer_size=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y0f9DNMrXQ5o"},"source":["vocab = np.array(vectorize_layer.get_vocabulary())\n","vocab[:1000]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mFmq_L7hXUWm"},"source":["vectorize_layer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Brh_6hl-XNrJ"},"source":["encoded_example = vectorize_layer(text_batch)[:100].numpy()\n","encoded_example"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l-oM174FXM0H"},"source":["for n in range(5):\n","  print(\"Original: \", text_batch[n].numpy().decode('utf-8').strip())\n","  print(\"Round-trip: \", \" \".join(vocab[encoded_example[n]]))\n","  print()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xv-M7bb6khq1"},"source":["## Build a model "]},{"cell_type":"code","metadata":{"id":"WCohoIbMhVj9"},"source":["from tensorflow.keras import layers\n","\n","# A integer input for vocab indices.\n","inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n","\n","# Next, we add a layer to map those vocab indices into a space of dimensionalityl\n","# 'embedding_dim'.\n","x = layers.Embedding(max_features, embedding_dim)(inputs)\n","x = layers.Dropout(0.5)(x)\n","\n","# Conv1D + global max pooling\n","x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n","# x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n","# x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n","x = layers.GlobalMaxPooling1D()(x)\n","\n","##################### salam here Add Bi lstm layer #########################\n","\n","# We add a vanilla hidden layer:\n","x = layers.Dense(128, activation=\"relu\")(x)\n","x = layers.Dropout(0.5)(x)\n","\n","# We project onto a single unit output layer, and squash it with a sigmoid:\n","predictions = layers.Dense(1, activation=\"sigmoid\", name=\"predictions\")(x)\n","\n","model = tf.keras.Model(inputs, predictions)\n","\n","# Compile the model with binary crossentropy loss and an adam optimizer.\n","model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yUxWhjJRkvX2"},"source":["## Train the model"]},{"cell_type":"code","metadata":{"id":"6f40euEzkly4"},"source":["from keras.callbacks import EarlyStopping\n","epochs = 30\n","\n","# Fit the model using the train and test datasets.\n","history = model.fit(train_ds, validation_data=val_ds, epochs=epochs,\n","                    callbacks=[EarlyStopping(monitor='val_loss',patience=5)])\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"edg-1dgVk31a"},"source":["## Evaluate the model on the test set\n"]},{"cell_type":"code","metadata":{"id":"LpyFcJNDlTa_"},"source":["test_loss, test_acc = model.evaluate(test_ds)\n","\n","print('Test Loss: {}'.format(test_loss))\n","print('Test Accuracy: {}'.format(test_acc))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B83gmSdHlAAJ"},"source":["## plotlib"]},{"cell_type":"code","metadata":{"id":"HKvke9H8k-DJ"},"source":["import matplotlib.pyplot as plt\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","\n","#epochs_range = range(22)\n","\n","plt.figure(figsize=(15, 15))\n","plt.subplot(1, 2, 1)\n","plt.plot(acc, label='Training Accuracy')\n","plt.plot(val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(loss, label='Training Loss')\n","plt.plot(val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hKOwfY9olYJG"},"source":["# !pip install tensorflow.js"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5PeP4cXzZJzd"},"source":[""],"execution_count":null,"outputs":[]}]}