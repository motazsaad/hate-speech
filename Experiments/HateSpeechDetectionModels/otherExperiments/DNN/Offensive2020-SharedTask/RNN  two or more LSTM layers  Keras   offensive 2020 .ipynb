{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":" RNN |two or more LSTM layers| Keras | offensive 2020 .ipynb","provenance":[{"file_id":"1ja8KruY-9DfTF1rn39m247fDgpa14q3m","timestamp":1608410488458},{"file_id":"1QkkGQfDCiFKqPTvfmxnNeL-MIiRfaJph","timestamp":1607460955296}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"x3iHYaNQGasL"},"source":["import tensorflow as tf\r\n","import numpy as np\r\n","from tensorflow import keras\r\n","from tensorflow.keras import layers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a_WYr2FiGbQ-","executionInfo":{"status":"ok","timestamp":1610475792172,"user_tz":-120,"elapsed":819,"user":{"displayName":"Israa alnabrisi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMbKQdFLs5-5nAccIyILdm6V2xUv8E9yNnIdQS=s64","userId":"12128949182236523165"}},"outputId":"7614adc6-c999-42e1-c7a0-82f4de6c3556"},"source":["!cat '/content/drive/MyDrive/fortest/train/HS/13.txt'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["@USER @USER @USER يا لطيف.. يا ساتر ..أحمدوا ربكم إنها مستقعدة🌚كيف لو إنها واقفه👌\tOFF\tNOT_HS\r\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eBNAX1DHGeph","executionInfo":{"status":"ok","timestamp":1610475795615,"user_tz":-120,"elapsed":1151,"user":{"displayName":"Israa alnabrisi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMbKQdFLs5-5nAccIyILdm6V2xUv8E9yNnIdQS=s64","userId":"12128949182236523165"}},"outputId":"4c4f684d-50bd-465b-f7c8-b07a8074f91b"},"source":["batch_size = 32\r\n","raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\r\n","    \"/content/drive/MyDrive/fortest/train\",\r\n","    batch_size=batch_size,\r\n","    validation_split=0.2,\r\n","    subset=\"training\",\r\n","    seed=1337,\r\n","   \r\n",")\r\n","raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\r\n","    \"/content/drive/MyDrive/fortest/dev\",\r\n","    batch_size=batch_size,\r\n","    validation_split=0.2,\r\n","    subset=\"validation\",\r\n","    seed=1337,\r\n","    \r\n",")\r\n","raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\r\n","    \"/content/drive/MyDrive/fortest/test\", batch_size=batch_size\r\n",")\r\n","\r\n","print(\r\n","    \"Number of batches in raw_train_ds: %d\"\r\n","    % tf.data.experimental.cardinality(raw_train_ds)\r\n",")\r\n","print(\r\n","    \"Number of batches in raw_val_ds: %d\" % tf.data.experimental.cardinality(raw_val_ds)\r\n",")\r\n","print(\r\n","    \"Number of batches in raw_test_ds: %d\"\r\n","    % tf.data.experimental.cardinality(raw_test_ds)\r\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 26 files belonging to 2 classes.\n","Using 21 files for training.\n","Found 25 files belonging to 2 classes.\n","Using 5 files for validation.\n","Found 24 files belonging to 2 classes.\n","Number of batches in raw_train_ds: 1\n","Number of batches in raw_val_ds: 1\n","Number of batches in raw_test_ds: 1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CcD9iYX0Gx0D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610475799810,"user_tz":-120,"elapsed":799,"user":{"displayName":"Israa alnabrisi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMbKQdFLs5-5nAccIyILdm6V2xUv8E9yNnIdQS=s64","userId":"12128949182236523165"}},"outputId":"03025ae0-5c0f-4fa9-b242-93b1d3ad082b"},"source":["# It's important to take a look at your raw data to ensure your normalization\r\n","# and tokenization will work as expected. We can do that by taking a few\r\n","# examples from the training set and looking at them.\r\n","# This is one of the places where eager execution shines:\r\n","# we can just evaluate these tensors using .numpy()\r\n","# instead of needing to evaluate them in a Session/Graph context.\r\n","for text_batch, label_batch in raw_train_ds.take(1):\r\n","    for i in range(5):\r\n","        print(text_batch.numpy()[i].decode('utf-8').strip())\r\n","        print(label_batch.numpy()[i])\r\n","        print('--------------------------------')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["@USER اعلامي هلالي وش ترجي منه اي والله الى قال محمد العويس حراق🔥🔥🔥حارق قلبك يا زقان يا المطيًويع من حرق عساه للحرق يا رب جعلني اشوف فيك يوم اسود انت وعائلتك يا ابن الكلب\tOFF\tNOT_HS\n","0\n","--------------------------------\n","يا التاج ع الراس يا السادة<LF>يا مالك الروح وراعيها❤️\tNOT_OFF\tNOT_HS\n","1\n","--------------------------------\n","فدوه يا بخت فدوه يا زمن واحد منكم يجيبه\tNOT_OFF\tNOT_HS\n","1\n","--------------------------------\n","@USER يا بجم يا عجم يا نجم كلنا فالهوا سوا\tOFF\tNOT_HS\n","0\n","--------------------------------\n","@USER @USER @USER يا لطيف.. يا ساتر ..أحمدوا ربكم إنها مستقعدة🌚كيف لو إنها واقفه👌\tOFF\tNOT_HS\n","0\n","--------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"id":"7oSIQ1Gxj9ks","executionInfo":{"status":"error","timestamp":1610475803338,"user_tz":-120,"elapsed":937,"user":{"displayName":"Israa alnabrisi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMbKQdFLs5-5nAccIyILdm6V2xUv8E9yNnIdQS=s64","userId":"12128949182236523165"}},"outputId":"2ed4fb05-37d5-4f45-cb5d-368859d86258"},"source":["import re\r\n","import string\r\n","import sys\r\n","import argparse\r\n","\r\n","arabic_punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ'''\r\n","english_punctuations = string.punctuation\r\n","punctuations_list = arabic_punctuations + english_punctuations\r\n","\r\n","\r\n","arabic_diacritics = re.compile(\"\"\"\r\n","                             ّ    | # Tashdid\r\n","                             َ    | # Fatha\r\n","                             ً    | # Tanwin Fath\r\n","                             ُ    | # Damma\r\n","                             ٌ    | # Tanwin Damm\r\n","                             ِ    | # Kasra\r\n","                             ٍ    | # Tanwin Kasr\r\n","                             ْ    | # Sukun\r\n","                             ـ     # Tatwil/Kashida\r\n","                         \"\"\", re.VERBOSE)\r\n","\r\n","\r\n","\r\n","\r\n","\r\n","def remove_diacritics(text):\r\n","    text = re.sub(arabic_diacritics, '', text)\r\n","    return text\r\n","\r\n","\r\n","def remove_punctuations(text):\r\n","    translator = str.maketrans('', '', punctuations_list)\r\n","    return text.translate(translator)\r\n","\r\n","\r\n","def remove_repeating_char(text):\r\n","    return re.sub(r'(.)\\1+', r'\\1', text)\r\n","\r\n","\r\n","def custom_standardization(input_data):\r\n","    #text = normalize_arabic(input_data)\r\n","    text = remove_punctuations(input_data)\r\n","    text = remove_diacritics(text)\r\n","    text = remove_repeating_char(text)\r\n","    return text.decode('utf-8')\r\n","\r\n","\r\n","\r\n","\r\n","# Model constants.\r\n","max_features = 20000\r\n","embedding_dim = 128\r\n","sequence_length = 500\r\n","\r\n","vectorize_layer = TextVectorization(\r\n","    standardize=custom_standardization,\r\n","    max_tokens=max_features,\r\n","    output_mode=\"int\",\r\n","    output_sequence_length=sequence_length,\r\n",")\r\n","\r\n","\r\n","text_ds = raw_train_ds.map(lambda x, y: x)\r\n","vectorize_layer.adapt(text_ds)\r\n"],"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-58-69f811783bcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mtext_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_train_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mvectorize_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/preprocessing/text_vectorization.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data, reset_state)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_legacy_output_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m       \u001b[0mpreprocessed_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m       raise ValueError(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1803\u001b[0m     \"\"\"\n\u001b[1;32m   1804\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1805\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1806\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1807\u001b[0m       return ParallelMapDataset(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4206\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4207\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   4208\u001b[0m     variant_tensor = gen_dataset_ops.map_dataset(\n\u001b[1;32m   4209\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3523\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3524\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3525\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3527\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3050\u001b[0m     \"\"\"\n\u001b[1;32m   3051\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 3052\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   3053\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3054\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3017\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3018\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3019\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3020\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m       captured = object_identity.ObjectIdentitySet(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3516\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3517\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3518\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3519\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3520\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3451\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3453\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3454\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3455\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    348\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/preprocessing/text_vectorization.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    575\u001b[0m                                         \"\")\n\u001b[1;32m    576\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m       raise ValueError((\"%s is not a supported standardization. \"\n","\u001b[0;32m<ipython-input-58-69f811783bcf>\u001b[0m in \u001b[0;36mcustom_standardization\u001b[0;34m(input_data)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcustom_standardization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m#text = normalize_arabic(input_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_punctuations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_diacritics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_repeating_char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-58-69f811783bcf>\u001b[0m in \u001b[0;36mremove_punctuations\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mremove_punctuations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mtranslator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaketrans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpunctuations_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'translate'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"FKokewub8uK7","executionInfo":{"status":"ok","timestamp":1610477670256,"user_tz":-120,"elapsed":1382,"user":{"displayName":"Israa alnabrisi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMbKQdFLs5-5nAccIyILdm6V2xUv8E9yNnIdQS=s64","userId":"12128949182236523165"}},"outputId":"132aa851-4597-4a2b-ca20-bf9ba31a4150"},"source":["re.sub(r'(.)\\1+', r'\\1', \"haaaaapppppyyy\")  "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'hapy'"]},"metadata":{"tags":[]},"execution_count":74}]},{"cell_type":"code","metadata":{"id":"0aTNbzaCGyI4","colab":{"base_uri":"https://localhost:8080/","height":270},"executionInfo":{"status":"error","timestamp":1610478010590,"user_tz":-120,"elapsed":808,"user":{"displayName":"Israa alnabrisi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMbKQdFLs5-5nAccIyILdm6V2xUv8E9yNnIdQS=s64","userId":"12128949182236523165"}},"outputId":"1d13d295-c4fb-4dc7-b338-3c7800f99c27"},"source":["import string\r\n","import re\r\n","from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\r\n","# Having looked at our data above, we see that the raw text contains HTML break\r\n","# tags of the form '<br />'. These tags will not be removed by the default\r\n","# standardizer (which doesn't strip HTML). Because of this, we will need to\r\n","# create a custom standardization function.\r\n","def custom_standardization(input_data):\r\n","    # lowercase = tf.strings.lower(input_data)\r\n","    # stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\r\n","    stripped_html = tf.strings.regex_replace(input_data, \"[a-zA-Z]|\\d+|[٠١٢٣٤٥٦٧٨٩]\", \" \")\r\n","    stripped_html = tf.strings.regex_replace(stripped_html, \"[.،,!?؟\\\\-”“٪ًَ]\", \" \")\r\n","    \r\n","    stripped_html = tf.strings.regex_replace(stripped_html, \"[إأآا]\", \"ا\")\r\n","    stripped_html = tf.strings.regex_replace(stripped_html, \"ة\", \"ه\")\r\n","    # stripped_html=tf.strings.regex_replace(stripped_html, \"[(\\U0001F600-\\U0001F92F|\\U0001F300-\\U0001F5FF|\\U0001F680-\\U0001F6FF|\\U0001F190-\\U0001F1FF|\\U00002702-\\U000027B0|\\U0001F926-\\U0001FA9F|\\u200d|\\u2640-\\u2642|\\u2600-\\u2B55|\\u23cf|\\u23e9|\\u231a|\\ufe0f)|\\u2069|\\u2066]+\", \" \")\r\n","    #stripped_html = tf.strings.regex_replace(stripped_html, r'(.)\\1+', r'\\1')\r\n","    stripped_html = tf.strings.regex_replace(stripped_html, r'(.)\\1+', r'\\1')\r\n","\r\n","    #stripped_html = re.sub(r'(.)\\1+', r'\\1',str(stripped_html) )\r\n","    return tf.strings.regex_replace(stripped_html, \"[%s]\" % re.escape(string.punctuation), \"\" )\r\n","\r\n","\r\n","# Model constants.\r\n","max_features = 20000\r\n","embedding_dim = 128\r\n","sequence_length = 500\r\n","\r\n","# Now that we have our custom standardization, we can instantiate our text\r\n","# vectorization layer. We are using this layer to normalize, split, and map\r\n","# strings to integers, so we set our 'output_mode' to 'int'.\r\n","# Note that we're using the default split function,\r\n","# and the custom standardization defined above.\r\n","# We also set an explicit maximum sequence length, since the CNNs later in our\r\n","# model won't support ragged sequences.\r\n","vectorize_layer = TextVectorization(\r\n","    standardize=custom_standardization,\r\n","    max_tokens=max_features,\r\n","    output_mode=\"int\",\r\n","    output_sequence_length=sequence_length,\r\n",")\r\n","\r\n","# Now that the vocab layer has been created, call `adapt` on a text-only\r\n","# dataset to create the vocabulary. You don't have to batch, but for very large\r\n","# datasets this means you're not keeping spare copies of the dataset in memory.\r\n","\r\n","# Let's make a text-only dataset (no labels):\r\n","text_ds = raw_train_ds.map(lambda x, y: x)\r\n","# Let's call `adapt`:\r\n","vectorize_layer.adapt(text_ds)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-80-53dc7132262f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mtext_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_train_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# Let's call `adapt`:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mvectorize_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/preprocessing/text_vectorization.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data, reset_state)\u001b[0m\n\u001b[1;32m    435\u001b[0m               type(data)))\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_lookup_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessed_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vectorize_layer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/preprocessing/index_lookup.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data, reset_state)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreset_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"IndexLookup does not support streaming adapts.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndexLookup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_preprocessing_layer.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data, reset_state)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;34m'elements. Please use `dataset.take(...)` to make the number '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             'of elements finite.')\n\u001b[0;32m--> 171\u001b[0;31m       \u001b[0mnext_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_dataset_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m       \u001b[0;31m# TODO(fchollet): consider checking if the dataset is already batched\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m       \u001b[0;31m# and otherwise batching it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_preprocessing_layer.py\u001b[0m in \u001b[0;36m_get_dataset_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_dataset_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;34m\"\"\"Gets an iterator from a tf.data.Dataset.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_one_shot_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmake_one_shot_iterator\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m   2820\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_one_shot_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2821\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2822\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDatasetV1Adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_one_shot_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_make_one_shot_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m     \u001b[0m_ensure_same_dataset_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    680\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    703\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 705\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m       \u001b[0;31m# Delete the resource when this object is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   2973\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2974\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2975\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2976\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2977\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Invalid pattern: (.)\\1+, error: invalid escape sequence: \\1\n\t [[{{node StaticRegexReplace_4}}]] [Op:MakeIterator]"]}]},{"cell_type":"code","metadata":{"id":"BxJIanrPG2KK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610476702203,"user_tz":-120,"elapsed":772,"user":{"displayName":"Israa alnabrisi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMbKQdFLs5-5nAccIyILdm6V2xUv8E9yNnIdQS=s64","userId":"12128949182236523165"}},"outputId":"25cbe005-5ea0-4a04-8ee5-dbf31c5337b9"},"source":["vocab = np.array(vectorize_layer.get_vocabulary())\r\n","vocab[:30]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['', '[UNK]', 'يا', 'من', 'على', 'ابن', 'و', 'كل', 'فاشل', 'سلمان',\n","       'انت', 'والله', 'قلبي', 'قال', 'عاش', 'زمالك', 'يوم', 'واحد',\n","       'ممحون', 'مش', 'لو', 'لسه', 'كرتونه', 'قلبك', 'فين', 'فيك', 'فدوه',\n","       'رب', 'حيوان', 'حلو'], dtype='<U11')"]},"metadata":{"tags":[]},"execution_count":67}]},{"cell_type":"code","metadata":{"id":"-kNQmzlnaR7o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610476705862,"user_tz":-120,"elapsed":1061,"user":{"displayName":"Israa alnabrisi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMbKQdFLs5-5nAccIyILdm6V2xUv8E9yNnIdQS=s64","userId":"12128949182236523165"}},"outputId":"073dc01e-4bed-450e-bce1-0b77a40d8774"},"source":["encoded_example = vectorize_layer(text_batch)[:20].numpy()\r\n","encoded_example"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[267,  75,  63, ...,   0,   0,   0],\n","       [  2, 256, 148, ...,   0,   0,   0],\n","       [ 26,   2, 214, ...,   0,   0,   0],\n","       ...,\n","       [  2,  27,   2, ...,   0,   0,   0],\n","       [ 24,   2, 180, ...,   0,   0,   0],\n","       [208, 226,   2, ...,   0,   0,   0]])"]},"metadata":{"tags":[]},"execution_count":68}]},{"cell_type":"code","metadata":{"id":"SCMlCLF3ache","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610476708529,"user_tz":-120,"elapsed":937,"user":{"displayName":"Israa alnabrisi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMbKQdFLs5-5nAccIyILdm6V2xUv8E9yNnIdQS=s64","userId":"12128949182236523165"}},"outputId":"084f2510-ea64-4cbb-9fc8-abb15d3359f8"},"source":["for n in range(20):\r\n","  print(\"Original: \", text_batch[n].numpy().decode())\r\n","  print(\"Round-trip: \", \" \".join(vocab[encoded_example[n]]))\r\n","  print()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Original:  @USER اعلامي هلالي وش ترجي منه اي والله الى قال محمد العويس حراق🔥🔥🔥حارق قلبك يا زقان يا المطيًويع من حرق عساه للحرق يا رب جعلني اشوف فيك يوم اسود انت وعائلتك يا ابن الكلب\tOFF\tNOT_HS\r\n","\n","Round-trip:  اعلامي هلالي وش ترجي منه اي والله الى قال محمد العويس حراق🔥🔥🔥حارق قلبك يا زقان يا المطي ويع من حرق عساه للحرق يا رب جعلني اشوف فيك يوم اسود انت وعائلتك يا ابن الكلب                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n","\n","Original:  يا التاج ع الراس يا السادة<LF>يا مالك الروح وراعيها❤️\tNOT_OFF\tNOT_HS\r\n","\n","Round-trip:  يا التاج ع الراس يا الساده يا مالك الروح وراعيها❤️                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n","\n","Original:  فدوه يا بخت فدوه يا زمن واحد منكم يجيبه\tNOT_OFF\tNOT_HS\r\n","\n","Round-trip:  فدوه يا بخت فدوه يا زمن واحد منكم يجيبه                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n","\n","Original:  @USER يا بجم يا عجم يا نجم كلنا فالهوا سوا\tOFF\tNOT_HS\r\n","\n","Round-trip:  يا بجم يا عجم يا نجم كلنا فالهوا سوا                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n","\n","Original:  @USER @USER @USER يا لطيف.. يا ساتر ..أحمدوا ربكم إنها مستقعدة🌚كيف لو إنها واقفه👌\tOFF\tNOT_HS\r\n","\n","Round-trip:  يا لطيف يا ساتر احمدوا ربكم انها مستقعده🌚كيف لو انها واقفه👌                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n","\n","Original:  @USER يا جدعان العلق دا لسه بيقولي هذاكر الاسئلة كفاية ، و راح فتح تويتر .. يا فاشل .. يا فاشل يا فاشل يا فاشل 😂😂😂\tOFF\tNOT_HS\r\n","\n","Round-trip:  يا جدعان العلق دا لسه بيقولي هذاكر الاسئله كفايه و راح فتح تويتر يا فاشل يا فاشل يا فاشل يا فاشل 😂😂😂                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n","\n","Original:  @USER اخخ يا قلببي يا هالحلقه 😩😭♥️ متعه على بكاء على حماس كل المشاعر داخله ببعض\tNOT_OFF\tNOT_HS\r\n","\n","Round-trip:  اخخ يا قلببي يا هالحلقه 😩😭♥️ متعه على بكاء على حماس كل المشاعر داخله ببعض                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n","\n","Original:  RT @USER: جالس أسمع أحمد قاسم يغني: \"أحبك من كل قلبي يا بلادي يا يمن\". حتى أنا والله أحب اليمن من كل قلبي أحب بلادي من طرفها لطرفها \"ب…\tNOT_OFF\tNOT_HS\r\n","\n","Round-trip:  جالس اسمع احمد قاسم يغني احبك من كل قلبي يا بلادي يا يمن حتى انا والله احب اليمن من كل قلبي احب بلادي من طرفها لطرفها ب…                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n","\n","Original:  RT @USER: #هوا_الحرية يا وجع قلبي عليكي يا امي...<LF>الله لا يحرق قلبك ويكسر بخاطرك للمرة الف نقف إجلال لعظمة وقدرة لين قلب الأم ال…\tNOT_OFF\tNOT_HS\r\n","\n","Round-trip:  هواالحريه يا وجع قلبي عليكي يا امي الله لا يحرق قلبك ويكسر بخاطرك للمره الف نقف اجلال لعظمه وقدره لين قلب الام ال…                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n","\n","Original:  الحمدلله يارب فوز مهم يا زمالك.. كل الدعم ليكم يا رجالة ⚪🔴<LF>الدوري يا زمالك .. الدوري يا زمالك<LF>#صدارة_بس\tNOT_OFF\tNOT_HS\r\n","\n","Round-trip:  الحمدلله يارب فوز مهم يا زمالك كل الدعم ليكم يا رجاله ⚪🔴 الدوري يا زمالك الدوري يا زمالك صدارهبس                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n","\n","Original:  يا بكون بحياتك الأهم يا إما ما بدي أكون 🎼\tNOT_OFF\tNOT_HS\r\n","\n","Round-trip:  يا بكون بحياتك الاهم يا اما ما بدي اكون 🎼                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n","\n","Original:  حقيقي ✋️ <LF>حلو انك ميجيش فيك اجوان عشان متخسرش !ده بديهي يعني <LF>بس حرفياً الزمالك بيطلع دين امي قدام و مش حلو نفضل ماشين بمبدأ يا نكسب يا نتعادل المهم منخسرش ..\tOFF\tNOT_HS\r\n","\n","Round-trip:  حقيقي ✋️ حلو انك ميجيش فيك اجوان عشان متخسرش ده بديهي يعني بس حرفيا الزمالك بيطلع دين امي قدام و مش حلو نفضل ماشين بمبدا يا نكسب يا نتعادل المهم منخسرش                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n","\n","Original:  RT @USER: @USER البراب عندى بيقولى بيخيروك يا كرتونة يا خمسين جنيه واستأذن يروح ياخد كرتونة 😁\tNOT_OFF\tNOT_HS\r\n","\n","Round-trip:  البراب عندى بيقولى بيخيروك يا كرتونه يا خمسين جنيه واستاذن يروح ياخد كرتونه 😁                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n","\n","Original:  @USER فين يا ابن القحبه يا معرص السودان مش هيعملوا اَي شي من مخططكم هاهاهاهاها و لسه يا خونه\tOFF\tNOT_HS\r\n","\n","Round-trip:  فين يا ابن القحبه يا معرص السودان مش هيعملوا ا ي شي من مخططكم هاهاهاهاها و لسه يا خونه                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n","\n","Original:  @USER عليك لعنه الله يا فتنه الفتنه اشد من القتل انت محرض من النوع الاخوانجي سلمان الحزم سلمان الانسانيه سلمان من دمر كم يا اخوانجي يا شيعي يا ابن موزه عاش سلمان الحزم عاش عاش ملك العرب URL\tOFF\tHS\r\n","\n","Round-trip:  عليك لعنه الله يا فتنه الفتنه اشد من القتل انت محرض من النوع الاخوانجي سلمان الحزم سلمان الانسانيه سلمان من دمر كم يا اخوانجي يا شيعي يا ابن موزه عاش سلمان الحزم عاش عاش ملك العرب                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n","\n","Original:  هما بيعملوا ايه !! انت يا حيوان انت يا اطرررش انا بسقط هنااااا URL\tOFF\tNOT_HS\r\n","\n","Round-trip:  هما بيعملوا ايه انت يا حيوان انت يا اطرررش انا بسقط هنااااا                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n","\n","Original:  @USER @USER أولا يا إبن الشرموطة السعودية , ليش تتكلم مصري , يمكن أمك ناكها حارس العمارة المصري جنبكم مسكينة مبس داعس على وجوهكم يا كلاب يا بدو يا معفنين تبي فلوس على تأكلكم من عرق طيزها ههههههه, والله لأجيك يا إبن الشرموطة البدوية لأنيكك و إحشي كس\tOFF\tHS\r\n","\n","Round-trip:  اولا يا ابن الشرموطه السعوديه ليش تتكلم مصري يمكن امك ناكها حارس العماره المصري جنبكم مسكينه مبس داعس على وجوهكم يا كلاب يا بدو يا معفنين تبي فلوس على تاكلكم من عرق طيزها ههههههه والله لاجيك يا ابن الشرموطه البدويه لانيكك و احشي كس                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n","\n","Original:  RT @USER: يا رب يا واحد يا أحد بحق يوم الاحد ان تهلك بني سعود المجرمين. لاجل اطفال اليمن شاركوا.\tOFF\tHS\r\n","\n","Round-trip:  يا رب يا واحد يا احد بحق يوم الاحد ان تهلك بني سعود المجرمين لاجل اطفال اليمن شاركوا                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n","\n","Original:  @USER <LF>فين GoT يا حرامية يا نصابين يا لصوص!؟\tOFF\tNOT_HS\r\n","\n","Round-trip:  فين يا حراميه يا نصابين يا لصوص                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n","\n","Original:  RT @USER: بطلو انانيه يا شعب يا انصرافي ويلا على صفوف عيشكم وبنزينكم\tOFF\tNOT_HS\r\n","\n","Round-trip:  بطلو انانيه يا شعب يا انصرافي ويلا على صفوف عيشكم وبنزينكم                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bxiWBqGba04S"},"source":["# Create the model"]},{"cell_type":"code","metadata":{"id":"CS_rTLWxaqoE"},"source":["model = tf.keras.Sequential([\r\n","    vectorize_layer,\r\n","    tf.keras.layers.Embedding(len(vectorize_layer.get_vocabulary()), 64, mask_zero=True),\r\n","    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\r\n","    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\r\n","    tf.keras.layers.Dense(64, activation='relu'),\r\n","    tf.keras.layers.Dropout(0.5),\r\n","    tf.keras.layers.Dense(1)\r\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rosrX61Ya4mF"},"source":["model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\r\n","              optimizer=tf.keras.optimizers.Adam(1e-4),\r\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3jyJmWGwbDy_"},"source":["from keras.callbacks import EarlyStopping\r\n","\r\n","history = model.fit(raw_train_ds, epochs=10,\r\n","                    validation_data=raw_val_ds, \r\n","                    validation_steps=30,\r\n","                    callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)]\r\n","                    )\r\n","\r\n","\r\n","# history=model.fit(train_ds, validation_data=val_ds, epochs=epochs,\r\n","#           callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1HNhwjehbVjv"},"source":["test_loss, test_acc = model.evaluate(raw_test_ds)\r\n","\r\n","print('Test Loss: {}'.format(test_loss))\r\n","print('Test Accuracy: {}'.format(test_acc))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y3mzafzzlP5A"},"source":["import matplotlib.pyplot as plt\r\n","acc = history.history['accuracy']\r\n","val_acc = history.history['val_accuracy']\r\n","\r\n","loss=history.history['loss']\r\n","val_loss=history.history['val_loss']\r\n","\r\n","#epochs_range = range(22)\r\n","\r\n","plt.figure(figsize=(15, 15))\r\n","plt.subplot(1, 2, 1)\r\n","plt.plot(acc, label='Training Accuracy')\r\n","plt.plot(val_acc, label='Validation Accuracy')\r\n","plt.legend(loc='lower right')\r\n","plt.title('Training and Validation Accuracy')\r\n","\r\n","plt.subplot(1, 2, 2)\r\n","plt.plot(loss, label='Training Loss')\r\n","plt.plot(val_loss, label='Validation Loss')\r\n","plt.legend(loc='upper right')\r\n","plt.title('Training and Validation Loss')\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T8zls0wytbv4"},"source":["sample_text = (' يا حبيبي بكل صفاتہ يا دموع و يا خضوع  ')\r\n","predictions = model.predict(np.array([sample_text]))\r\n","predictions\r\n","#NOT hate speech"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UQce8atfuw2Q"},"source":["sample_text = (' القم يا ايطالي يا ابن الكلب انت و باصك يلعن اهلك  ')\r\n","predictions = model.predict(np.array([sample_text]))\r\n","predictions\r\n","#Hate"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FxLuitza5as7"},"source":[""],"execution_count":null,"outputs":[]}]}