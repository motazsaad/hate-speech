{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"xlm-r-large-arabic-toxic (toxic/hate speech classifier).ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1UYOM_5no2seS0AaaOZnbnt7aeKQaNwNr","authorship_tag":"ABX9TyP2OJWEYKU299eY4g4BmX+B"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"RIKDI68euAkU"},"source":["#Toxic/hate speech classification\n"]},{"cell_type":"code","metadata":{"id":"45CpiWYkjOpc"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gb_XsWT7moIF","executionInfo":{"status":"ok","timestamp":1618289041611,"user_tz":-180,"elapsed":7963,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"c6cccd41-f2d3-4ab7-898b-f4681f12f0dc"},"source":["# !pip install -U -q transformers\n","!pip install transformers \n","!pip install sentencepiece"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.44)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Wmrx7sJZupqE","executionInfo":{"status":"ok","timestamp":1618289041613,"user_tz":-180,"elapsed":7956,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["import os\n","\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense, Input\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","import transformers\n","from transformers import TFAutoModel, AutoTokenizer\n","from tqdm.notebook import tqdm\n","from tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors\n","from transformers import AutoTokenizer, AutoConfig\n"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"10J1JJ__EY7g"},"source":["#TPU Configs"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w5kFc9X4ENX9","executionInfo":{"status":"ok","timestamp":1618289054153,"user_tz":-180,"elapsed":20490,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"de88d6b7-cd8c-4e50-8a2d-04bb44c81633"},"source":["# Detect hardware, return appropriate distribution strategy\n","try:\n","    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n","    # set: this is always the case on Kaggle.\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    print('Running on TPU ', tpu.master())\n","except ValueError:\n","    tpu = None\n","\n","if tpu:\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","else:\n","    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n","    strategy = tf.distribute.get_strategy()\n","\n","print(\"REPLICAS: \", strategy.num_replicas_in_sync)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Running on TPU  grpc://10.92.44.138:8470\n","WARNING:tensorflow:TPU system grpc://10.92.44.138:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:TPU system grpc://10.92.44.138:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.92.44.138:8470\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.92.44.138:8470\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n","WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["REPLICAS:  8\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"diHHtQUDEQfJ"},"source":["#Functions"]},{"cell_type":"code","metadata":{"id":"apSU-A3iBAgE","executionInfo":{"status":"ok","timestamp":1618289054153,"user_tz":-180,"elapsed":20485,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# Configuration\n","EPOCHS = 3\n","BATCH_SIZE = 64 \n","MAX_LEN = 200\n","PATIENCE = 1\n","LEARNING_RATE = 1e-5"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Y8yl0kYOhrn","executionInfo":{"status":"ok","timestamp":1618289056047,"user_tz":-180,"elapsed":22371,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"0d181c00-d239-4240-9104-6fe2fc0fa8f5"},"source":["from transformers import AutoModelForSequenceClassification, BertForSequenceClassification\n","from transformers import (XLMRobertaConfig, XLMRobertaTokenizer, TFXLMRobertaModel)            \n","from transformers import AutoTokenizer, AutoConfig, AutoModel    \n","\n","PRETRAINED_MODEL_TYPES = {\n","    'xlmroberta': (AutoConfig,  AutoModel, AutoTokenizer, 'akhooli/xlm-r-large-arabic-toxic')\n","}\n","\n","# model_class,model = AutoModelForSequenceClassification.from_pretrained(\"akhooli/xlm-r-large-arabic-toxic\")\n","\n","config_class, model_class, tokenizer_class, model_name = PRETRAINED_MODEL_TYPES['xlmroberta']\n","\n","# Download vocabulary from huggingface.co and cache.\n","# tokenizer = tokenizer_class.from_pretrained(model_name) \n","# from_pt=True,\n","tokenizer = AutoTokenizer.from_pretrained(model_name,use_fast=False) #fast tokenizer\n","\n","tokenizer"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PreTrainedTokenizer(name_or_path='akhooli/xlm-r-large-arabic-toxic', vocab_size=250002, model_max_len=512, is_fast=False, padding_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'})"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"_mE7vnPVNkJq","executionInfo":{"status":"ok","timestamp":1618289061907,"user_tz":-180,"elapsed":28224,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["PRE_TRAINED_MODEL = 'Hate-speech-CNERG/dehatebert-mono-arabic'\n","# PRE_TRAINED_MODEL = 'bert-base-multilingual-cased'\n","# PRE_TRAINED_MODEL = 'xlm-roberta-large'\n","tokenizer = transformers.AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL)\n","from transformers import AutoModelForSequenceClassification\n","\n","model = AutoModel.from_pretrained(PRE_TRAINED_MODEL,\n","                                                      num_labels = 3,\n","                                                      output_attentions = False,\n","                                                      output_hidden_states = False)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"aqBddqzNvQSx","executionInfo":{"status":"ok","timestamp":1618289061908,"user_tz":-180,"elapsed":28221,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["def build_model(transformer, max_len=512):\n","    \"\"\"\n","    function for training the model\n","    \"\"\"\n","    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n","    sequence_output = transformer(input_word_ids)[0]\n","    cls_token = sequence_output[:, 0, :]\n","    out = Dense(1, activation='sigmoid')(cls_token)\n","    \n","    model = Model(inputs=input_word_ids, outputs=out)\n","    model.compile(Adam(lr=3e-5), loss='binary_crossentropy', metrics=[tf.keras.metrics.AUC()])\n","    # changed from 1e-5 to 3e-5\n","    return model"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"7UIqHoMkvnAq","executionInfo":{"status":"error","timestamp":1618289070014,"user_tz":-180,"elapsed":36325,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"d3f54c5a-cf0c-41c6-a517-b1034669ba57"},"source":["with strategy.scope():\n","    transformer_layer = (\n","        transformers\n","        .AutoModelForSequenceClassification.from_pretrained(\"Hate-speech-CNERG/dehatebert-mono-arabic\")\n","        # .TFAutoModel.from_pretrained('jplu/tf-xlm-roberta-large')\n","    )\n","    model = build_model(transformer_layer, max_len=MAX_LEN)"],"execution_count":29,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-b86451db7ee9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# .TFAutoModel.from_pretrained('jplu/tf-xlm-roberta-large')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     )\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-28-a5cd92d230bd>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(transformer, max_len)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m      5\u001b[0m     \u001b[0minput_word_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"input_word_ids\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_word_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mcls_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1508\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1510\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1511\u001b[0m         )\n\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    922\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You cannot specify both input_ids and inputs_embeds at the same time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'KerasTensor' object has no attribute 'size'"]}]},{"cell_type":"markdown","metadata":{"id":"PZNDG6k5Ewk2"},"source":["#Load text data"]},{"cell_type":"code","metadata":{"id":"OAa-Zsaa3EMR","executionInfo":{"status":"ok","timestamp":1618289094409,"user_tz":-180,"elapsed":3366,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["train = pd.read_excel(\"/content/drive/MyDrive/MasterThesis/DataSet-forUsing/semeval2020/train.xlsx\")\n","# n_train_steps = train.shape[0] \n","valid = pd.read_excel('/content/drive/MyDrive/MasterThesis/DataSet-forUsing/semeval2020/dev.xlsx')\n","# n_valid_steps = valid.shape[0] \n","\n","test = pd.read_excel('/content/drive/MyDrive/MasterThesis/DataSet-forUsing/semeval2020/test.xlsx')\n","sub = pd.read_excel('/content/drive/MyDrive/MasterThesis/DataSet-forUsing/semeval2020/sample_submission.xlsx')\n","# gc.collect()\n"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"KFJhOCgrx-DK","executionInfo":{"status":"ok","timestamp":1618289096363,"user_tz":-180,"elapsed":614,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["def encode(df, tokenizer, max_len=512):\n","    \n","    pairs = df['tweets'].values.astype(str).tolist() #shape=[num_examples]\n","    # pairs = df['tweets'].values.astype(str) #shape=[num_examples]\n","    \n","    print (\"Encoding...\")\n","    encoded_dict = tokenizer.batch_encode_plus(pairs, max_length=max_len, padding=True, truncation=True, \n","                                               add_special_tokens=True, return_attention_mask=True)\n","    print (\"Complete\")\n","    \n","    input_word_ids = tf.convert_to_tensor(encoded_dict['input_ids'], dtype=tf.int32) #shape=[num_examples, max_len])\n","    input_mask = tf.convert_to_tensor(encoded_dict['attention_mask'], dtype=tf.int32) #shape=[num_examples, max_len]\n","    \n","    inputs = {\n","        'input_word_ids': input_word_ids,\n","        'input_mask': input_mask}    \n","    \n","    return inputs"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wOZBzhZGAxy-","executionInfo":{"status":"ok","timestamp":1618289101746,"user_tz":-180,"elapsed":5991,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}},"outputId":"6068d8c0-ebea-4389-baa7-eb7215d624e1"},"source":["train_input = encode(train, tokenizer=tokenizer, max_len=MAX_LEN)\n","vaild_input = encode(valid, tokenizer=tokenizer, max_len=MAX_LEN)\n","test_input = encode(test, tokenizer=tokenizer, max_len=MAX_LEN)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Encoding...\n","Complete\n","Encoding...\n","Complete\n","Encoding...\n","Complete\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z_wHUz_qvdJm","executionInfo":{"status":"ok","timestamp":1618289101747,"user_tz":-180,"elapsed":5987,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# y_train = train.hs.values.tolist()\n","# y_valid = valid.hs.values"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"yr2VLOvbONsR","executionInfo":{"status":"ok","timestamp":1618289101748,"user_tz":-180,"elapsed":5984,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# # instantiating the model in the strategy scope creates the model on the TPU\n","# with strategy.scope():\n","#     # model = build_model(MAX_LEN)\n","#     # transformer_layer = TFAutoModel.from_pretrained(model_name)\n","#     model = build_model(max_len=MAX_LEN)\n","#     model.summary()"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lAH70SBYQqLb"},"source":["#Remove"]},{"cell_type":"code","metadata":{"id":"1dRAD2hs3wUX","executionInfo":{"status":"ok","timestamp":1618289101749,"user_tz":-180,"elapsed":5981,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# from transformers import BertTokenizer\n","\n","# # Load the BERT tokenizer.\n","# print('Loading BERT tokenizer...')\n","# # tokenizer = AutoTokenizer.from_pretrained(\"akhooli/xlm-r-large-arabic-toxic\",use_fast=False)\n"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"HFv9rTcZ4FS8","executionInfo":{"status":"ok","timestamp":1618289101749,"user_tz":-180,"elapsed":5976,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# tokenizer"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"jLfZmmM3NyD3","executionInfo":{"status":"ok","timestamp":1618289101750,"user_tz":-180,"elapsed":5973,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# def build_model(max_len=512):\n","    \n","#     # tf.random.set_seed(12345) # For reproducibility\n","    \n","#     # The bare XLM-RoBERTa Model transformer outputting raw hidden-states without any specific head on top.\n","#     encoder = model_class.from_pretrained(model_name)\n","# #     encoder = TFAutoModel.from_pretrained(model_name)\n","#     # tokenized_text = tokenizer.prepare_seq2seq_batch([text], return_tensors='pt')\n","\n","\n","#     input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n","#     input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n","    \n","#     # Extract pretrained embedding vectors\n","#     embedding = encoder([input_word_ids, input_mask])[0] # shape=(batch_size, max_len, embed_size)\n","#     # embedding = encoder(input_word_ids)[0] # shape=(batch_size, max_len, embed_size)\n","#     # We pass the embedding vectors of only the 'cls' token (at index=0) to the dense layer\n","#     sequence_output = embedding[:,0,:] #shape=(batch_size, embed_size)\n","   \n","#     # Add a classification layer\n","#     # output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(sequence_output)  \n","#     output = tf.keras.layers.Dense(2, activation=\"softmax\")(sequence_output)  \n","\n","#     model = tf.keras.Model(inputs=[input_word_ids, input_mask], outputs=output)\n","#     # model = tf.keras.Model(inputs=input_word_ids, outputs=output)\n","#     model.compile(tf.keras.optimizers.Adam(lr=LEARNING_RATE), loss='binary_crossentropy',  metrics=[tf.keras.metrics.AUC(name='auc'), 'accuracy'])\n","    \n","#     return model"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"1kc6DkyV4M04","executionInfo":{"status":"ok","timestamp":1618289101751,"user_tz":-180,"elapsed":5970,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# # Print the original sentence.\n","# print(' Original: ', x_train[0])\n","\n","# # Print the sentence split into tokens.\n","# print('Tokenized: ', tokenizer.tokenize(x_train[0]))\n","\n","# # Print the sentence mapped to token ids.\n","# print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(x_train[0])))"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"5CRBe4uX3hqF","executionInfo":{"status":"ok","timestamp":1618289101752,"user_tz":-180,"elapsed":5966,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":[""],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"9sgXpFvNac8L","executionInfo":{"status":"ok","timestamp":1618289101752,"user_tz":-180,"elapsed":5961,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# def fast_encode(texts, tokenizer, chunk_size=256, maxlen=512):\n","#     \"\"\"\n","#     Encoder for encoding the text into sequence of integers for BERT Input\n","#     \"\"\"\n","#     # tokenizer.enable_truncation(max_length=maxlen)\n","#     # tokenizer.enable_padding(max_length=maxlen)\n","#     tokenizer.enable_truncation(max_length=maxlen)\n","#     if enable_padding:\n","#        tokenizer.enable_padding(max_length=maxlen)\n","#     all_ids = []\n","    \n","#     for i in tqdm(range(0, len(texts), chunk_size)):\n","#         text_chunk = texts[i:i+chunk_size].tolist()\n","#         encs = tokenizer.encode_batch(text_chunk)\n","#         all_ids.extend([enc.ids for enc in encs])\n","    \n","#     return np.array(all_ids)"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"zeGZIAa1a0Cp","executionInfo":{"status":"ok","timestamp":1618289101754,"user_tz":-180,"elapsed":5959,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# def combine_qa_ids(q_ids, a_ids, tokenizer, maxlen=512):\n","#     \"\"\"\n","#     Given two arrays of IDs (questions and answers) created by\n","#     `fast_encode`, we combine and pad them.\n","#     Inputs:\n","#         tokenizer: The original tokenizer (not the fast_tokenizer)\n","#     \"\"\"\n","#     combined_ids = []\n","\n","#     for i in tqdm(range(q_ids.shape[0])):\n","#         ids = []\n","#         ids.append(tokenizer.cls_token_id)\n","#         ids.extend(q_ids[i])\n","#         ids.append(tokenizer.sep_token_id)\n","#         ids.extend(a_ids[i])\n","#         ids.append(tokenizer.sep_token_id)\n","#         ids.extend([tokenizer.pad_token_id] * (maxlen - len(ids)))\n","\n","#         combined_ids.append(ids)\n","    \n","#     return np.array(combined_ids)"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"jFUFpbnd3q5M","executionInfo":{"status":"ok","timestamp":1618289101755,"user_tz":-180,"elapsed":5954,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# def encode_qa(questions, answers, tokenizer, chunk_size=256, maxlen=512):\n","#     \"\"\"\n","#     https://www.kaggle.com/xhlulu/jigsaw-tpu-distilbert-with-huggingface-and-keras\n","#     \"\"\"\n","#     tokenizer.enable_truncation(max_length=maxlen)\n","#     tokenizer.enable_padding(max_length=maxlen)\n","#     all_ids = []\n","    \n","#     for i in tqdm(range(0, len(questions), chunk_size)):\n","#         q_chunk = questions[i:i+chunk_size].tolist()\n","#         a_chunk = answers[i:i+chunk_size].tolist()\n","#         text_chunk = list(zip(q_chunk, a_chunk))\n","        \n","#         encs = tokenizer.encode_batch(text_chunk)\n","#         all_ids.extend([enc.ids for enc in encs])\n","    \n","#     return np.array(all_ids)"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"LRI-2Sl630UQ","executionInfo":{"status":"ok","timestamp":1618289101755,"user_tz":-180,"elapsed":5949,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# def truncate_text(text, tokenizer, chunk_size=256, maxlen=256):\n","#     \"\"\"\n","#     Ensure that the text does not have more than maxlen tokens\n","#     \"\"\"\n","#     tokenizer.enable_truncation(max_length=maxlen)\n","#     all_norm_str = []\n","    \n","#     for i in tqdm(range(0, len(text), chunk_size)):\n","#         chunk = text[i:i+chunk_size].tolist()\n","#         encs = tokenizer.encode_batch(chunk)\n","#         all_norm_str.extend([str(enc.normalized_str) for enc in encs])\n","    \n","#     return all_norm_str"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"E6LQ8tyP31Oz","executionInfo":{"status":"ok","timestamp":1618289101756,"user_tz":-180,"elapsed":5946,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":[""],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"r5L1v3-iaejK","executionInfo":{"status":"ok","timestamp":1618289101757,"user_tz":-180,"elapsed":5943,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# #IMP DATA FOR CONFIG\n","\n","# AUTO = tf.data.experimental.AUTOTUNE\n","\n","\n","# # Configuration\n","# EPOCHS = 3\n","# BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n","# MAX_LEN = 192"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"ox8VwKt_bDQd","executionInfo":{"status":"ok","timestamp":1618289101757,"user_tz":-180,"elapsed":5939,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# from tokenizers import BertWordPieceTokenizer\n","\n","# # First load the real tokenizer\n","# tokenizer = AutoTokenizer.from_pretrained('akhooli/xlm-r-large-arabic-toxic')\n","# # Save the loaded tokenizer locally\n","# # tokenizer.save_pretrained('.')\n","# # Reload it with the huggingface tokenizers library\n","# # fast_tokenizer = BertWordPieceTokenizer('/content/saved_model/vocab.txt', do_lower_case=False)\n","# # fast_tokenizer=BertTokenizer('/content/saved_model/vocab.txt', do_lower_case=False)\n","# # fast_tokenizer=BertTokenizer.from_pretrained('./content/saved_model/vocab.txt')\n","# # fast_tokenizer\n","# # Save the loaded tokenizer locally\n","# # tokenizer.save_pretrained('.')\n","# # Reload it with the huggingface tokenizers library\n","# from transformers import BertTokenizer\n","# sequence = \"Hello, y'all! How are you Tokenizer ðŸ˜ ?\"\n","\n","# tokenizerBT = BertTokenizer('/content/saved_model/vocab.txt')\n","# tokenized_sequenceBT = tokenizerBT.encode(sequence)\n","# print(tokenized_sequenceBT)\n","# # fast_tokenizer = BertWordPieceTokenizer('/content/saved_model/vocab.txt', lowercase=True, add_special_tokens=False)\n","# # fast_tokenizer"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"id":"J7oj1po0uM7k","executionInfo":{"status":"ok","timestamp":1618289101758,"user_tz":-180,"elapsed":5935,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# tokenizerBT"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yl-QGqWIbxyO","executionInfo":{"status":"ok","timestamp":1618289101759,"user_tz":-180,"elapsed":5932,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# x_train = fast_encode(train.tweets.astype(str), tokenizer, maxlen=MAX_LEN)\n","# x_valid = fast_encode(valid.tweets.astype(str), tokenizer, maxlen=MAX_LEN)\n","# x_test = fast_encode(test.tweets.astype(str), tokenizer, maxlen=MAX_LEN)\n","\n","# y_train = train.hs.values\n","# y_valid = valid.hs.values"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"id":"YPiXXf1xfwnR","executionInfo":{"status":"ok","timestamp":1618289101759,"user_tz":-180,"elapsed":5928,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# train_dataset = (\n","#     # tf.convert_to_tensor((x_train, y_train))\n","#     tf.data.Dataset.from_tensor_slices((x_train, y_train))\n","#     .repeat()\n","#     .shuffle(2048)\n","#     .batch(BATCH_SIZE)\n","#     .prefetch(AUTO)\n","# )\n","\n","# valid_dataset = (\n","#     tf.data.Dataset\n","#     .from_tensor_slices((x_valid, y_valid))\n","#     .batch(BATCH_SIZE)\n","#     .cache()\n","#     .prefetch(AUTO)\n","# )\n","\n","# test_dataset = (\n","#     tf.data.Dataset\n","#     .from_tensor_slices(x_test)\n","#     .batch(BATCH_SIZE)\n","# )\n"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"id":"-WppDcRi5dLp","executionInfo":{"status":"ok","timestamp":1618289101760,"user_tz":-180,"elapsed":5925,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# # Tokenize all of the sentences and map the tokens to thier word IDs.\n","# input_ids = []\n","\n","# # For every sentence...\n","# for tweet in tweets:\n","#     # `encode` will:\n","#     #   (1) Tokenize the sentence.\n","#     #   (2) Prepend the `[CLS]` token to the start.\n","#     #   (3) Append the `[SEP]` token to the end.\n","#     #   (4) Map tokens to their IDs.\n","#     encoded_tweets = tokenizer.encode(\n","#                         str(tweet),                      # Sentence to encode.\n","#                         add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","\n","#                         # This function also supports truncation and conversion\n","#                         # to pytorch tensors, but we need to do padding, so we\n","#                         # can't use these features :( .\n","#                         #max_length = 128,          # Truncate all sentences.\n","#                         #return_tensors = 'pt',     # Return pytorch tensors.\n","#                    )\n","    \n","#     # Add the encoded sentence to the list.\n","#     input_ids.append(encoded_tweets)\n","\n","# # Print tweet 0, now as a list of IDs.\n","# print('Original: ', x_train[0])\n","# print('Token IDs:', input_ids[0])"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gwbjp2Cz6EaD","executionInfo":{"status":"ok","timestamp":1618289106229,"user_tz":-180,"elapsed":479,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# print('Max sentence length: ', max([len(sen) for sen in input_ids]))"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"id":"M8IT0YIE6rTp","executionInfo":{"status":"ok","timestamp":1618289110455,"user_tz":-180,"elapsed":530,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# from keras.preprocessing.sequence import pad_sequences\n","\n","# # Set the maximum sequence length.\n","# # I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n","# # maximum training sentence length of 47...\n","# MAX_LEN = 192\n","\n","# print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n","\n","# print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n","\n","# # Pad our input tokens with value 0.\n","# # \"post\" indicates that we want to pad and truncate at the end of the sequence,\n","# # as opposed to the beginning.\n","# input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n","#                           value=0, truncating=\"post\", padding=\"post\")\n","\n","# print('\\nDone.')"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"0dZt_abv7Exn","executionInfo":{"status":"ok","timestamp":1618289110944,"user_tz":-180,"elapsed":1014,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# # Create attention masks\n","# attention_masks = []\n","\n","# # For each sentence...\n","# for tweet in input_ids:\n","    \n","#     # Create the attention mask.\n","#     #   - If a token ID is 0, then it's padding, set the mask to 0.\n","#     #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n","#     att_mask = [int(token_id > 0) for token_id in tweet]\n","    \n","#     # Store the attention mask for this sentence.\n","#     attention_masks.append(att_mask)"],"execution_count":52,"outputs":[]},{"cell_type":"code","metadata":{"id":"-m7k65YmQnsg","executionInfo":{"status":"ok","timestamp":1618289110945,"user_tz":-180,"elapsed":1010,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# # Use train_test_split to split our data into train and validation sets for\n","# # training\n","# from sklearn.model_selection import train_test_split\n","\n","# # Use 90% for training and 10% for validation.\n","# train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n","#                                                             random_state=2018, test_size=0.1)\n","# # Do the same for the masks.\n","# train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n","#                                              random_state=2018, test_size=0.1)"],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"id":"xnWmLGxZ9mu1","executionInfo":{"status":"ok","timestamp":1618289110946,"user_tz":-180,"elapsed":1007,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# import torch"],"execution_count":54,"outputs":[]},{"cell_type":"code","metadata":{"id":"kxKdc4I-a01T","executionInfo":{"status":"ok","timestamp":1618289110946,"user_tz":-180,"elapsed":1003,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# # # Convert all inputs and labels into torch tensors, the required datatype \n","# # for our model.\n","# train_inputs = torch.tensor(x_train.shape[0])\n","# validation_inputs = torch.tensor(valid.tweets)\n","\n","# train_labels = torch.tensor(train_labels)\n","# validation_labels = torch.tensor(validation_labels)\n","\n","# train_masks = torch.tensor(train_masks)\n","# validation_masks = torch.tensor(validation_masks)\n","\n","\n","# train_seq = torch.tensor(tokens_train['input_ids'])\n","# train_mask = torch.tensor(tokens_train['attention_mask'])\n","# train_y = torch.tensor(train_labels.tolist())"],"execution_count":55,"outputs":[]},{"cell_type":"code","metadata":{"id":"wslrHogfbFe1","executionInfo":{"status":"ok","timestamp":1618289110947,"user_tz":-180,"elapsed":998,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# def build_model(transformer, max_len=512):\n","#     \"\"\"\n","#     https://www.kaggle.com/xhlulu/jigsaw-tpu-distilbert-with-huggingface-and-keras\n","#     \"\"\"\n","#     input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n","#     attention_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n","#     sequence_output = transformer({\"input_ids\": input_word_ids, \"attention_mask\": attention_mask})[0]\n","#     cls_token = sequence_output[:, 0, :]\n","#     out = Dense(1, activation='sigmoid')(cls_token)\n","    \n","#     model = Model(inputs={\n","#         \"input_ids\": input_word_ids,\n","#         \"attention_mask\": attention_mask\n","#     }, outputs=out)\n","#     model.compile(Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n","    \n","#     return model"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"id":"xsNxaJa6bPav","executionInfo":{"status":"ok","timestamp":1618289110947,"user_tz":-180,"elapsed":994,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# # Detect hardware, return appropriate distribution strategy\n","# try:\n","#     # TPU detection. No parameters necessary if TPU_NAME environment variable is\n","#     # set: this is always the case on Kaggle.\n","#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","#     print('Running on TPU ', tpu.master())\n","# except ValueError:\n","#     tpu = None\n","\n","# if tpu:\n","#     tf.config.experimental_connect_to_cluster(tpu)\n","#     tf.tpu.experimental.initialize_tpu_system(tpu)\n","#     strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","# else:\n","#     # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n","#     strategy = tf.distribute.get_strategy()\n","\n","# print(\"REPLICAS: \", strategy.num_replicas_in_sync)"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"id":"REeWZSihbUGm","executionInfo":{"status":"ok","timestamp":1618289110948,"user_tz":-180,"elapsed":991,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# MAX_LEN = 192\n","# MODEL = 'akhooli/xlm-r-large-arabic-toxic'\n","# AUTO = tf.data.experimental.AUTOTUNE\n","# BATCH_SIZE = 4 * strategy.num_replicas_in_sync\n","# tokenizer = AutoTokenizer.from_pretrained(MODEL)"],"execution_count":58,"outputs":[]},{"cell_type":"code","metadata":{"id":"R9iEtyQEbgTb","executionInfo":{"status":"ok","timestamp":1618289110948,"user_tz":-180,"elapsed":987,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# x_train = dict_encode(train.tweets.values, tokenizer, maxlen=MAX_LEN)\n","# y_train = train.hs.values\n","\n","# del train\n","# gc.collect()\n","\n","# x_valid = dict_encode(valid.tweets.values, tokenizer, maxlen=MAX_LEN)\n","# y_valid = valid.hs.values\n","# del valid\n","# gc.collect()\n","# x_test = dict_encode(test.tweets.values, tokenizer, maxlen=MAX_LEN)"],"execution_count":59,"outputs":[]},{"cell_type":"code","metadata":{"id":"JWxIUoxj8Vin","executionInfo":{"status":"ok","timestamp":1618289110949,"user_tz":-180,"elapsed":983,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# First load the real tokenizer\n","# tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased')\n","# tokenizer = AutoTokenizer.from_pretrained(\"akhooli/xlm-r-large-arabic-toxic\",use_fast=False)\n","\n","# # Save the loaded tokenizer locally\n","# tokenizer.save_pretrained('./models/tokenizer/')\n","# Reload it with the huggingface tokenizers library\n","# fast_tokenizer = DistilBertTokenizer.from_pretrained('/content/models/tokenizer')\n","# fast_tokenizer = BertWordPieceTokenizer('vocab.txt')\n","# fast_tokenizer\n","\n","# BASE_MODEL = \"distilbert-base-multilingual-cased\"\n","# tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n","# tokenizer.save_pretrained(\"./models/tokenizer/\")\n"],"execution_count":60,"outputs":[]},{"cell_type":"code","metadata":{"id":"6g1XvPy8ShF7","executionInfo":{"status":"ok","timestamp":1618289110949,"user_tz":-180,"elapsed":979,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":[""],"execution_count":60,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SqPieorfEqJg"},"source":["##Create fast tokenizer"]},{"cell_type":"code","metadata":{"id":"UhBuQb2lEgBP","executionInfo":{"status":"ok","timestamp":1618289111412,"user_tz":-180,"elapsed":1439,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# AUTO = tf.data.experimental.AUTOTUNE\n","\n","# # Data access\n","# # GCS_DS_PATH = KaggleDatasets().get_gcs_path()\n","\n","# # Configuration\n","# EPOCHS = 2\n","# BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n","# MAX_LEN = 192\n","# MODEL = 'akhooli/xlm-r-large-arabic-toxic'"],"execution_count":61,"outputs":[]},{"cell_type":"code","metadata":{"id":"a19VoA9iEKYM","executionInfo":{"status":"ok","timestamp":1618289111413,"user_tz":-180,"elapsed":1436,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# def build_model(transformer, max_len=512):\n","#     \"\"\"\n","#     https://www.kaggle.com/xhlulu/jigsaw-tpu-distilbert-with-huggingface-and-keras\n","#     \"\"\"\n","#     input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n","#     sequence_output = transformer(input_word_ids)[0]\n","#     cls_token = sequence_output[:, 0, :]\n","#     out = Dense(1, activation='sigmoid')(cls_token)\n","    \n","#     model = Model(inputs=input_word_ids, outputs=out)\n","#     model.compile(Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n","    \n","#     return model"],"execution_count":62,"outputs":[]},{"cell_type":"code","metadata":{"id":"yCU69Ytzul6U","executionInfo":{"status":"ok","timestamp":1618289111413,"user_tz":-180,"elapsed":1431,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# # def regular_encode(texts, tokenizer, maxlen=512):\n","# #     enc_di = tokenizer.batch_encode_plus(\n","# #         texts,\n","# #         return_tensors='tf',\n","# #         return_attention_masks=False, \n","# #         return_token_type_ids=True,\n","# #         pad_to_max_length=True,\n","# #         max_length=10\n","# #         # texts, \n","# #         # return_attention_masks=True, \n","# #         # return_token_type_ids=False,\n","# #         # pad_to_max_length=True,\n","# #         # padding = 'max_length',\n","# #         # max_length=maxlen,\n","# #         # return_tensors='pt'\n","\n","# #         #  add_special_tokens=False,\n","# #         #                                       # max_length=10,\n","# #         #                                       # pad_to_max_length=True,\n","# #         #                                       return_tensors='pt',\n","# #         #                                       return_attention_mask=True,\n","# #         #                                       return_overflowing_tokens=False\n","# #     )\n","    \n","# #     return np.array(enc_di['input_ids'])\n","\n","# def regular_encode(texts, tokenizer, maxlen=512):\n","#     enc_di = tokenizer.batch_encode_plus(\n","#         texts, \n","#         # return_attention_masks=False, \n","#         # return_token_type_ids=False,\n","#         pad_to_max_length=True,\n","#         max_length=maxlen\n","#     )\n","#     # batch_encode_plus(inp_raw, max_length=20, pad_to_max_length=True)\n","    \n","#     return np.array(enc_di['input_ids'])"],"execution_count":63,"outputs":[]},{"cell_type":"code","metadata":{"id":"12SjpcWMvoAj","executionInfo":{"status":"ok","timestamp":1618289111414,"user_tz":-180,"elapsed":1428,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# def fast_encode(texts, tokenizer, chunk_size=256, maxlen=512):\n","#     \"\"\"\n","#     https://www.kaggle.com/xhlulu/jigsaw-tpu-distilbert-with-huggingface-and-keras\n","#     \"\"\"\n","#     tokenizer.enable_truncation(max_length=maxlen)\n","#     tokenizer.enable_padding(max_length=maxlen)\n","#     all_ids = []\n","    \n","#     for i in tqdm(range(0, len(texts), chunk_size)):\n","#         text_chunk = texts[i:i+chunk_size].tolist()\n","#         encs = tokenizer.encode_batch(text_chunk)\n","#         all_ids.extend([enc.ids for enc in encs])\n","    \n","#     return np.array(all_ids)"],"execution_count":64,"outputs":[]},{"cell_type":"code","metadata":{"id":"CTZCDR5pNrej","executionInfo":{"status":"ok","timestamp":1618289111414,"user_tz":-180,"elapsed":1424,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# !pip install sentencepiece"],"execution_count":65,"outputs":[]},{"cell_type":"code","metadata":{"id":"aHQEGdZUEnmZ","executionInfo":{"status":"ok","timestamp":1618289111415,"user_tz":-180,"elapsed":1422,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# First load the real tokenizer\n","# tokenizer = AutoTokenizer.from_pretrained(MODEL)"],"execution_count":66,"outputs":[]},{"cell_type":"code","metadata":{"id":"yUsQvQQ8Rfj2","executionInfo":{"status":"ok","timestamp":1618289111415,"user_tz":-180,"elapsed":1417,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# from tokenizers import BertWordPieceTokenizer\n","\n","# # # First load the real tokenizer\n","# # # tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# # Save the loaded tokenizer locally\n","\n","# save_path = \"akhooli/xlm-r-large-arabic-toxic/\"\n","# if not os.path.exists(save_path):\n","#     os.makedirs(save_path)\n","# tokenizer.save_pretrained(save_path)\n","\n","# # Load the fast tokenizer from saved file\n","# tokenizer = BertWordPieceTokenizer(\"akhooli/xlm-r-large-arabic-toxic/vocab.txt\", lowercase=True)\n","\n","\n","\n","# ,from_pt=True\n","# tokenizer = AutoTokenizer.from_pretrained('akhooli/xlm-r-large-arabic-toxic',use_fast=False)\n","# tokenizer = AutoTokenizer.from_pretrained('Hate-speech-CNERG/dehatebert-mono-arabic')\n","# tokenizer.save_pretrained('TEST/tokenizer')\n","\n","# tokenizer = AutoTokenizer.from_pretrained('TEST/tokenizer', config=AutoConfig.from_pretrained(\"akhooli/xlm-r-large-arabic-toxic\"))"],"execution_count":67,"outputs":[]},{"cell_type":"code","metadata":{"id":"bxi3a0hZ6svM","executionInfo":{"status":"ok","timestamp":1618289111416,"user_tz":-180,"elapsed":1413,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# len(tokenizer.vocab)\n"],"execution_count":68,"outputs":[]},{"cell_type":"code","metadata":{"id":"EKQR6Pka8j1U","executionInfo":{"status":"ok","timestamp":1618289111416,"user_tz":-180,"elapsed":1409,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["\n","# bert_keys = []\n","\n","# for token in tokenizer.vocab.keys():\n","    \n","#     bert_keys.append(token)\n","    \n","    \n","# print(bert_keys[101])\n","# print(bert_keys[102])\n","# print(bert_keys[0])\n","\n","# print(bert_keys[7592])\n","# print(bert_keys[2088])"],"execution_count":69,"outputs":[]},{"cell_type":"code","metadata":{"id":"eDqM04UeE8Ag","executionInfo":{"status":"ok","timestamp":1618289111417,"user_tz":-180,"elapsed":1405,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# # x_train=tokenizer.encode_batch(train.tweets.values.tolist())\n","# x_train = fast_encode(train.tweets.astype(str), tokenizer, maxlen=MAX_LEN)\n","# x_valid = regular_encode(valid.tweets.values, tokenizer, maxlen=MAX_LEN)\n","# x_test = regular_encode(test.tweets.values, tokenizer, maxlen=MAX_LEN)\n","\n","# y_train = train.hs.values\n","# y_valid = valid.hs.values"],"execution_count":70,"outputs":[]},{"cell_type":"code","metadata":{"id":"sOf3Wi5J6yym","executionInfo":{"status":"ok","timestamp":1618289111417,"user_tz":-180,"elapsed":1401,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# bert_vocab = tokenizer.vocab\n","# bert_vocab\n","# print(bert_vocab['[CLS]'])\n","# print(bert_vocab['[SEP]'])\n","# print(bert_vocab['[PAD]'])\n","\n","# print(bert_vocab['hello'])\n","# print(bert_vocab['world'])"],"execution_count":71,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ieCPvOS4SvL","executionInfo":{"status":"ok","timestamp":1618289111418,"user_tz":-180,"elapsed":1398,"user":{"displayName":"Do salam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP0GyFxHH-3NAPSZ_ethp4uMqaN8pUWhOxcO0NDw=s64","userId":"03587359084159229589"}}},"source":["# # Get the lists of sentences and their labels.\n","# x_train = train.tweets.values\n","# y_train = train.hs.values\n","# x_vaild = valid.tweets.values\n","# y_valid = valid.hs.values\n","# x_test = train.tweets.values\n","# # y_train = train.hs.values"],"execution_count":72,"outputs":[]}]}